# Sparklio V4 ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ (Performance Tuning Guide)

## ëª©ì°¨
- [ê°œìš”](#ê°œìš”)
- [ì„±ëŠ¥ ëª©í‘œ](#ì„±ëŠ¥-ëª©í‘œ)
- [ëª¨ë‹ˆí„°ë§ ë° í”„ë¡œíŒŒì¼ë§](#ëª¨ë‹ˆí„°ë§-ë°-í”„ë¡œíŒŒì¼ë§)
- [Backend ìµœì í™”](#backend-ìµœì í™”)
- [Database ìµœì í™”](#database-ìµœì í™”)
- [Redis ìµœì í™”](#redis-ìµœì í™”)
- [LLM ìµœì í™”](#llm-ìµœì í™”)
- [Frontend ìµœì í™”](#frontend-ìµœì í™”)
- [ë„¤íŠ¸ì›Œí¬ ìµœì í™”](#ë„¤íŠ¸ì›Œí¬-ìµœì í™”)
- [ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìµœì í™”](#ì‹œìŠ¤í…œ-ë¦¬ì†ŒìŠ¤-ìµœì í™”)

---

## ê°œìš”

Sparklio V4ëŠ” ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œìœ¼ë¡œ, ë‹¤ì–‘í•œ ë ˆì´ì–´ì—ì„œ ì„±ëŠ¥ ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ ë¬¸ì„œëŠ” ì‹œìŠ¤í…œ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì„±ëŠ¥ ë³‘ëª© ì§€ì 

```mermaid
flowchart LR
    A[ì‚¬ìš©ì ìš”ì²­] --> B[Frontend]
    B --> C[Backend API]
    C --> D[SmartRouter]
    D --> E[Agent ì‹¤í–‰]
    E --> F[LLM í˜¸ì¶œ]
    E --> G[Database ì¿¼ë¦¬]
    E --> H[Asset ìƒì„±]
    F --> I[ì‘ë‹µ]
    G --> I
    H --> I
    I --> A

    style F fill:#ff9999
    style G fill:#ffcc99
    style H fill:#ffcc99
```

**ì£¼ìš” ë³‘ëª© ì§€ì **:
1. ğŸ”´ **LLM í˜¸ì¶œ** (3-10ì´ˆ) - ê°€ì¥ í° ë³‘ëª©
2. ğŸŸ  **Database ì¿¼ë¦¬** (10-500ms)
3. ğŸŸ  **Asset ìƒì„±** (5-30ì´ˆ)

---

## ì„±ëŠ¥ ëª©í‘œ

### í˜„ì¬ ì„±ëŠ¥ (Baseline)

| ë©”íŠ¸ë¦­ | í˜„ì¬ ê°’ | ëª©í‘œ ê°’ | ê°œì„ ìœ¨ |
|--------|---------|---------|--------|
| **ë‹¨ì¼ Agent ì‘ë‹µ ì‹œê°„** | 23ì´ˆ | 18ì´ˆ | -22% |
| **Context í¬ê¸°** | 15KB | 8KB | -47% |
| **ë³‘ë ¬ Agent ì²˜ë¦¬ëŸ‰** | 5 TPS | 10 TPS | +100% |
| **Database ì¿¼ë¦¬ ì‹œê°„** | 150ms | 50ms | -67% |
| **LLM ì²« í† í° ì‹œê°„** | 2ì´ˆ | 1ì´ˆ | -50% |
| **Frontend ë Œë”ë§** | 500ms | 200ms | -60% |

### ì„±ëŠ¥ SLA

| ì§€í‘œ | Target | Warning | Critical |
|------|--------|---------|----------|
| P50 ì‘ë‹µ ì‹œê°„ | < 3ì´ˆ | > 5ì´ˆ | > 10ì´ˆ |
| P95 ì‘ë‹µ ì‹œê°„ | < 10ì´ˆ | > 15ì´ˆ | > 30ì´ˆ |
| P99 ì‘ë‹µ ì‹œê°„ | < 20ì´ˆ | > 30ì´ˆ | > 60ì´ˆ |
| ì—ëŸ¬ìœ¨ | < 1% | > 3% | > 5% |
| CPU ì‚¬ìš©ë¥  | < 70% | > 85% | > 95% |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | < 80% | > 90% | > 95% |

---

## ëª¨ë‹ˆí„°ë§ ë° í”„ë¡œíŒŒì¼ë§

### 1. Prometheus ë©”íŠ¸ë¦­ í™œìš©

```bash
# ì‘ë‹µ ì‹œê°„ ë¶„ì„
curl -s http://localhost:8000/metrics | grep "sparklio_http_request_duration_seconds"

# Agent ì„±ëŠ¥ ë¶„ì„
curl -s http://localhost:8000/metrics | grep "sparklio_agent_duration_seconds"

# LLM í˜¸ì¶œ ë¶„ì„
curl -s http://localhost:8000/metrics | grep "sparklio_llm_call_duration_seconds"
```

### 2. ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ í™œì„±í™”

#### Backend í”„ë¡œíŒŒì¼ë§ (Python)

```python
# backend/app/profiling.py

from fastapi import Request
import time
import logging
from typing import Callable

logger = logging.getLogger(__name__)

async def profile_middleware(request: Request, call_next: Callable):
    """
    ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ë¯¸ë“¤ì›¨ì–´
    """
    start_time = time.time()

    # ìš”ì²­ ì²˜ë¦¬
    response = await call_next(request)

    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    process_time = time.time() - start_time

    # ëŠë¦° ìš”ì²­ ë¡œê¹… (> 3ì´ˆ)
    if process_time > 3.0:
        logger.warning(
            f"Slow request: {request.method} {request.url.path} "
            f"took {process_time:.2f}s"
        )

    # ì‘ë‹µ í—¤ë”ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
    response.headers["X-Process-Time"] = str(process_time)

    return response
```

```python
# backend/app/main.pyì— ì¶”ê°€

from app.profiling import profile_middleware

app.add_middleware(BaseHTTPMiddleware, dispatch=profile_middleware)
```

#### Database ì¿¼ë¦¬ ë¡œê¹…

```python
# backend/app/database.py

import logging
from sqlalchemy import event
from sqlalchemy.engine import Engine
import time

logger = logging.getLogger(__name__)

# ëŠë¦° ì¿¼ë¦¬ ê°ì§€
@event.listens_for(Engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    conn.info.setdefault('query_start_time', []).append(time.time())

@event.listens_for(Engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    total = time.time() - conn.info['query_start_time'].pop(-1)

    # 100ms ì´ìƒ ê±¸ë¦° ì¿¼ë¦¬ ë¡œê¹…
    if total > 0.1:
        logger.warning(f"Slow query ({total:.2f}s): {statement[:200]}")
```

### 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/performance_test.sh

echo "=== Sparklio V4 Performance Test ==="

# 1. Backend ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
echo "Testing Backend response time..."
for i in {1..10}; do
    curl -w "@curl-format.txt" -o /dev/null -s http://localhost:8000/health
done

# 2. Agent ì‹¤í–‰ ì‹œê°„ í…ŒìŠ¤íŠ¸
echo "Testing Agent execution..."
time curl -X POST http://localhost:8000/api/v1/router/classify \
    -H "Content-Type: application/json" \
    -d '{"query": "Create a social media post about AI"}'

# 3. ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Apache Bench)
echo "Running load test..."
ab -n 100 -c 10 http://localhost:8000/health

# 4. Database ì¿¼ë¦¬ ì„±ëŠ¥
echo "Testing database performance..."
psql sparklio_v4 -c "EXPLAIN ANALYZE SELECT * FROM workflows LIMIT 100;"
```

**curl-format.txt**:
```
time_namelookup:  %{time_namelookup}\n
time_connect:  %{time_connect}\n
time_appconnect:  %{time_appconnect}\n
time_pretransfer:  %{time_pretransfer}\n
time_redirect:  %{time_redirect}\n
time_starttransfer:  %{time_starttransfer}\n
----------\n
time_total:  %{time_total}\n
```

---

## Backend ìµœì í™”

### 1. FastAPI ìµœì í™”

#### Async/Await í™œìš©

```python
# âŒ ë™ê¸° ë°©ì‹ (ëŠë¦¼)
def get_user(user_id: int):
    user = db.query(User).filter(User.id == user_id).first()
    return user

# âœ… ë¹„ë™ê¸° ë°©ì‹ (ë¹ ë¦„)
async def get_user(user_id: int):
    async with async_session() as session:
        result = await session.execute(
            select(User).filter(User.id == user_id)
        )
        return result.scalar_one_or_none()
```

#### ë³‘ë ¬ ì²˜ë¦¬

```python
# âŒ ìˆœì°¨ ì²˜ë¦¬
async def process_agents():
    result1 = await agent1.execute()
    result2 = await agent2.execute()
    result3 = await agent3.execute()
    return [result1, result2, result3]

# âœ… ë³‘ë ¬ ì²˜ë¦¬
import asyncio

async def process_agents():
    results = await asyncio.gather(
        agent1.execute(),
        agent2.execute(),
        agent3.execute()
    )
    return results
```

#### Response ìºì‹±

```python
from fastapi_cache import FastAPICache
from fastapi_cache.backends.redis import RedisBackend
from fastapi_cache.decorator import cache

# Redis ìºì‹œ ë°±ì—”ë“œ ì„¤ì •
@app.on_event("startup")
async def startup():
    redis = aioredis.from_url("redis://localhost")
    FastAPICache.init(RedisBackend(redis), prefix="fastapi-cache")

# ìºì‹œ ì ìš©
@app.get("/api/v1/agents")
@cache(expire=300)  # 5ë¶„ ìºì‹±
async def list_agents():
    return await db.query(Agent).all()
```

### 2. Uvicorn ì„¤ì • ìµœì í™”

```bash
# ë‹¨ì¼ ì›Œì»¤ (ê¸°ë³¸)
uvicorn app.main:app --host 0.0.0.0 --port 8000

# ë©€í‹° ì›Œì»¤ (ê¶Œì¥ - CPU ì½”ì–´ ìˆ˜ì— ë§ì¶¤)
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4

# Gunicorn + Uvicorn (Production)
gunicorn app.main:app \
    --workers 4 \
    --worker-class uvicorn.workers.UvicornWorker \
    --bind 0.0.0.0:8000 \
    --timeout 120 \
    --keep-alive 5
```

**ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°**:
```
workers = (2 x CPU ì½”ì–´ ìˆ˜) + 1
```

Mac mini (M2, 8ì½”ì–´): `workers = 4`

### 3. Context ìµœì†Œí™”

```python
# backend/app/context/minimizer.py

def minimize_context(context: dict, intent: str) -> dict:
    """
    Intentì— ë”°ë¼ ë¶ˆí•„ìš”í•œ Context ì œê±°

    ëª©í‘œ: 15KB â†’ 8KB (47% ê°ì†Œ)
    """
    minimized = {}

    # System Context (í•­ìƒ í¬í•¨)
    minimized['system'] = context.get('system', {})

    # Intentë³„ í•„ìš”í•œ Contextë§Œ ì„ íƒ
    if intent == "copy_generation":
        minimized['task'] = {
            'brand_voice': context['task'].get('brand_voice'),
            'target_audience': context['task'].get('target_audience')
        }
    elif intent == "visual_generation":
        minimized['task'] = {
            'brand_colors': context['task'].get('brand_colors'),
            'style_guide': context['task'].get('style_guide')
        }
    # ...

    # Working Memory (ìµœê·¼ 2-3ê°œë§Œ)
    minimized['working'] = context.get('working', [])[-3:]

    return minimized
```

---

## Database ìµœì í™”

### 1. ì¸ë±ìŠ¤ ì¶”ê°€

```sql
-- ìì£¼ ì¿¼ë¦¬ë˜ëŠ” ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ì¶”ê°€

-- Workflows í…Œì´ë¸”
CREATE INDEX idx_workflows_user_id ON workflows(user_id);
CREATE INDEX idx_workflows_status ON workflows(status);
CREATE INDEX idx_workflows_created_at ON workflows(created_at DESC);

-- Agents í…Œì´ë¸”
CREATE INDEX idx_agents_type ON agents(agent_type);
CREATE INDEX idx_agents_status ON agents(status);

-- Assets í…Œì´ë¸”
CREATE INDEX idx_assets_workflow_id ON assets(workflow_id);
CREATE INDEX idx_assets_type ON assets(asset_type);

-- ë³µí•© ì¸ë±ìŠ¤ (WHERE + ORDER BY ìµœì í™”)
CREATE INDEX idx_workflows_user_status_created
    ON workflows(user_id, status, created_at DESC);
```

### 2. ì¿¼ë¦¬ ìµœì í™”

#### N+1 ì¿¼ë¦¬ ë¬¸ì œ í•´ê²°

```python
# âŒ N+1 ë¬¸ì œ (ëŠë¦¼)
workflows = db.query(Workflow).all()
for workflow in workflows:
    print(workflow.user.name)  # ê° workflowë§ˆë‹¤ ì¶”ê°€ ì¿¼ë¦¬!

# âœ… Eager Loading (ë¹ ë¦„)
from sqlalchemy.orm import joinedload

workflows = db.query(Workflow).options(
    joinedload(Workflow.user),
    joinedload(Workflow.assets)
).all()

for workflow in workflows:
    print(workflow.user.name)  # ì¶”ê°€ ì¿¼ë¦¬ ì—†ìŒ
```

#### Pagination

```python
# âŒ ëª¨ë“  ë ˆì½”ë“œ ë¡œë“œ (ëŠë¦¼)
workflows = db.query(Workflow).all()

# âœ… Pagination (ë¹ ë¦„)
from fastapi import Query

@app.get("/api/v1/workflows")
async def list_workflows(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100)
):
    offset = (page - 1) * page_size

    workflows = db.query(Workflow)\
        .offset(offset)\
        .limit(page_size)\
        .all()

    total = db.query(Workflow).count()

    return {
        "items": workflows,
        "total": total,
        "page": page,
        "page_size": page_size
    }
```

### 3. Connection Pool íŠœë‹

```python
# backend/app/database.py

from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,        # ê¸°ë³¸ ì—°ê²° ìˆ˜ (ê¸°ë³¸ê°’: 5)
    max_overflow=10,     # ì¶”ê°€ ì—°ê²° ìˆ˜ (ê¸°ë³¸ê°’: 10)
    pool_timeout=30,     # ì—°ê²° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    pool_recycle=3600,   # ì—°ê²° ì¬í™œìš© ì‹œê°„ (1ì‹œê°„)
    pool_pre_ping=True,  # ì—°ê²° ìœ íš¨ì„± ê²€ì‚¬
    echo=False           # SQL ë¡œê¹… ë¹„í™œì„±í™” (Production)
)
```

**ê¶Œì¥ ì„¤ì •**:
- `pool_size`: ì˜ˆìƒ ë™ì‹œ ì—°ê²° ìˆ˜
- `max_overflow`: pool_sizeì˜ 50%
- Mac mini ê¸°ì¤€: `pool_size=20, max_overflow=10`

### 4. PostgreSQL ì„¤ì • íŠœë‹

```bash
# /opt/homebrew/var/postgresql@15/postgresql.conf

# ë©”ëª¨ë¦¬ ì„¤ì • (Mac mini M2, 16GB RAM ê¸°ì¤€)
shared_buffers = 4GB                    # ì´ RAMì˜ 25%
effective_cache_size = 12GB             # ì´ RAMì˜ 75%
maintenance_work_mem = 1GB              # ìœ ì§€ë³´ìˆ˜ ì‘ì—…
work_mem = 64MB                         # ì •ë ¬/í•´ì‹œ ì‘ì—…

# ì¿¼ë¦¬ í”Œë˜ë„ˆ
random_page_cost = 1.1                  # SSD ê¸°ì¤€ (ê¸°ë³¸ê°’: 4.0)
effective_io_concurrency = 200          # SSD ë™ì‹œ I/O

# WAL (Write-Ahead Logging)
wal_buffers = 16MB
checkpoint_completion_target = 0.9
max_wal_size = 2GB

# ì—°ê²° ìˆ˜
max_connections = 100

# ë¡œê¹… (ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§)
log_min_duration_statement = 1000       # 1ì´ˆ ì´ìƒ ì¿¼ë¦¬ ë¡œê¹…
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d '
```

ì„¤ì • ì ìš©:
```bash
brew services restart postgresql@15
```

### 5. VACUUM ë° ANALYZE

```bash
# ì •ê¸°ì ì¸ ë°ì´í„°ë² ì´ìŠ¤ ìœ ì§€ë³´ìˆ˜
# Cronìœ¼ë¡œ ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ ì‹¤í–‰

# ì „ì²´ VACUUM
vacuumdb --all --analyze --verbose

# íŠ¹ì • í…Œì´ë¸”
vacuumdb -d sparklio_v4 -t workflows --analyze --verbose
```

---

## Redis ìµœì í™”

### 1. Redis ë©”ëª¨ë¦¬ ìµœì í™”

```bash
# /opt/homebrew/etc/redis.conf

# ìµœëŒ€ ë©”ëª¨ë¦¬ ì„¤ì • (2GB)
maxmemory 2gb

# ë©”ëª¨ë¦¬ ì •ì±… (LRU - Least Recently Used)
maxmemory-policy allkeys-lru

# ì˜êµ¬ ì €ì¥ (RDB ìŠ¤ëƒ…ìƒ·)
save 900 1       # 900ì´ˆ ë™ì•ˆ 1ê°œ ì´ìƒ ë³€ê²½ ì‹œ ì €ì¥
save 300 10      # 300ì´ˆ ë™ì•ˆ 10ê°œ ì´ìƒ ë³€ê²½ ì‹œ ì €ì¥
save 60 10000    # 60ì´ˆ ë™ì•ˆ 10000ê°œ ì´ìƒ ë³€ê²½ ì‹œ ì €ì¥

# AOF (Append Only File) - ë°ì´í„° ì•ˆì •ì„± ìš°ì„  ì‹œ
# appendonly yes
# appendfsync everysec
```

### 2. Redis ìºì‹± ì „ëµ

```python
# backend/app/cache.py

import redis
import json
from typing import Optional, Any
from functools import wraps

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def cache_result(ttl: int = 300):
    """
    í•¨ìˆ˜ ê²°ê³¼ë¥¼ Redisì— ìºì‹±í•˜ëŠ” ë°ì½”ë ˆì´í„°

    Args:
        ttl: Time To Live (ì´ˆ)
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"

            # ìºì‹œ í™•ì¸
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # í•¨ìˆ˜ ì‹¤í–‰
            result = await func(*args, **kwargs)

            # ê²°ê³¼ ìºì‹±
            redis_client.setex(
                cache_key,
                ttl,
                json.dumps(result)
            )

            return result
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@cache_result(ttl=600)  # 10ë¶„ ìºì‹±
async def get_brand_assets(brand_id: int):
    return await db.query(BrandAsset).filter(
        BrandAsset.brand_id == brand_id
    ).all()
```

### 3. Redis Pipeline (ì¼ê´„ ì²˜ë¦¬)

```python
# âŒ ê°œë³„ ìš”ì²­ (ëŠë¦¼)
for key in keys:
    redis_client.get(key)

# âœ… Pipeline (ë¹ ë¦„)
pipe = redis_client.pipeline()
for key in keys:
    pipe.get(key)
results = pipe.execute()
```

---

## LLM ìµœì í™”

### 1. ëª¨ë¸ ì„ íƒ ìµœì í™”

```python
# backend/app/smartrouter/model_selector.py

def select_optimal_model(intent: str, complexity: str) -> str:
    """
    Intentì™€ ë³µì¡ë„ì— ë”°ë¼ ìµœì  ëª¨ë¸ ì„ íƒ

    ëª©í‘œ: í‰ê·  ì‘ë‹µ ì‹œê°„ 23s â†’ 18s (22% ê°œì„ )
    """

    # ê°„ë‹¨í•œ ì‘ì—… â†’ ì‘ì€ ëª¨ë¸
    if complexity == "low":
        if intent in ["copy_generation", "social_post"]:
            return "llama2:7b"  # ë¹ ë¦„, ì¶©ë¶„í•œ í’ˆì§ˆ

    # ì¤‘ê°„ ë³µì¡ë„ â†’ ì¤‘ê°„ ëª¨ë¸
    elif complexity == "medium":
        return "llama2:13b"  # ê· í˜•

    # ë†’ì€ ë³µì¡ë„ â†’ í° ëª¨ë¸
    else:
        return "llama2:70b"  # ë†’ì€ í’ˆì§ˆ
```

### 2. Prompt ìµœì í™”

```python
# âŒ ê¸´ Prompt (ëŠë¦¼)
prompt = f"""
You are a professional copywriter with 10 years of experience...
[500 tokens of instructions]

User request: {user_query}
"""

# âœ… ì§§ì€ Prompt (ë¹ ë¦„)
prompt = f"""
Role: Expert copywriter
Task: {user_query}
Style: {brand_voice}
Max length: 100 words
"""
```

**íš¨ê³¼**:
- Prompt í† í° ìˆ˜: 500 â†’ 50 (90% ê°ì†Œ)
- ì²˜ë¦¬ ì‹œê°„: 8ì´ˆ â†’ 2ì´ˆ (75% ê°œì„ )

### 3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

```python
# backend/app/integrations/ollama.py

async def generate_streaming(prompt: str, model: str):
    """
    ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ LLM ì‘ë‹µ ìƒì„±

    ì¥ì : ì²« í† í° ì‹œê°„ ë‹¨ì¶• (2ì´ˆ â†’ 1ì´ˆ)
    """
    async with httpx.AsyncClient() as client:
        async with client.stream(
            'POST',
            f'{OLLAMA_URL}/api/generate',
            json={'model': model, 'prompt': prompt, 'stream': True},
            timeout=60.0
        ) as response:
            async for line in response.aiter_lines():
                if line:
                    chunk = json.loads(line)
                    yield chunk['response']
```

### 4. LLM ìºì‹±

```python
# ë™ì¼í•œ ìš”ì²­ì— ëŒ€í•´ LLM í˜¸ì¶œ ìŠ¤í‚µ

import hashlib

def get_prompt_hash(prompt: str) -> str:
    return hashlib.sha256(prompt.encode()).hexdigest()

async def generate_with_cache(prompt: str, model: str):
    cache_key = f"llm:{model}:{get_prompt_hash(prompt)}"

    # ìºì‹œ í™•ì¸
    cached = redis_client.get(cache_key)
    if cached:
        return cached.decode()

    # LLM í˜¸ì¶œ
    result = await ollama_client.generate(prompt, model)

    # ìºì‹± (24ì‹œê°„)
    redis_client.setex(cache_key, 86400, result)

    return result
```

### 5. Ollama ì„¤ì • ìµœì í™”

```bash
# Desktop (Windows)ì—ì„œ Ollama ì„œë¹„ìŠ¤ ì„¤ì •

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
# OLLAMA_NUM_PARALLEL=4           # ë³‘ë ¬ ìš”ì²­ ìˆ˜
# OLLAMA_MAX_LOADED_MODELS=2      # ë™ì‹œ ë¡œë“œ ëª¨ë¸ ìˆ˜
# OLLAMA_FLASH_ATTENTION=1        # Flash Attention í™œì„±í™”
```

---

## Frontend ìµœì í™”

### 1. Next.js ìµœì í™”

#### Image ìµœì í™”

```tsx
// âŒ ì¼ë°˜ img íƒœê·¸
<img src="/logo.png" alt="Logo" />

// âœ… Next.js Image ì»´í¬ë„ŒíŠ¸
import Image from 'next/image'

<Image
  src="/logo.png"
  alt="Logo"
  width={200}
  height={50}
  priority  // LCP ìµœì í™”
/>
```

#### Code Splitting

```tsx
// âŒ ì •ì  import
import HeavyComponent from '@/components/HeavyComponent'

// âœ… Dynamic import
import dynamic from 'next/dynamic'

const HeavyComponent = dynamic(() => import('@/components/HeavyComponent'), {
  loading: () => <p>Loading...</p>,
  ssr: false  // í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œë§Œ
})
```

#### React Query ìºì‹±

```tsx
// frontend/src/hooks/useWorkflows.ts

import { useQuery } from '@tanstack/react-query'

export function useWorkflows() {
  return useQuery({
    queryKey: ['workflows'],
    queryFn: fetchWorkflows,
    staleTime: 5 * 60 * 1000,  // 5ë¶„ê°„ fresh
    cacheTime: 10 * 60 * 1000,  // 10ë¶„ê°„ ìºì‹œ ìœ ì§€
    refetchOnWindowFocus: false
  })
}
```

### 2. Bundle í¬ê¸° ìµœì í™”

```bash
# Bundle ë¶„ì„
npm run build
npx @next/bundle-analyzer

# Tree shaking (ë¶ˆí•„ìš”í•œ ì½”ë“œ ì œê±°)
# package.json
{
  "sideEffects": false
}
```

### 3. Service Worker ìºì‹±

```javascript
// frontend/public/sw.js

self.addEventListener('fetch', (event) => {
  event.respondWith(
    caches.match(event.request).then((response) => {
      return response || fetch(event.request)
    })
  )
})
```

---

## ë„¤íŠ¸ì›Œí¬ ìµœì í™”

### 1. HTTP/2 í™œì„±í™”

```bash
# Nginx ì„¤ì • (ì¶”í›„ ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ë„ì… ì‹œ)
server {
    listen 443 ssl http2;
    # ...
}
```

### 2. Compression

```python
# FastAPIì—ì„œ Gzip ì••ì¶• í™œì„±í™”

from fastapi.middleware.gzip import GZipMiddleware

app.add_middleware(GZipMiddleware, minimum_size=1000)
```

### 3. API Response ìµœì í™”

```python
# âŒ ëª¨ë“  í•„ë“œ ë°˜í™˜
@app.get("/api/v1/workflows/{id}")
async def get_workflow(id: int):
    workflow = await db.get(Workflow, id)
    return workflow  # ëª¨ë“  í•„ë“œ

# âœ… í•„ìš”í•œ í•„ë“œë§Œ ë°˜í™˜
from pydantic import BaseModel

class WorkflowResponse(BaseModel):
    id: int
    name: str
    status: str
    # í•„ìš”í•œ í•„ë“œë§Œ

@app.get("/api/v1/workflows/{id}", response_model=WorkflowResponse)
async def get_workflow(id: int):
    workflow = await db.get(Workflow, id)
    return workflow
```

---

## ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìµœì í™”

### 1. Mac mini (M2) ìµœì í™”

```bash
# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
top -o cpu

# ë©”ëª¨ë¦¬ ì••ë ¥ í™•ì¸
memory_pressure

# ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
# Activity Monitorì—ì„œ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ì€ í”„ë¡œì„¸ìŠ¤ í™•ì¸
```

### 2. íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ì œí•œ ì¦ê°€

```bash
# Mac miniì—ì„œ ë™ì‹œ ì—°ê²° ìˆ˜ ì¦ê°€

# /etc/sysctl.conf
kern.maxfiles=65536
kern.maxfilesperproc=32768

# ì ìš©
sudo sysctl -w kern.maxfiles=65536
sudo sysctl -w kern.maxfilesperproc=32768

# ì˜êµ¬ ì„¤ì •
echo "kern.maxfiles=65536" | sudo tee -a /etc/sysctl.conf
echo "kern.maxfilesperproc=32768" | sudo tee -a /etc/sysctl.conf
```

### 3. Celery Worker ìµœì í™”

```bash
# Celery worker ì‹¤í–‰ (ì¶”í›„ êµ¬í˜„)
celery -A app.celery worker \
    --loglevel=info \
    --concurrency=4 \
    --max-tasks-per-child=1000 \
    --time-limit=300
```

---

## ì„±ëŠ¥ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

### Backend
- [ ] Async/await ì‚¬ìš©
- [ ] Database ì¿¼ë¦¬ ìµœì í™” (N+1 í•´ê²°)
- [ ] Redis ìºì‹± ì ìš©
- [ ] Context ìµœì†Œí™” êµ¬í˜„
- [ ] Uvicorn worker ìˆ˜ ì„¤ì •

### Database
- [ ] ì¸ë±ìŠ¤ ì¶”ê°€
- [ ] Connection pool íŠœë‹
- [ ] PostgreSQL ì„¤ì • ìµœì í™”
- [ ] VACUUM ì‹¤í–‰

### LLM
- [ ] ëª¨ë¸ ì„ íƒ ìµœì í™”
- [ ] Prompt ìµœì†Œí™”
- [ ] LLM ìºì‹± êµ¬í˜„
- [ ] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í™œì„±í™”

### Frontend
- [ ] Image ìµœì í™”
- [ ] Code splitting
- [ ] React Query ìºì‹±
- [ ] Bundle í¬ê¸° í™•ì¸

### ë„¤íŠ¸ì›Œí¬
- [ ] Gzip ì••ì¶• í™œì„±í™”
- [ ] API Response ìµœì í™”
- [ ] HTTP/2 í™œì„±í™” (ì„ íƒ)

### ëª¨ë‹ˆí„°ë§
- [ ] Prometheus ë©”íŠ¸ë¦­ í™•ì¸
- [ ] ëŠë¦° ì¿¼ë¦¬ ë¡œê¹… í™•ì¸
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ìµœì¢… ìˆ˜ì •ì¼**: 2025-01-15
**ì‘ì„±ì**: AíŒ€ (Infrastructure Team)
