---
doc_id: DEC-001
title: Why Gateway Pattern? (왜 Gateway 패턴인가?)
created: 2025-11-16
updated: 2025-11-16
status: approved
decision_date: 2025-11-16
participants: A팀 (QA), PM
phase: Phase 0 - 설계
priority: P0
authors: A팀 (Claude + QA)
related:
  - ARCH-002: Gateway Pattern
  - DEC-002: Ollama First Strategy
  - REPORT: 2025-11-16_LLM_CONNECTION_ANALYSIS
---

# ADR-001: Why Gateway Pattern?

## 의사결정 요약

**결정**: LLM/Media Gateway 패턴 채택

**날짜**: 2025-11-16

**상황**: Backend API 테스트 타임아웃 문제 해결 + LLM 연결 전략 수립

**결과**: 4개 Gateway (LLM / Image / Video / Audio) 구조로 확정

---

## 목차

1. [배경 (Context)](#배경-context)
2. [문제 상황 (Problem)](#문제-상황-problem)
3. [고려한 대안들 (Options)](#고려한-대안들-options)
4. [결정 (Decision)](#결정-decision)
5. [근거 (Rationale)](#근거-rationale)
6. [결과 (Consequences)](#결과-consequences)

---

## 배경 (Context)

### 프로젝트 현황 (2025-11-16 기준)

**인프라**:
- Desktop: Ollama (Docker), ComfyUI (Standalone)
- Mac mini: Backend API (FastAPI)
- 6개 Agent 구현 완료 (Brief / Brand / Strategist / Copywriter / Vision / Reviewer)

**문제**:
- Backend API 테스트 189개 중 대부분 타임아웃
- 원인: LLM/ComfyUI 미연결, Mock 모드 없음
- Agent가 직접 Ollama/ComfyUI 호출 시도

**목표**:
- LLM/ComfyUI 연결
- 테스트 타임아웃 해결
- 향후 GPT/Claude/Gemini/DALL·E/Veo3 확장 가능하게

---

## 문제 상황 (Problem)

### 2025-11-15 테스트 타임아웃 사건

```
테스트 실행: npm run test:backend
결과: 189개 테스트 중 대부분 타임아웃 (60초)

원인 분석:
1. Generator API가 실제 LLM/ComfyUI 호출 시도
2. Ollama/ComfyUI 연결되지 않음 → 타임아웃
3. Mock 모드 없어서 모든 테스트가 실제 생성 시도
4. 동시에 많은 요청 → 네트워크 부하
```

### 근본 원인: 직접 호출 구조

```python
# Agent 코드 (Before)
class CopywriterAgent:
    def generate(self, brief):
        # ❌ 문제 1: 직접 Ollama 호출
        import ollama
        response = ollama.generate(
            model="qwen2.5:14b",  # ❌ 문제 2: 모델명 하드코딩
            prompt=f"Generate copy for {brief}"
        )
        return response
```

**문제점**:
1. **테스트 불가능**: Mock 처리 어려움
2. **확장 불가능**: Ollama → GPT 변경 시 모든 Agent 수정 필요
3. **일관성 없음**: Agent마다 다른 에러 처리
4. **모델 관리 어려움**: 모델명이 코드 곳곳에 하드코딩

---

## 고려한 대안들 (Options)

### 대안 1: 현상 유지 (직접 호출)

```python
# Agent가 직접 Ollama/ComfyUI 호출
Agent → Ollama
     → ComfyUI
```

**장점**:
- 구현 간단
- 레이턴시 낮음 (중간 레이어 없음)

**단점**:
- ❌ Mock 모드 구현 어려움
- ❌ Provider 교체 시 모든 Agent 수정
- ❌ 에러 처리 일관성 없음
- ❌ 비용/사용량 추적 어려움

### 대안 2: Agent 내부에 Mock 로직

```python
class CopywriterAgent:
    def generate(self, brief):
        if settings.GENERATOR_MODE == "mock":
            return self._get_mock_response()
        else:
            return ollama.generate(...)
```

**장점**:
- Mock/Live 분리 가능

**단점**:
- ❌ 모든 Agent에 중복 코드
- ❌ Provider 교체 시 여전히 모든 Agent 수정
- ❌ Mock 응답 일관성 관리 어려움

### 대안 3: LLM Service 레이어

```python
# 단일 LLMService 클래스
Agent → LLMService → Ollama
```

**장점**:
- Mock/Live 분리 가능
- 중복 코드 제거

**단점**:
- ❌ Provider 추가 시 LLMService 수정 필요
- ❌ Image/Video/Audio는 별도 처리 필요

### 대안 4: Gateway Pattern ✅ (채택)

```python
Agent → LLM Gateway → Router → Provider (Ollama | GPT | Claude)
     → Media Gateway → Router → Provider (ComfyUI | DALL·E)
```

**장점**:
- ✅ Mock/Live 분리 쉬움
- ✅ Provider 교체 시 Agent 코드 수정 불필요
- ✅ API Contract 불변
- ✅ 비용/사용량 추적 쉬움
- ✅ 에러 처리 통일
- ✅ 확장성 (GPT/Claude/DALL·E/Veo3 추가 용이)

**단점**:
- ⚠️ 초기 구현 복잡도 높음
- ⚠️ 레이턴시 약간 증가 (무시할 수준)

---

## 결정 (Decision)

### 최종 결정: Gateway Pattern 채택

**구조**:
```
4개 Gateway:
1. LLM Gateway - 텍스트/JSON 생성
2. Image Gateway - 이미지 생성/수정
3. Video Gateway - 영상 합성
4. Audio Gateway - TTS/음악 생성

각 Gateway:
- API Layer: 요청 검증, Mock/Live 분기, 로깅
- Router Layer: role/task 기반 Provider 선택
- Provider Layer: 실제 모델 호출 (Ollama, GPT, ComfyUI 등)
```

**Phase별 구현**:
```
Phase 1 (5일):
- LLM Gateway (Ollama만)
- Image Gateway (ComfyUI만)
- Video Gateway (ffmpeg만)
- Audio Gateway (구조만)

Phase 2-4 (향후):
- GPT / Claude / Gemini Provider 추가
- DALL·E / Nanobanana Provider 추가
- Veo3 Provider 추가
- ElevenLabs / Suno Provider 추가
```

---

## 근거 (Rationale)

### 1. 테스트 가능성

**Before (직접 호출)**:
```python
# 테스트 시 실제 Ollama 필요
def test_copywriter():
    agent = CopywriterAgent()
    result = agent.generate(brief)  # ← Ollama 호출
    # Ollama 없으면 실패
```

**After (Gateway)**:
```python
# Mock Gateway로 테스트
def test_copywriter():
    with mock_llm_gateway():
        agent = CopywriterAgent()
        result = agent.generate(brief)  # ← Mock 응답
        # 항상 성공, 30초 내
```

### 2. 확장성

**Ollama → GPT 변경 시**:

```python
# Agent 코드 (Before)
# ❌ 모든 Agent 파일 수정 필요
class CopywriterAgent:
    def generate(self, brief):
        # import ollama  ← 제거
        import openai  ← 추가
        response = openai.ChatCompletion.create(...)  ← 변경
```

```python
# Agent 코드 (After)
# ✅ 수정 불필요
class CopywriterAgent:
    def generate(self, brief):
        response = await self.llm_client.generate(
            role="copywriter",
            task="product_detail",
            payload={"brief": brief}
        )
        # Gateway 내부에서 Ollama → GPT 라우팅
```

### 3. 일관성

**에러 처리 통일**:
```python
# Gateway 표준 에러 포맷
{
  "error": {
    "code": "LLM_TIMEOUT",
    "message": "LLM 호출 시간 초과",
    "provider": "ollama",
    "model": "qwen2.5:14b"
  }
}

# 모든 Agent가 동일한 에러 포맷 받음
```

### 4. 비용 관리

**사용량 자동 추적**:
```python
# Gateway에서 자동 로깅
{
  "request_id": "req_001",
  "provider": "openai",
  "model": "gpt-4o",
  "usage": {
    "prompt_tokens": 500,
    "completion_tokens": 300,
    "total_tokens": 800,
    "estimated_cost_usd": 0.024
  }
}

# 월별 리포트 생성 가능
```

---

## 결과 (Consequences)

### 긍정적 효과

1. **테스트 타임아웃 해결**
   - Mock 모드로 189개 테스트 30초 내 완료
   - Live 모드는 E2E 테스트에서만 사용

2. **확장 용이**
   - GPT/Claude/Gemini 추가 시 Agent 코드 수정 불필요
   - `provider_config.yaml` 수정만으로 Provider 활성화

3. **운영 편의**
   - 중앙 집중식 로깅/모니터링
   - 비용 추적 자동화
   - Draft/Final 모드 전환 쉬움

### 부정적 효과 (Trade-offs)

1. **초기 구현 복잡도**
   - Gateway + Router + Provider 3계층 구현 필요
   - 예상 시간: 5일 (vs 직접 호출: 1일)
   - **판단**: 장기적 이득이 더 큼 ✅

2. **레이턴시 증가**
   - Agent → Gateway → Provider (2 hop)
   - 예상 증가: 10-20ms
   - **판단**: 무시할 수준 (전체 3-5초 중 0.02초) ✅

3. **학습 곡선**
   - 새 개발자가 Gateway 구조 이해 필요
   - **대응**: 상세 문서 작성 (ARCH-001, ARCH-002) ✅

---

## 실행 계획

### Phase 1 (5일, B팀)

**목표**: Ollama + ComfyUI 연결

1. LLM Gateway API 구현
2. OllamaProvider 구현
3. Media Gateway (Image) API 구현
4. ComfyUIProvider 구현
5. Mock/Live 모드 분리
6. 6개 Agent 리팩터링

**완료 기준**:
- [ ] `/api/v1/llm/generate` Mock/Live 동작
- [ ] Ollama 연결 성공 (qwen2.5:7b/14b)
- [ ] `/api/v1/media/image/generate` ComfyUI 연결
- [ ] P0 E2E "상품 상세 + 이미지 1장" 성공

### Phase 2-4 (향후)

- Phase 2: ElevenLabs (TTS), Suno (Music)
- Phase 3: OpenAI, Anthropic, Gemini, DALL·E
- Phase 4: Veo3

---

## 검증 지표

### 성공 지표

1. **테스트 속도**
   - Mock 모드: 189개 테스트 30초 이내 ✅ 목표
   - Live 모드: E2E 1개 3분 이내 ✅ 목표

2. **확장성**
   - 새 Provider 추가 시 Agent 코드 수정 0줄 ✅ 목표

3. **안정성**
   - 테스트 성공률 95% 이상 ✅ 목표
   - Gateway 에러율 5% 이하 ✅ 목표

### 모니터링 항목

```yaml
# Prometheus 지표
llm_gateway_requests_total{provider,model,role,task,status}
llm_gateway_latency_ms{provider,model}
llm_gateway_errors_total{provider,code}
media_gateway_requests_total{provider,kind,status}
```

---

## 관련 문서

### 필수 읽기
- [ARCH-002: Gateway Pattern](../architecture/002_GATEWAY_PATTERN.md)
- [SPEC-001: LLM Gateway Spec](../specs/LLM_GATEWAY_SPEC_v1.0.md)

### 배경
- [2025-11-16 LLM 연결 분석 보고서](../reports/2025-11-16_LLM_CONNECTION_ANALYSIS.md)
- [2025-11-15 테스트 타임아웃 분석](../reports/2025-11-15_TEST_TIMEOUT_ANALYSIS.md)

### 다음 결정
- [DEC-002: Ollama First Strategy](./2025-11-16_002_OLLAMA_FIRST.md)

---

**결정자**: A팀 (QA) + PM
**결정일**: 2025-11-16
**다음 리뷰**: Phase 1 완료 후
