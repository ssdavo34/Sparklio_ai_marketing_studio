# ë‹¤ìŒ ì„¸ì…˜ ì‘ì—… ê°€ì´ë“œ (2025-11-20 ì—…ë°ì´íŠ¸)

## ğŸ“Œ í˜„ì¬ ìƒíƒœ ìš”ì•½

### ì™„ë£Œëœ Phase
- âœ… **Phase 1-3**: EditorAgent, MeetingAIAgent êµ¬í˜„ ì™„ë£Œ
- âœ… **Phase 4**: Admin Monitoring Dashboard êµ¬í˜„ ì™„ë£Œ
- âœ… **Phase 5**: Integration Testing & Debugging ì™„ë£Œ
- âœ… **Phase 6**: User-Selected LLM Mode êµ¬í˜„ ì™„ë£Œ

### í˜„ì¬ ë¸Œëœì¹˜
```bash
feature/editor-v2-konva
```

### ì‹œìŠ¤í…œ ìƒíƒœ
- **ë°±ì—”ë“œ**: Mock Modeë¡œ ì •ìƒ ë™ì‘ (`GENERATOR_MODE="mock"`)
- **í”„ë¡ íŠ¸ì—”ë“œ**: LLM Selector UI í†µí•© ì™„ë£Œ
- **í†µí•© í…ŒìŠ¤íŠ¸**: ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ âœ…
- **Git ìƒíƒœ**: Phase 6 ë³€ê²½ì‚¬í•­ ì»¤ë°‹ ëŒ€ê¸° ì¤‘

---

## ğŸ”„ Git ë™ê¸°í™” ë°©ë²•

### 1. í˜„ì¬ ë³€ê²½ì‚¬í•­ í™•ì¸
```powershell
cd k:\sparklio_ai_marketing_studio
git status
```

### 2. Phase 6 ë³€ê²½ì‚¬í•­ ì»¤ë°‹
```powershell
# ëª¨ë“  ë³€ê²½ì‚¬í•­ ìŠ¤í…Œì´ì§•
git add .

# ì»¤ë°‹ ë©”ì‹œì§€ ì‘ì„±
git commit -m "feat: Phase 6 - User-Selected LLM Mode êµ¬í˜„ ì™„ë£Œ

- LLMSelection ìŠ¤í‚¤ë§ˆ ì¶”ê°€ (backend/app/schemas/llm.py)
- LLMGateway ì—…ë°ì´íŠ¸ (Manual/Auto ëª¨ë“œ ì§€ì›, Novita ì œê±°)
- Chat API ë° EditorAgent LLM ì„ íƒ ê¸°ëŠ¥ í†µí•©
- Zustand LLM Store ë° LLMSelector ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
- ChatInterfaceì— LLM ì„ íƒ UI í†µí•©
- useSparkChat Hookì—ì„œ LLM ì„ íƒ ì „ì†¡ êµ¬í˜„

Backend: 4 files modified, 1 file added
Frontend: 3 files modified, 2 files added"

# ì›ê²© ì €ì¥ì†Œì— í‘¸ì‹œ
git push origin feature/editor-v2-konva
```

### 3. ì¶©ëŒ ë°œìƒ ì‹œ
```powershell
# ì›ê²© ë³€ê²½ì‚¬í•­ ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
git pull origin feature/editor-v2-konva --rebase

# ì¶©ëŒ í•´ê²° í›„
git add .
git rebase --continue
git push origin feature/editor-v2-konva
```

---

## ğŸš€ Phase 7 ì‘ì—… ì§€ì¹¨

### ëª©í‘œ: Live LLM Provider í™œì„±í™” ë° Manual Mode ê²€ì¦

#### 1ë‹¨ê³„: Live LLM Provider ì„¤ì • (ìš°ì„ ìˆœìœ„: ë†’ìŒ)

##### Option A: OpenAI (GPT-4o) í™œì„±í™”
```bash
# .env íŒŒì¼ ìˆ˜ì •
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_DEFAULT_MODEL=gpt-4o-mini
OPENAI_TIMEOUT=60
```

**í…ŒìŠ¤íŠ¸ ë°©ë²•**:
1. ë°±ì—”ë“œ ì¬ì‹œì‘ (Mock Mode í•´ì œ)
   ```powershell
   cd backend
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```
2. ë¸Œë¼ìš°ì €ì—ì„œ Spark Chat ì ‘ì†
3. LLM Modeë¥¼ "Manual Selection"ìœ¼ë¡œ ë³€ê²½
4. Text LLMì„ "GPT-4o"ë¡œ ì„ íƒ
5. ë©”ì‹œì§€ ì „ì†¡ í›„ ì‘ë‹µ í™•ì¸

##### Option B: Gemini (2.5 Flash) í™œì„±í™”
```bash
# .env íŒŒì¼ ìˆ˜ì •
GOOGLE_API_KEY=your-gemini-api-key-here
GEMINI_TEXT_MODEL=gemini-2.5-flash
GEMINI_TIMEOUT=60
```

**í…ŒìŠ¤íŠ¸ ë°©ë²•**: OpenAIì™€ ë™ì¼ (Text LLMì„ "Gemini 2.5 Flash"ë¡œ ì„ íƒ)

##### Option C: Ollama (ë¡œì»¬) í™œì„±í™”
```bash
# Ollama ì„œë²„ ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„)
ollama serve

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull qwen2.5:7b
ollama pull llama3.1:8b
```

**í…ŒìŠ¤íŠ¸ ë°©ë²•**: OpenAIì™€ ë™ì¼ (Text LLMì„ "Ollama (Local)"ë¡œ ì„ íƒ)

#### 2ë‹¨ê³„: Manual Mode ë¸Œë¼ìš°ì € í…ŒìŠ¤íŠ¸

##### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: Auto â†’ Manual ì „í™˜
1. Spark Chat ì ‘ì†
2. ì´ˆê¸° ìƒíƒœ: "Auto (Smart Router)" í™•ì¸
3. "Manual Selection"ìœ¼ë¡œ ë³€ê²½
4. Text LLM ë“œë¡­ë‹¤ìš´ í‘œì‹œ í™•ì¸
5. ê° Provider ì„ íƒ í›„ ë©”ì‹œì§€ ì „ì†¡
6. ì‘ë‹µ ì •ìƒ ìˆ˜ì‹  í™•ì¸

##### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 2: Provider ë³€ê²½
1. Manual Modeì—ì„œ "GPT-4o" ì„ íƒ â†’ ë©”ì‹œì§€ ì „ì†¡
2. "Gemini 2.5 Flash"ë¡œ ë³€ê²½ â†’ ë©”ì‹œì§€ ì „ì†¡
3. "Ollama (Local)"ë¡œ ë³€ê²½ â†’ ë©”ì‹œì§€ ì „ì†¡
4. ê° Providerë³„ ì‘ë‹µ ì°¨ì´ í™•ì¸

##### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 3: ì—ëŸ¬ ì²˜ë¦¬
1. API í‚¤ ì—†ëŠ” Provider ì„ íƒ (ì˜ˆ: Anthropic)
2. ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
3. Mock Providerë¡œ Fallback ë˜ëŠ”ì§€ í™•ì¸

#### 3ë‹¨ê³„: Image/Video Engine êµ¬í˜„ (ì„ íƒ)

**í˜„ì¬ ìƒíƒœ**: UIë§Œ êµ¬í˜„ë¨, ì‹¤ì œ Provider ë¯¸êµ¬í˜„

**ì‘ì—… í•„ìš”ì‚¬í•­**:
1. `backend/app/services/llm/providers/comfyui_image.py` ìƒì„±
2. `backend/app/services/llm/providers/nanobanana.py` ìƒì„±
3. `LLMGateway`ì— Image/Video Provider ì´ˆê¸°í™” ì¶”ê°€
4. `_provider_from_name()`ì— ë§¤í•‘ ì¶”ê°€

**ì°¸ê³  íŒŒì¼**:
- `backend/app/services/llm/providers/base.py` (Provider ì¸í„°í˜ì´ìŠ¤)
- `backend/app/services/llm/providers/mock.py` (êµ¬í˜„ ì˜ˆì‹œ)

---

## ğŸ› ì•Œë ¤ì§„ ì´ìŠˆ ë° í•´ê²° ë°©ë²•

### ì´ìŠˆ 1: "Ollama API error: 404"
**ì›ì¸**: Ollamaì— ìš”ì²­í•œ ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ  
**í•´ê²°**:
```bash
ollama pull gpt-4o  # ì‹¤íŒ¨ (OllamaëŠ” GPT ëª¨ë¸ ë¯¸ì§€ì›)
ollama pull qwen2.5:7b  # ì„±ê³µ
```
**ê¶Œì¥**: Manual Modeì—ì„œ Ollama ì„ íƒ ì‹œ `qwen2.5:7b` ë˜ëŠ” `llama3.1:8b` ì‚¬ìš©

### ì´ìŠˆ 2: "Provider 'novita' not found"
**ìƒíƒœ**: âœ… í•´ê²°ë¨ (Phase 6ì—ì„œ Novita ì™„ì „ ì œê±°)

### ì´ìŠˆ 3: Redis ì—°ê²° ì‹¤íŒ¨
**ìƒíƒœ**: âš ï¸ ë‚®ì€ ìš°ì„ ìˆœìœ„  
**í˜„ì¬ ë™ì‘**: `NO-REDIS` ëª¨ë“œë¡œ ì •ìƒ ë™ì‘ ì¤‘  
**í•´ê²° ë°©ë²•** (ì„ íƒ):
```bash
# Redis ì„œë²„ ì„¤ì¹˜ ë° ì‹¤í–‰
# Windows: https://github.com/microsoftarchive/redis/releases
redis-server
```

---

## ğŸ“‚ ì¤‘ìš” íŒŒì¼ ìœ„ì¹˜

### Backend
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ llm.py                    # LLMSelection ìŠ¤í‚¤ë§ˆ
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ gateway.py            # LLM Gateway (Manual/Auto ë¡œì§)
â”‚   â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚   â”‚       â”œâ”€â”€ base.py           # Provider ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚       â”œâ”€â”€ mock.py           # Mock Provider
â”‚   â”‚   â”‚       â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â”‚       â”œâ”€â”€ gemini_provider.py
â”‚   â”‚   â”‚       â””â”€â”€ ollama.py
â”‚   â”‚   â””â”€â”€ agents/
â”‚   â”‚       â””â”€â”€ editor.py             # EditorAgent (LLM ì„ íƒ ì „ë‹¬)
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ v1/
â”‚           â””â”€â”€ chat.py               # Chat API (LLM ì„ íƒ ìˆ˜ì‹ )
â””â”€â”€ tests/
    â””â”€â”€ test_integration_flow.py      # í†µí•© í…ŒìŠ¤íŠ¸
```

### Frontend
```
frontend/
â”œâ”€â”€ store/
â”‚   â””â”€â”€ llmStore.ts                   # Zustand LLM Store
â”œâ”€â”€ components/
â”‚   â””â”€â”€ spark/
â”‚       â”œâ”€â”€ LLMSelector.tsx           # LLM ì„ íƒ UI
â”‚       â””â”€â”€ ChatInterface.tsx         # Spark Chat (LLM Selector í†µí•©)
â””â”€â”€ hooks/
    â””â”€â”€ useSparkChat.ts               # Chat Hook (LLM ì„ íƒ ì „ì†¡)
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë°©ë²•

### 1. í†µí•© í…ŒìŠ¤íŠ¸ (Mock Mode)
```powershell
cd backend
$env:GENERATOR_MODE="mock"
python -m pytest tests/test_integration_flow.py -v
```

**ì˜ˆìƒ ê²°ê³¼**: ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ âœ…

### 2. ë¸Œë¼ìš°ì € í…ŒìŠ¤íŠ¸
```powershell
# Terminal 1: Backend (Mock Mode)
cd backend
$env:GENERATOR_MODE="mock"
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Frontend
cd frontend
npm run dev
```

**ì ‘ì†**: `http://localhost:3000/studio` â†’ Spark Chat íƒ­

### 3. Live Mode í…ŒìŠ¤íŠ¸ (API í‚¤ ì„¤ì • í›„)
```powershell
# Terminal 1: Backend (Live Mode)
cd backend
# GENERATOR_MODE í™˜ê²½ë³€ìˆ˜ ì œê±° ë˜ëŠ” "live"ë¡œ ì„¤ì •
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Frontend
cd frontend
npm run dev
```

---

## ğŸ“‹ Phase 7 ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•„ìˆ˜ ì‘ì—…
- [ ] OpenAI API í‚¤ ì„¤ì • ë° GPT-4o í…ŒìŠ¤íŠ¸
- [ ] Gemini API í‚¤ ì„¤ì • ë° Gemini 2.5 Flash í…ŒìŠ¤íŠ¸
- [ ] Manual Mode ë¸Œë¼ìš°ì € í…ŒìŠ¤íŠ¸ (Auto â†” Manual ì „í™˜)
- [ ] ê° Provider ì„ íƒ ì‹œ ì •ìƒ ë™ì‘ í™•ì¸
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° Fallback ë¡œì§ ê²€ì¦

### ì„ íƒ ì‘ì—…
- [ ] Ollama ë¡œì»¬ ì„œë²„ ì„¤ì • ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [ ] ComfyUI Image Provider êµ¬í˜„
- [ ] Nanobanana Provider êµ¬í˜„
- [ ] Redis ì„œë²„ ì„¤ì • (ë‚®ì€ ìš°ì„ ìˆœìœ„)

### ë¬¸ì„œí™”
- [ ] Live Mode í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡
- [ ] Providerë³„ ì„±ëŠ¥ ë¹„êµ (ì‘ë‹µ ì‹œê°„, í’ˆì§ˆ)
- [ ] Phase 7 ì™„ë£Œ ë³´ê³ ì„œ ì‘ì„±

---

## ğŸ’¡ ì‘ì—… íŒ

### 1. í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬
`.env` íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ API í‚¤ ê´€ë¦¬:
```bash
# backend/.env
GENERATOR_MODE=live  # or "mock"
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...
ANTHROPIC_API_KEY=...
```

### 2. ë””ë²„ê¹…
ë°±ì—”ë“œ ë¡œê·¸ í™•ì¸:
```powershell
# backend/app/services/llm/gateway.py ì—ì„œ ë¡œê·¸ ì¶œë ¥
# "LLM Generate: role=..., provider=..., model=..." í™•ì¸
```

í”„ë¡ íŠ¸ì—”ë“œ ì½˜ì†” í™•ì¸:
```javascript
// ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬ â†’ Console
// Network íƒ­ì—ì„œ /api/v1/chat/analyze ìš”ì²­ í™•ì¸
```

### 3. Mock Mode â†” Live Mode ì „í™˜
```powershell
# Mock Mode
$env:GENERATOR_MODE="mock"

# Live Mode (í™˜ê²½ë³€ìˆ˜ ì œê±°)
Remove-Item Env:GENERATOR_MODE
```

---

## ğŸ“ ë¬¸ì œ ë°œìƒ ì‹œ

### 1. ë°±ì—”ë“œ ì—ëŸ¬
- ë¡œê·¸ í™•ì¸: í„°ë¯¸ë„ ì¶œë ¥ ë˜ëŠ” `backend/logs/` í™•ì¸
- `debug_log.txt` íŒŒì¼ í™•ì¸ (Chat API ë””ë²„ê·¸ ë¡œê·¸)

### 2. í”„ë¡ íŠ¸ì—”ë“œ ì—ëŸ¬
- ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬ â†’ Console í™•ì¸
- Network íƒ­ì—ì„œ API ìš”ì²­/ì‘ë‹µ í™•ì¸

### 3. Provider ì—°ê²° ì‹¤íŒ¨
- API í‚¤ í™•ì¸ (`.env` íŒŒì¼)
- Provider ì´ˆê¸°í™” ë¡œê·¸ í™•ì¸ ("Initializing ... Provider")
- Mock Providerë¡œ Fallback ë˜ëŠ”ì§€ í™•ì¸

---

## ğŸ¯ ë‹¤ìŒ ì„¸ì…˜ ëª©í‘œ

**Phase 7: Live LLM Provider í™œì„±í™” ë° ê²€ì¦**

1. âœ… OpenAI/Gemini ì¤‘ 1ê°œ ì´ìƒ í™œì„±í™”
2. âœ… Manual Mode ë¸Œë¼ìš°ì € í…ŒìŠ¤íŠ¸ ì™„ë£Œ
3. âœ… ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦
4. âœ… Phase 7 ì™„ë£Œ ë³´ê³ ì„œ ì‘ì„±

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 2-3ì‹œê°„

---

**ì‘ì„±ì¼**: 2025-11-20  
**ì‘ì„±ì**: AI Agent (Claude)  
**ë‹¤ìŒ ì‘ì—…ì**: Phase 7 êµ¬í˜„ ë‹´ë‹¹ì
