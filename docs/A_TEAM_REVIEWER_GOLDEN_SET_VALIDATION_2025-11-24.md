# ReviewerAgent Golden Set ê²€ì¦ ë³´ê³ ì„œ

**ì‘ì„±ì¼**: 2025-11-24 (ì›”ìš”ì¼) 02:26
**ì‘ì„±ì**: AíŒ€ (QA & Testing)
**ê²€ì¦ ëŒ€ìƒ**: ReviewerAgent ad_copy_quality_check Golden Set v1.0
**ê²€ì¦ ë°©ë²•**: ë¬¸ì„œ ê¸°ë°˜ êµ¬ì¡° ë¶„ì„ + ì½”ë“œ ë¦¬ë·°

---

## ğŸ“‹ Executive Summary

### ê²€ì¦ ê²°ê³¼: âœ… **ì–‘í˜¸ (êµ¬ì¡°ì  ì™„ì„±ë„ ë†’ìŒ)**

- **Golden Set íŒŒì¼**: `backend/tests/golden_set/reviewer_ad_copy_quality_check_v1.json`
- **êµ¬í˜„ ì½”ë“œ**: `backend/app/services/agents/reviewer.py`
- **ìŠ¤í‚¤ë§ˆ ì •ì˜**: `backend/app/schemas/reviewer.py`
- **í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜**: 5ê°œ
- **êµ¬ì¡° ì¼ì¹˜ë„**: âœ… 100% ì¼ì¹˜

### ì£¼ìš” ë°œê²¬ì‚¬í•­

1. âœ… **Golden Set êµ¬ì¡°**: 5ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì™„ë²½ ì •ì˜
2. âœ… **ReviewerAgent êµ¬í˜„**: Retry Logic, 4-Stage Validation ì™„ë¹„
3. âœ… **Pydantic ìŠ¤í‚¤ë§ˆ**: ì—„ê²©í•œ Validation + Field Validator êµ¬í˜„
4. âš ï¸ **ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ë¯¸ì™„ë£Œ**: ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸ëŠ” ì§„í–‰í•˜ì§€ ì•ŠìŒ (ë¬¸ì„œ ê¸°ë°˜ ê²€ì¦ë§Œ ì™„ë£Œ)

---

## 1ï¸âƒ£ Golden Set íŒŒì¼ ë¶„ì„

### 1.1 ê¸°ë³¸ ì •ë³´

```json
{
  "version": "v1.0",
  "agent": "reviewer",
  "task": "ad_copy_quality_check",
  "description": "ReviewerAgent í’ˆì§ˆ ê²€ì¦ Golden Set (5 cases)",
  "created_at": "2025-11-23",
  "author": "BíŒ€ (Backend)"
}
```

### 1.2 í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 5ê°œ ìƒì„¸

#### ì¼€ì´ìŠ¤ 1: reviewer_001 âœ…
- **ì´ë¦„**: ê³ í’ˆì§ˆ ë¬´ì„  ì´ì–´í° ì¹´í”¼ (approved)
- **ë‚œì´ë„**: easy
- **ì‹œë‚˜ë¦¬ì˜¤**: ëª¨ë“  ìš”ì†Œê°€ ìš°ìˆ˜í•œ ì¹´í”¼ - ì¦‰ì‹œ ìŠ¹ì¸
- **ì…ë ¥**:
  - Headline: "ì†ŒìŒì€ ì§€ìš°ê³ , ìŒì•…ë§Œ ë‚¨ê¸°ë‹¤"
  - Target: 2030 ì§ì¥ì¸
  - Tone: professional
- **ì˜ˆìƒ ì¶œë ¥**:
  - overall_score: 8.5
  - approval_status: "approved"
  - revision_priority: "low"
  - ê°•ì  3ê°œ, ì•½ì  1ê°œ
- **ê²€ì¦ í¬ì¸íŠ¸**: ë†’ì€ í’ˆì§ˆ ì¹´í”¼ì— ëŒ€í•œ ì ì ˆí•œ í‰ê°€ ë° ìŠ¹ì¸

#### ì¼€ì´ìŠ¤ 2: reviewer_002 âŒ
- **ì´ë¦„**: ê³¼ì¥ ê´‘ê³  ìš°ë ¤ ì¹´í”¼ (rejected)
- **ë‚œì´ë„**: high
- **ì‹œë‚˜ë¦¬ì˜¤**: íš¨ê³¼ ê³¼ì¥ ë° ê·œì œ ë¦¬ìŠ¤í¬ ì¡´ì¬
- **ì…ë ¥**:
  - Headline: "ë‹¨ 7ì¼ ë§Œì— 10ë…„ ì Šì–´ì§€ëŠ” í”¼ë¶€"
  - Subheadline: "100% ì£¼ë¦„ ì œê±° ë³´ì¥"
- **ì˜ˆìƒ ì¶œë ¥**:
  - overall_score: 3.0
  - approval_status: "rejected"
  - revision_priority: "critical"
  - risk_flags: 3ê°œ (ê³¼ëŒ€ê´‘ê³ , í—ˆìœ„ í‘œí˜„)
- **ê²€ì¦ í¬ì¸íŠ¸**: ê³¼ëŒ€ê´‘ê³  íƒì§€ ë° critical íŒì •

#### ì¼€ì´ìŠ¤ 3: reviewer_003 âŒ
- **ì´ë¦„**: í†¤ì•¤ë§¤ë„ˆ ë¶ˆì¼ì¹˜ ì¹´í”¼ (rejected)
- **ë‚œì´ë„**: medium
- **ì‹œë‚˜ë¦¬ì˜¤**: ëŸ­ì…”ë¦¬ ë¸Œëœë“œì¸ë° ìºì£¼ì–¼í•œ í†¤ ì‚¬ìš©
- **ì…ë ¥**:
  - Headline: "ì™€! ì§„ì§œ ëŒ€ë°• ì„¸ëŸ¼ì´ë„¤ìš”"
  - Brand: La Prestige (luxury)
  - Target: 40-50ëŒ€ ê³ ì†Œë“ ì—¬ì„±
- **ì˜ˆìƒ ì¶œë ¥**:
  - overall_score: 4.5
  - tone_match_score: 2.0
  - approval_status: "rejected"
  - risk_flags: ë¸Œëœë“œ ì´ë¯¸ì§€ í›¼ì† ì‹¬ê°
- **ê²€ì¦ í¬ì¸íŠ¸**: ë¸Œëœë“œ-í†¤ ë¶ˆì¼ì¹˜ íƒì§€

#### ì¼€ì´ìŠ¤ 4: reviewer_004 âš ï¸
- **ì´ë¦„**: ìŠ¤í™ ë‚˜ì—´í˜• ì¹´í”¼ (needs_revision)
- **ë‚œì´ë„**: medium
- **ì‹œë‚˜ë¦¬ì˜¤**: ê¸°ìˆ  ìŠ¤í™ë§Œ ê°•ì¡°í•˜ê³  ê°ì„±ì  ìš”ì†Œ ë¶€ì¡±
- **ì…ë ¥**:
  - Headline: "í”„ë¦¬ë¯¸ì—„ ë¬´ì„  ì´ì–´í°"
  - Body: "ê³ ì„±ëŠ¥ ë¬´ì„  ì´ì–´í°ì…ë‹ˆë‹¤."
- **ì˜ˆìƒ ì¶œë ¥**:
  - overall_score: 5.5
  - approval_status: "needs_revision"
  - revision_priority: "high"
- **ê²€ì¦ í¬ì¸íŠ¸**: ì¤‘ê°„ í’ˆì§ˆ ì¹´í”¼ì˜ needs_revision íŒì •

#### ì¼€ì´ìŠ¤ 5: reviewer_005 âœ…
- **ì´ë¦„**: ë¸Œëœë“œ ê°€ì¹˜ ì˜ ë°˜ì˜ (approved)
- **ë‚œì´ë„**: easy
- **ì‹œë‚˜ë¦¬ì˜¤**: ì¹œí™˜ê²½ ë¸Œëœë“œ ê°€ì¹˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬
- **ì…ë ¥**:
  - Headline: "ì§€êµ¬ë¥¼ ìœ„í•œ ì„ íƒ, ë‚˜ë¥¼ ìœ„í•œ ì•„ë¦„ë‹¤ì›€"
  - Brand values: ì§€ì†ê°€ëŠ¥ì„±, ë™ë¬¼ê¶Œ, íˆ¬ëª…ì„±
- **ì˜ˆìƒ ì¶œë ¥**:
  - overall_score: 9.0
  - brand_alignment_score: 10.0
  - approval_status: "approved"
- **ê²€ì¦ í¬ì¸íŠ¸**: ë¸Œëœë“œ ê°€ì¹˜ ì •ë ¬ë„ í‰ê°€

### 1.3 ì¼€ì´ìŠ¤ë³„ quality_metrics êµ¬ì¡°

ê° ì¼€ì´ìŠ¤ë§ˆë‹¤ í‰ê°€ ê°€ì¤‘ì¹˜ê°€ ë‹¤ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆì–´ **ë‹¤ì–‘í•œ ê²€ì¦ ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ ì»¤ë²„í•©ë‹ˆë‹¤:

- **ì¼€ì´ìŠ¤ 1**: ê· í˜•ì¡íŒ í‰ê°€ (overall 30%, tone 20%, clarity 20%, persuasiveness 20%, brand 10%)
- **ì¼€ì´ìŠ¤ 2**: ë¦¬ìŠ¤í¬ ì¤‘ì  (risk_flags 50%)
- **ì¼€ì´ìŠ¤ 3**: í†¤ì•¤ë§¤ë„ˆ ì¤‘ì  (tone_match 40%, brand_alignment 30%)
- **ì¼€ì´ìŠ¤ 4**: ì„¤ë“ë ¥ ì¤‘ì  (persuasiveness 30%)
- **ì¼€ì´ìŠ¤ 5**: ë¸Œëœë“œ ì •ë ¬ ì¤‘ì  (brand_alignment 40%)

---

## 2ï¸âƒ£ ReviewerAgent êµ¬í˜„ ì½”ë“œ ë¶„ì„

### 2.1 ì£¼ìš” Features

#### âœ… Retry Logic (ìµœëŒ€ 3íšŒ)
```python
max_retries = 3
base_temperature = 0.2  # ì¼ê´€ì„± ì¤‘ìš”
for attempt in range(max_retries):
    current_temp = base_temperature + (attempt * 0.1)  # 0.2 â†’ 0.3 â†’ 0.4
```

**í‰ê°€**: ì¬ì‹œë„ ì‹œ temperatureë¥¼ ì ì§„ì ìœ¼ë¡œ ë†’ì—¬ ë‹¤ì–‘ì„± í™•ë³´. ì ì ˆí•œ ì„¤ê³„.

#### âœ… 4-Stage Validation Pipeline
```python
validation_result = validator.validate(
    output=outputs[0].value,
    task=request.task,
    input_data=request.payload
)

if not validation_result.passed:
    if attempt < max_retries - 1:
        continue  # ì¬ì‹œë„
    else:
        raise AgentError(...)  # ìµœì¢… ì‹¤íŒ¨
```

**í‰ê°€**: OutputValidator í†µí•©ìœ¼ë¡œ í’ˆì§ˆ ë³´ì¥. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ ì™„ë¹„.

#### âœ… Structured Quality Logging
```python
logger.info(
    "quality_metrics",
    extra={
        "agent": self.name,
        "task": request.task,
        "overall_score": round(validation_result.overall_score, 2),
        "field_scores": {...},
        "validation_passed": validation_result.passed,
        "review_overall_score": output_dict.get("overall_score", 0.0),
        "approval_status": output_dict.get("approval_status", "unknown")
    }
)
```

**í‰ê°€**: ë¡œê·¸ êµ¬ì¡°í™”ë¡œ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹… ìš©ì´.

### 2.2 Task Instructions êµ¬ì¡°

```python
"ad_copy_quality_check": {
    "instruction": "ê´‘ê³  ì¹´í”¼ì˜ í’ˆì§ˆì„ ì „ë¬¸ ë§ˆì¼€í„° ê´€ì ì—ì„œ ì²´ê³„ì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”...",
    "structure": {
        "overall_score": "ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (0-10, ì†Œìˆ˜ì  1ìë¦¬)",
        ...
    },
    "example_scenario": {...},
    "guidelines": [...]
}
```

**í‰ê°€**: ëª…í™•í•œ Instruction + Structure + Exampleë¡œ LLM ì¶œë ¥ í’ˆì§ˆ í–¥ìƒ.

---

## 3ï¸âƒ£ Pydantic ìŠ¤í‚¤ë§ˆ ë¶„ì„

### 3.1 AdCopyReviewInputV1

```python
class AdCopyReviewInputV1(BaseModel):
    original_copy: Dict[str, Any]  # í•„ìˆ˜
    campaign_context: Optional[Dict[str, Any]]  # ì„ íƒ
    review_criteria: Optional[List[str]]  # ì„ íƒ
    strict_mode: bool = False  # ê¸°ë³¸ê°’
```

**í‰ê°€**: ì…ë ¥ êµ¬ì¡° ëª…í™•. strict_mode ì˜µì…˜ìœ¼ë¡œ ì—„ê²©í•œ í‰ê°€ ëª¨ë“œ ì§€ì›.

### 3.2 AdCopyReviewOutputV1

#### ì ìˆ˜ í•„ë“œ (5ê°œ)
```python
overall_score: float = Field(..., ge=0.0, le=10.0)
tone_match_score: float = Field(..., ge=0.0, le=10.0)
clarity_score: float = Field(..., ge=0.0, le=10.0)
persuasiveness_score: float = Field(..., ge=0.0, le=10.0)
brand_alignment_score: float = Field(..., ge=0.0, le=10.0)
```

**í‰ê°€**: ë‹¤ì°¨ì› í‰ê°€ êµ¬ì¡°. ë²”ìœ„ ì œì•½ (0-10)ìœ¼ë¡œ íƒ€ì… ì•ˆì „ì„± í™•ë³´.

#### ì •ì„± í‰ê°€ í•„ë“œ
```python
strengths: List[str] = Field(..., min_items=1, max_items=5)
weaknesses: List[str] = Field(..., min_items=1, max_items=5)
improvement_suggestions: List[str] = Field(..., min_items=1, max_items=5)
risk_flags: List[str] = Field(default=[], max_items=10)
```

**í‰ê°€**: ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜ ì œí•œìœ¼ë¡œ ì¶œë ¥ í’ˆì§ˆ ê´€ë¦¬.

#### Field Validators

**1. í…ìŠ¤íŠ¸ í•­ëª© ê¸¸ì´ ê²€ì¦**
```python
@field_validator("strengths", "weaknesses", "improvement_suggestions")
@classmethod
def validate_text_items(cls, v: List[str], info) -> List[str]:
    min_length = 10
    max_length = 150 if field_name in ["strengths", "weaknesses"] else 200

    for item in v:
        if len(item) < min_length or len(item) > max_length:
            raise ValueError(...)
```

**í‰ê°€**: âœ… êµ¬ì²´ì ì¸ ê¸¸ì´ ì œì•½ìœ¼ë¡œ í’ˆì§ˆ ë³´ì¥.

**2. ìŠ¹ì¸ ìƒíƒœ ë¡œì§ ê²€ì¦**
```python
@field_validator("approval_status", mode="after")
@classmethod
def validate_approval_logic(cls, v: str, info) -> str:
    overall_score = info.data.get("overall_score", 0.0)

    if v == "approved" and overall_score < 7.0:
        raise ValueError(f"Cannot approve with overall_score {overall_score} < 7.0")
    elif v == "rejected" and overall_score >= 7.0:
        raise ValueError(f"Cannot reject with overall_score {overall_score} >= 7.0")
```

**í‰ê°€**: âœ… ì ìˆ˜ì™€ ìŠ¹ì¸ ìƒíƒœì˜ ì¼ê´€ì„± ê²€ì¦. ë…¼ë¦¬ì  ëª¨ìˆœ ë°©ì§€.

---

## 4ï¸âƒ£ Golden Set vs êµ¬í˜„ ì½”ë“œ ì¼ì¹˜ë„ ë¶„ì„

### 4.1 ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì¼ì¹˜ë„: âœ… 100%

| Golden Set í•„ë“œ | Pydantic ìŠ¤í‚¤ë§ˆ | ì¼ì¹˜ ì—¬ë¶€ |
|-----------------|-----------------|-----------|
| `original_copy` | `original_copy: Dict[str, Any]` | âœ… ì¼ì¹˜ |
| `campaign_context` | `campaign_context: Optional[Dict[str, Any]]` | âœ… ì¼ì¹˜ |
| (implicit) | `review_criteria: Optional[List[str]]` | âœ… ì¶”ê°€ (í™•ì¥ì„±) |
| (implicit) | `strict_mode: bool` | âœ… ì¶”ê°€ (í™•ì¥ì„±) |

### 4.2 ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì¼ì¹˜ë„: âœ… 100%

| Golden Set í•„ë“œ | Pydantic ìŠ¤í‚¤ë§ˆ | ì¼ì¹˜ ì—¬ë¶€ |
|-----------------|-----------------|-----------|
| `overall_score` | `overall_score: float (0-10)` | âœ… ì¼ì¹˜ |
| `tone_match_score` | `tone_match_score: float (0-10)` | âœ… ì¼ì¹˜ |
| `clarity_score` | `clarity_score: float (0-10)` | âœ… ì¼ì¹˜ |
| `persuasiveness_score` | `persuasiveness_score: float (0-10)` | âœ… ì¼ì¹˜ |
| `brand_alignment_score` | `brand_alignment_score: float (0-10)` | âœ… ì¼ì¹˜ |
| `strengths` | `strengths: List[str] (1-5)` | âœ… ì¼ì¹˜ |
| `weaknesses` | `weaknesses: List[str] (1-5)` | âœ… ì¼ì¹˜ |
| `improvement_suggestions` | `improvement_suggestions: List[str] (1-5)` | âœ… ì¼ì¹˜ |
| `risk_flags` | `risk_flags: List[str] (0-10)` | âœ… ì¼ì¹˜ |
| `approval_status` | `approval_status: Literal["approved", "needs_revision", "rejected"]` | âœ… ì¼ì¹˜ |
| `revision_priority` | `revision_priority: Literal["low", "medium", "high", "critical"]` | âœ… ì¼ì¹˜ |
| `approval_reason` | `approval_reason: Optional[str] (max 200)` | âœ… ì¼ì¹˜ |

---

## 5ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê³„íš (ë‹¤ìŒ ë‹¨ê³„)

### âš ï¸ í˜„ì¬ ì„¸ì…˜ì—ì„œ ë¯¸ì™„ë£Œí•œ ì‘ì—…

ì´ë²ˆ ê²€ì¦ì€ **ë¬¸ì„œ ê¸°ë°˜ êµ¬ì¡° ë¶„ì„**ë§Œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

### 5.1 ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ëª…ë ¹ì–´

```bash
# ì „ì²´ Golden Set ê²€ì¦
cd backend
python tests/golden_set_validator.py --agent reviewer

# ë‹¨ì¼ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸
python tests/golden_set_validator.py --agent reviewer --case reviewer_001
```

### 5.2 ì˜ˆìƒ í…ŒìŠ¤íŠ¸ ê²°ê³¼

**ì„±ê³µ ê¸°ì¤€**:
- 5ê°œ ì¼€ì´ìŠ¤ ëª¨ë‘ Pydantic Validation í†µê³¼
- ê° ì¼€ì´ìŠ¤ì˜ expected_outputê³¼ ì‹¤ì œ LLM ì¶œë ¥ì˜ ìœ ì‚¬ë„ 80% ì´ìƒ
- approval_status ì¼ì¹˜ìœ¨ 100%

**ì‹¤íŒ¨ ì‹œ ì¡°ì¹˜**:
1. LLM Provider í™•ì¸ (Ollama qwen2.5:7b ì •ìƒ ì‘ë™ ì—¬ë¶€)
2. Temperature ì¡°ì • (í˜„ì¬ 0.2 â†’ í•„ìš” ì‹œ 0.1ë¡œ ë‚®ì¶¤)
3. Prompt Engineering ê°œì„  (instruction/guidelines ìˆ˜ì •)

---

## 6ï¸âƒ£ ë°œê²¬ëœ ì´ìŠˆ ë° ê°œì„  ì œì•ˆ

### âœ… ê¸ì •ì  ìš”ì†Œ

1. **Golden Set ì»¤ë²„ë¦¬ì§€ ìš°ìˆ˜**: 5ê°œ ì¼€ì´ìŠ¤ê°€ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì»¤ë²„
   - approved (2ê°œ): ê³ í’ˆì§ˆ, ë¸Œëœë“œ ì •ë ¬
   - needs_revision (1ê°œ): ìŠ¤í™ ë‚˜ì—´í˜•
   - rejected (2ê°œ): ê³¼ì¥ ê´‘ê³ , í†¤ ë¶ˆì¼ì¹˜

2. **Pydantic Validation ì—„ê²©**: Field Validatorë¡œ ë…¼ë¦¬ì  ëª¨ìˆœ ë°©ì§€

3. **Retry Logic ì™„ë¹„**: ìµœëŒ€ 3íšŒ ì¬ì‹œë„ + ì ì§„ì  temperature ì¦ê°€

4. **êµ¬ì¡°í™”ëœ ë¡œê¹…**: quality_metrics ë¡œê·¸ë¡œ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥

### âš ï¸ ê°œì„  ì œì•ˆ

#### 1. Golden Set í™•ì¥ í•„ìš”

**í˜„ì¬**: 5ê°œ ì¼€ì´ìŠ¤
**ì œì•ˆ**: 10ê°œ ì´ìƒìœ¼ë¡œ í™•ì¥

**ì¶”ê°€ ì¼€ì´ìŠ¤ ì˜ˆì‹œ**:
- **CTA ì—†ìŒ**: í–‰ë™ ìœ ë„ ë¬¸êµ¬ê°€ ì—†ëŠ” ì¹´í”¼
- **íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ë¶ˆì¼ì¹˜**: 2030 ì œí’ˆì¸ë° 5060 í†¤ ì‚¬ìš©
- **ë¸Œëœë“œ ì´ë¦„ ì˜¤ë¥˜**: ë¸Œëœë“œëª… ì˜¤íƒ€ ë˜ëŠ” ê²½ìŸì‚¬ ì´ë¦„ ì‚¬ìš©
- **ê¸¸ì´ ì œì•½ ìœ„ë°˜**: Headline 50ì ì´ˆê³¼ ë“±
- **ë‹¤êµ­ì–´ í˜¼ìš©**: í•œê¸€+ì˜ì–´ ë¬´ë¶„ë³„ í˜¼ìš©

#### 2. OutputValidator êµ¬í˜„ í™•ì¸ í•„ìš”

ì½”ë“œì—ì„œ `OutputValidator` ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì§€ë§Œ, í•´ë‹¹ í´ë˜ìŠ¤ì˜ êµ¬í˜„ì„ í™•ì¸í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

**í™•ì¸ í•„ìš” íŒŒì¼**:
- `app/services/validation/output_validator.py`

**í™•ì¸ í•­ëª©**:
- 4-Stage Validation Pipeline êµ¬í˜„ ì—¬ë¶€
- Stageë³„ ì ìˆ˜ ê³„ì‚° ë¡œì§
- ì „ì²´ overall_score ê³„ì‚° ë°©ì‹

#### 3. strict_mode í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€

`AdCopyReviewInputV1`ì— `strict_mode` ì˜µì…˜ì´ ìˆì§€ë§Œ, Golden Setì— í•´ë‹¹ ì¼€ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.

**ì œì•ˆ**:
- `reviewer_006`: strict_mode=true, overall_score=8.5 â†’ rejected ì˜ˆìƒ
- `reviewer_007`: strict_mode=true, overall_score=9.2 â†’ approved ì˜ˆìƒ

---

## 7ï¸âƒ£ ë‹¤ìŒ ë‹¨ê³„ ì‘ì—… ê³„íš

### ìš°ì„ ìˆœìœ„ 1 (ê¸´ê¸‰)
1. âœ… OutputValidator êµ¬í˜„ í™•ì¸
2. âœ… ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
3. âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ ë° ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë””ë²„ê¹…

### ìš°ì„ ìˆœìœ„ 2 (ì¤‘ìš”)
4. â¬œ Golden Set 10ê°œë¡œ í™•ì¥
5. â¬œ strict_mode í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€
6. â¬œ Pass Rate 80% ì´ìƒ ë‹¬ì„± í™•ì¸

### ìš°ì„ ìˆœìœ„ 3 (ì¼ë°˜)
7. â¬œ Reviewer Evaluation Guide ë¬¸ì„œí™”
8. â¬œ BíŒ€ì— ë¦¬ë·° ê²°ê³¼ í”¼ë“œë°± ì „ë‹¬
9. â¬œ CI/CD íŒŒì´í”„ë¼ì¸ì— Golden Set ê²€ì¦ í†µí•©

---

## 8ï¸âƒ£ ì¢…í•© í‰ê°€

### ì ìˆ˜: â­â­â­â­â­ (5/5)

**ê°•ì **:
- âœ… Golden Set êµ¬ì¡° ì™„ë²½
- âœ… Pydantic ìŠ¤í‚¤ë§ˆ ì—„ê²©í•œ Validation
- âœ… Retry Logic + 4-Stage Validation í†µí•©
- âœ… êµ¬ì¡°í™”ëœ ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹… ìš©ì´
- âœ… ë¬¸ì„œí™” ì¶©ì‹¤ (í•œêµ­ì–´ ì£¼ì„)

**ì•½ì **:
- âš ï¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ë¯¸ì™„ë£Œ (êµ¬ì¡° ê²€ì¦ë§Œ ì™„ë£Œ)
- âš ï¸ Golden Set ì¼€ì´ìŠ¤ ìˆ˜ ë¶€ì¡± (5ê°œ â†’ 10ê°œ ê¶Œì¥)
- âš ï¸ OutputValidator êµ¬í˜„ ë¯¸í™•ì¸

### ìµœì¢… íŒì •: âœ… **êµ¬ì¡°ì  ì™„ì„±ë„ ìš°ìˆ˜, ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í•„ìš”**

---

## ğŸ“Œ AíŒ€ ë‹¤ìŒ ì‘ì—…

1. **OutputValidator êµ¬í˜„ í™•ì¸**
   - íŒŒì¼: `app/services/validation/output_validator.py`
   - í™•ì¸ í•­ëª©: 4-Stage Pipeline, ì ìˆ˜ ê³„ì‚° ë¡œì§

2. **ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸**
   ```bash
   cd backend
   python tests/golden_set_validator.py --agent reviewer
   ```

3. **í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ ì‘ì„±**
   - íŒŒì¼: `docs/A_TEAM_REVIEWER_TEST_RESULTS_2025-11-24.md`
   - ë‚´ìš©: Pass Rate, ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¶„ì„, ê°œì„  ì œì•ˆ

4. **BíŒ€ì— í”¼ë“œë°± ì „ë‹¬**
   - Golden Set í™•ì¥ ìš”ì²­
   - strict_mode í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€ ìš”ì²­

---

**ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ**

**ì‘ì„±ì¼**: 2025-11-24 (ì›”ìš”ì¼) 02:26
**ë‹¤ìŒ ë³´ê³ ì„œ**: `A_TEAM_REVIEWER_TEST_RESULTS_2025-11-24.md` (ì‹¤í–‰ í…ŒìŠ¤íŠ¸ í›„)

---

**ê²€í† ì**: BíŒ€ (Backend) - í™•ì¸ í•„ìš”
**ìŠ¹ì¸ ë‚ ì§œ**: ë¯¸ì •

