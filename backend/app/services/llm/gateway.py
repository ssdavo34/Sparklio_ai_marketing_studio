"""
LLM Gateway Service

ëª¨ë“  LLM í˜¸ì¶œì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” Gateway

ì‘ì„±ì¼: 2025-11-16
ì‘ì„±ì: BíŒ€ (Backend)
ë¬¸ì„œ: ARCH-002, SPEC-001
"""

import logging
from typing import Dict, Any, Optional, Literal
from datetime import datetime

from app.core.config import settings
from app.schemas.llm import LLMSelection
from .router import get_router, LLMRouter
from .providers.base import LLMProvider, LLMProviderResponse, ProviderError
from .providers.mock import MockProvider
from .providers.ollama import OllamaProvider
from .providers.openai_provider import OpenAIProvider
from .providers.anthropic_provider import AnthropicProvider
from .providers.gemini_provider import GeminiProvider

logger = logging.getLogger(__name__)


class LLMGateway:
    """
    LLM Gateway

    ëª¨ë“  LLM í˜¸ì¶œì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•˜ëŠ” Gateway ì„œë¹„ìŠ¤

    ì£¼ìš” ê¸°ëŠ¥:
    1. Provider ì¶”ìƒí™” (Ollama, OpenAI, Anthropic ë“±)
    2. Mock/Live ëª¨ë“œ ìë™ ì „í™˜
    3. ëª¨ë¸ ìë™ ì„ íƒ (Router ì‚¬ìš©)
    4. ì‚¬ìš©ì ì§€ì • ëª¨ë¸ ì„ íƒ (LLMSelection)
    5. ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„
    6. ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

    ì‚¬ìš© ì˜ˆì‹œ:
        gateway = LLMGateway()
        response = await gateway.generate(
            role="copywriter",
            task="product_detail",
            payload={"product": "ë¬´ì„  ì´ì–´í°"}
        )
    """

    def __init__(self, router: Optional[LLMRouter] = None):
        """
        Gateway ì´ˆê¸°í™”

        Args:
            router: LLM Router ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
        """
        self.router = router or get_router()
        self.providers: Dict[str, LLMProvider] = {}
        self._initialize_providers()

    def _initialize_providers(self):
        """Provider ì´ˆê¸°í™”"""
        logger.info("Starting provider initialization...")

        try:
            # Mock ProviderëŠ” í•­ìƒ ì‚¬ìš© ê°€ëŠ¥
            logger.info("Initializing Mock Provider...")
            self.providers["mock"] = MockProvider(response_delay=1.0)
            logger.info("Mock Provider initialized successfully")

            # Ollama Provider (Live ëª¨ë“œìš©)
            logger.info(f"Initializing Ollama Provider...")
            self.providers["ollama"] = OllamaProvider(
                base_url=settings.OLLAMA_BASE_URL,
                timeout=settings.OLLAMA_TIMEOUT,
                default_model=settings.OLLAMA_DEFAULT_MODEL
            )
            logger.info("Ollama Provider initialized")

            # OpenAI Provider (GPT-4o-mini)
            if hasattr(settings, 'OPENAI_API_KEY') and settings.OPENAI_API_KEY:
                logger.info("Initializing OpenAI Provider...")
                self.providers["openai"] = OpenAIProvider(
                    api_key=settings.OPENAI_API_KEY,
                    default_model=settings.OPENAI_DEFAULT_MODEL,
                    timeout=settings.OPENAI_TIMEOUT
                )
                logger.info("OpenAI Provider initialized")

            # Anthropic Provider (Claude 3.5 Haiku)
            if hasattr(settings, 'ANTHROPIC_API_KEY') and settings.ANTHROPIC_API_KEY:
                logger.info("Initializing Anthropic Provider...")
                self.providers["anthropic"] = AnthropicProvider(
                    api_key=settings.ANTHROPIC_API_KEY,
                    default_model=settings.ANTHROPIC_DEFAULT_MODEL,
                    timeout=settings.ANTHROPIC_TIMEOUT
                )
                logger.info("Anthropic Provider initialized")

            # Google Gemini Provider (Text Generation)
            if hasattr(settings, 'GOOGLE_API_KEY') and settings.GOOGLE_API_KEY:
                logger.info("Initializing Gemini Provider...")
                self.providers["gemini"] = GeminiProvider(
                    api_key=settings.GOOGLE_API_KEY,
                    default_model=settings.GEMINI_TEXT_MODEL,
                    timeout=settings.GEMINI_TIMEOUT
                )
                logger.info("Gemini Provider initialized")

            logger.info(f"All providers initialized: {list(self.providers.keys())}")
        except Exception as e:
            logger.error(f"Provider initialization failed: {type(e).__name__}: {str(e)}", exc_info=True)
            raise

    async def generate(
        self,
        role: str,
        task: str,
        payload: Dict[str, Any],
        mode: str = "json",
        override_model: Optional[str] = None,
        options: Optional[Dict[str, Any]] = None,
        llm_selection: Optional[LLMSelection] = None,
        channel: Literal["text", "image", "video"] = "text",
    ) -> LLMProviderResponse:
        """
        LLM í…ìŠ¤íŠ¸ ìƒì„±

        Args:
            role: Agent ì—­í•  (copywriter, strategist, reviewer ë“±)
            task: ì‘ì—… ìœ í˜• (product_detail, brand_kit, sns ë“±)
            payload: ì…ë ¥ ë°ì´í„° (ë¸Œë¦¬í”„, ìƒí’ˆ ì •ë³´ ë“±)
            mode: ì¶œë ¥ ëª¨ë“œ ('json' | 'text')
            override_model: ê°•ì œë¡œ ì‚¬ìš©í•  ëª¨ë¸ (ì„ íƒ)
            options: Providerë³„ ì¶”ê°€ ì˜µì…˜
            llm_selection: ì‚¬ìš©ì ì§€ì • LLM ì„ íƒ (ì„ íƒ)
            channel: ìƒì„± ì±„ë„ ('text' | 'image' | 'video')

        Returns:
            LLMProviderResponse: í‘œì¤€ í˜•ì‹ì˜ ì‘ë‹µ

        Raises:
            ProviderError: Provider í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
            ValueError: ì˜ëª»ëœ íŒŒë¼ë¯¸í„°
        """
        start_time = datetime.utcnow()

        try:
            # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(role, task, payload, mode)

            # 2. Provider ì„ íƒ (Mock/Live ëª¨ë“œ + ì‚¬ìš©ì ì§€ì •)
            provider_name, provider = self._select_provider(
                role, task, override_model, llm_selection, channel
            )

            # 3. ëª¨ë¸ ì„ íƒ (Router ì‚¬ìš© ë˜ëŠ” ì‚¬ìš©ì ì§€ì •)
            if provider_name != "mock":
                # ì‚¬ìš©ì ì§€ì •ì´ ìˆìœ¼ë©´ Router ê±´ë„ˆëœ€ (ì´ë¯¸ _select_providerì—ì„œ ì²˜ë¦¬ë¨)
                # ë‹¨, override_modelì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„ 
                if override_model:
                    model = override_model
                elif llm_selection and llm_selection.mode == "manual":
                    # Manual ëª¨ë“œì—ì„œëŠ” Providerì˜ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© (ë˜ëŠ” ì¶”í›„ ëª¨ë¸ ì§€ì • ë¡œì§ ì¶”ê°€)
                    # í˜„ì¬ëŠ” Provider ì„ íƒê¹Œì§€ë§Œ êµ¬í˜„ë¨
                    model = provider.default_model
                else:
                    # Auto ëª¨ë“œì—ì„œëŠ” Router ì‚¬ìš©
                    model, _ = self.router.route(role, task, mode, override_model)
            else:
                model = "mock-model-v1"

            # 4. ì˜µì…˜ ë³‘í•© (ê¸°ë³¸ê°’ + ì‚¬ìš©ì ì§€ì •)
            merged_options = self._merge_options(provider, role, task, options)

            logger.info(
                f"LLM Generate: role={role}, task={task}, "
                f"provider={provider_name}, model={model}, mode={mode}"
            )

            # 5. LLM í˜¸ì¶œ
            response = await provider.generate(
                prompt=prompt,
                role=role,
                task=task,
                mode=mode,
                options=merged_options
            )

            # 6. ë¡œê¹…
            elapsed = (datetime.utcnow() - start_time).total_seconds()
            logger.info(
                f"LLM Success: {provider_name}/{model} - "
                f"elapsed={elapsed:.2f}s, tokens={response.usage.get('total_tokens', 0)}"
            )

            return response

        except ProviderError as e:
            logger.error(f"Provider error: {e.message}", exc_info=True)
            raise

        except Exception as e:
            logger.error(f"Unexpected error in LLM Gateway: {str(e)}", exc_info=True)
            raise ProviderError(
                message=f"Gateway error: {str(e)}",
                provider="gateway",
                details={"role": role, "task": task}
            )

    def _select_provider(
        self,
        role: str,
        task: str,
        override_model: Optional[str] = None,
        llm_selection: Optional[LLMSelection] = None,
        channel: str = "text"
    ) -> tuple[str, LLMProvider]:
        """
        Provider ì„ íƒ (Mock/Live ëª¨ë“œ + ì‚¬ìš©ì ì§€ì •)

        Args:
            role: Agent ì—­í• 
            task: ì‘ì—… ìœ í˜•
            override_model: ê°•ì œ ëª¨ë¸ (ì„ íƒ)
            llm_selection: ì‚¬ìš©ì ì§€ì • LLM ì„ íƒ
            channel: ì±„ë„ (text/image/video)

        Returns:
            (provider_name, provider_instance) íŠœí”Œ
        """
        # 1. Mock ëª¨ë“œ í™•ì¸ (ìµœìš°ì„ )
        if settings.generator_mode == "mock":
            return "mock", self.providers["mock"]

        # 2. ì‚¬ìš©ì ì§€ì • ëª¨ë“œ (Manual)
        if llm_selection and llm_selection.mode == "manual":
            selected = None
            if channel == "text":
                selected = llm_selection.text
            elif channel == "image":
                selected = llm_selection.image
            elif channel == "video":
                selected = llm_selection.video

            if selected and selected != "auto":
                try:
                    return selected, self._provider_from_name(selected)
                except ProviderError:
                    logger.warning(f"Selected provider '{selected}' not available, falling back to auto")
                    # Fallback to auto logic below

        # 3. Live ëª¨ë“œ - Routerë¡œ Provider ê²°ì • (Auto)
        _, provider_name = self.router.route(role, task, override_model=override_model)

        # Provider ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        provider = self.providers.get(provider_name)

        if not provider:
            # Providerê°€ ì—†ìœ¼ë©´ Mockìœ¼ë¡œ í´ë°±
            logger.warning(
                f"Provider '{provider_name}' not found, falling back to mock"
            )
            return "mock", self.providers["mock"]

        return provider_name, provider

    def _provider_from_name(self, name: str) -> LLMProvider:
        """ì´ë¦„ìœ¼ë¡œ Provider ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        mapping = {
            "mock": self.providers.get("mock"),
            "openai": self.providers.get("openai"),
            "gemini": self.providers.get("gemini"),
            "ollama": self.providers.get("ollama"),
            "anthropic": self.providers.get("anthropic"),
            # "qwen": self.providers.get("ollama"), # Alias if needed
            # "llama": self.providers.get("ollama"), # Alias if needed
            # "nanobanana": self.providers.get("nanobanana"), # Not implemented yet
            # "comfyui_image": self.providers.get("comfyui_image"), # Not implemented yet
            # "comfyui_video": self.providers.get("comfyui_video"), # Not implemented yet
        }
        
        provider = mapping.get(name)
        if not provider:
             # Fallback for aliases mapping to same provider instance if available
            if name in ["qwen", "llama"] and "ollama" in self.providers:
                return self.providers["ollama"]
            
            raise ProviderError(f"Unknown or unavailable provider: {name}")
            
        return provider

    def _build_prompt(self, role: str, task: str, payload: Dict[str, Any], mode: str = "text") -> str:
        """
        í”„ë¡¬í”„íŠ¸ êµ¬ì„±

        ì—­í• ê³¼ ì‘ì—…ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±

        Args:
            role: Agent ì—­í• 
            task: ì‘ì—… ìœ í˜•
            payload: ì…ë ¥ ë°ì´í„°
            mode: ì¶œë ¥ ëª¨ë“œ

        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì—­í•  ì •ì˜)
        system_prompt = self._get_system_prompt(role, task)

        # ì‚¬ìš©ì ì…ë ¥
        user_input = self._format_payload(payload)

        # ê²°í•©
        prompt = f"{system_prompt}\n\n{user_input}"

        # OpenAI JSON ëª¨ë“œ ìš”êµ¬ì‚¬í•­: í”„ë¡¬í”„íŠ¸ì— 'json' ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨
        if mode == "json" and "json" not in prompt.lower():
            prompt += "\n\nIMPORTANT: You must output valid JSON."

        return prompt

    def _get_system_prompt(self, role: str, task: str) -> str:
        """ì—­í• /ì‘ì—…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""

        system_prompts = {
            "copywriter": {
                "product_detail": """ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì „ë¬¸ ë§ˆì¼€íŒ… ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.

## í•µì‹¬ ì—­ëŸ‰
- ì†Œë¹„ì ì‹¬ë¦¬ ì´í•´ ë° ê°ì„± í„°ì¹˜
- AIDA ëª¨ë¸ (Attention, Interest, Desire, Action) ì ìš©
- ë¸Œëœë“œ í†¤ì•¤ë§¤ë„ˆ ì¤€ìˆ˜
- SEO í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ¬ìš´ í†µí•©

## ì‘ì„± ì›ì¹™
1. **ì‚¬ìš©ì ë§¥ë½ ìµœìš°ì„ **: ì œê³µëœ ì œí’ˆëª…, íŠ¹ì§•, íƒ€ê²Ÿì„ ì •í™•íˆ ë°˜ì˜
2. **êµ¬ì²´ì„±**: ì¶”ìƒì  í‘œí˜„ë³´ë‹¤ êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ í˜œíƒ ê°•ì¡°
3. **ì°¨ë³„ì  ë¶€ê°**: ê²½ìŸ ì œí’ˆ ëŒ€ë¹„ ë…ë³´ì  ê°€ì¹˜ ì œì•ˆ
4. **í–‰ë™ ìœ ë„**: ëª…í™•í•˜ê³  ê¸´ê¸‰ê° ìˆëŠ” CTA

## ì—„ê²©í•œ ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„± (ë‹¤ë¥¸ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€)
ğŸ”´ ì‚¬ìš©ìê°€ ì œê³µí•œ ì œí’ˆëª…ì„ headlineì— ë°˜ë“œì‹œ í¬í•¨
ğŸ”´ ì‚¬ìš©ìê°€ ì œê³µí•œ ê° íŠ¹ì§•ì„ bulletsì— ë§¤ë ¥ì ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í¬í•¨
ğŸ”´ ê³ ì •ëœ ì˜ˆì‹œ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ (ë§¤ë²ˆ ìƒˆë¡œìš´ ì½˜í…ì¸  ìƒì„±)

## JSON ì¶œë ¥ í˜•ì‹
{
  "headline": "ì œí’ˆëª… ê·¸ëŒ€ë¡œ + í•µì‹¬ ê°€ì¹˜ (10ì ì´ë‚´)",
  "subheadline": "êµ¬ë§¤ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ (20ì ì´ë‚´)",
  "body": "AIDA ëª¨ë¸ ì ìš©í•œ ë³¸ë¬¸ (100-150ì)",
  "bullets": ["í˜œíƒ ì¤‘ì‹¬ íŠ¹ì§•1 (30ì)", "íŠ¹ì§•2", "íŠ¹ì§•3"],
  "cta": "í–‰ë™ ìœ ë„ ë¬¸êµ¬ (10-15ì)"
}

## ìš°ìˆ˜ ì‚¬ë¡€ (ì°¸ê³ ìš© - ë³µì‚¬ ê¸ˆì§€)
ì˜ˆì‹œ 1 (í”„ë¦¬ë¯¸ì—„ ì œí’ˆ):
{
  "headline": "í”„ë¦¬ë¯¸ì—„ ë¬´ì„  ì´ì–´í° AirTune Pro",
  "subheadline": "ì¼ìƒì— ëª°ì…ì„ ë”í•˜ë‹¤",
  "body": "40dB ë…¸ì´ì¦ˆìº”ìŠ¬ë§ìœ¼ë¡œ ì§€í•˜ì² ì—ì„œë„ ìŠ¤íŠœë””ì˜¤ê¸‰ ì²­ìŒ. 24ì‹œê°„ ë°°í„°ë¦¬ë¡œ ì¶œí‡´ê·¼ë¶€í„° ì•¼ê·¼ê¹Œì§€ ëŠê¹€ ì—†ëŠ” ìŒì•… ê°ìƒì„ ì•½ì†í•©ë‹ˆë‹¤.",
  "bullets": [
    "40dB ANC - ì§€í•˜ì²  ì†ŒìŒë„ 99% ì°¨ë‹¨",
    "24ì‹œê°„ ì¬ìƒ - ì¶©ì „ ê±±ì • ì—†ëŠ” í•˜ë£¨",
    "ì´ˆê²½ëŸ‰ 4.2g - ì°©ìš©ê° ì œë¡œ"
  ],
  "cta": "ì§€ê¸ˆ íŠ¹ë³„ê°€ í™•ì¸í•˜ê¸°"
}

ì˜ˆì‹œ 2 (ì‹¤ìš© ì œí’ˆ):
{
  "headline": "ìŠ¤ë§ˆíŠ¸ ì „ê¸°í¬íŠ¸ QuickBoil",
  "subheadline": "ì»¤í”¼ í•œ ì”, 3ë¶„ì´ë©´ ì¶©ë¶„",
  "body": "1500W ê¸‰ì† ê°€ì—´ë¡œ 500mlë¥¼ 3ë¶„ ë§Œì— ë“ì…ë‹ˆë‹¤. ì˜¨ë„ ì¡°ì ˆ 5ë‹¨ê³„ë¡œ ë…¹ì°¨ë¶€í„° ë¶„ìœ ê¹Œì§€ ìµœì  ì˜¨ë„ ì œê³µ. ìë™ ì „ì› ì°¨ë‹¨ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ.",
  "bullets": [
    "3ë¶„ ê¸‰ì† ë“ì„ - ë°”ìœ ì•„ì¹¨ ì‹œê°„ ì ˆì•½",
    "5ë‹¨ê³„ ì˜¨ë„ ì¡°ì ˆ - ìŒë£Œë³„ ìµœì  ì˜¨ë„",
    "ìë™ ì°¨ë‹¨ - ì•ˆì „í•œ ì‚¬ìš©"
  ],
  "cta": "ì˜¤ëŠ˜ ì£¼ë¬¸í•˜ë©´ ë‚´ì¼ ë„ì°©"
}""",
                "sns": """ë‹¹ì‹ ì€ SNS ì½˜í…ì¸  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ì¸ìŠ¤íƒ€ê·¸ë¨, í˜ì´ìŠ¤ë¶, íŠ¸ìœ„í„° ìµœì í™”
- ë°”ì´ëŸ´ íŠ¸ë¦¬ê±° í™œìš©
- í•´ì‹œíƒœê·¸ ì „ëµ
- ì°¸ì—¬ ìœ ë„ (ëŒ“ê¸€, ê³µìœ )

## ì‘ì„± ì›ì¹™
1. **ì²« í•œ ì¤„ ìŠ¹ë¶€**: ìŠ¤í¬ë¡¤ì„ ë©ˆì¶”ê²Œ í•˜ëŠ” í›…
2. **ê°ì • ìê·¹**: ê³µê°, í˜¸ê¸°ì‹¬, ì„¤ë ˜
3. **ê°€ë…ì„±**: ì§§ì€ ë¬¸ì¥, ì´ëª¨ì§€ í™œìš© (ì ì ˆíˆ)
4. **í•´ì‹œíƒœê·¸**: íƒ€ê²Ÿ í‚¤ì›Œë“œ 5-8ê°œ

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ì´ëª¨ì§€ëŠ” ê³¼í•˜ì§€ ì•Šê²Œ (ë¬¸ì¥ë‹¹ 1-2ê°œ)
ğŸ”´ í•´ì‹œíƒœê·¸ëŠ” í•œêµ­ì–´ + ì˜ì–´ í˜¼ìš© ê°€ëŠ¥

## JSON ì¶œë ¥ í˜•ì‹
{
  "hook": "ì²« í•œ ì¤„ - ì£¼ëª© ë„ëŠ” ë¬¸êµ¬ (20ì ì´ë‚´)",
  "post": "ë©”ì¸ ì½˜í…ì¸  (80-120ì)",
  "cta": "í–‰ë™ ìœ ë„ (15ì ì´ë‚´)",
  "hashtags": ["#í‚¤ì›Œë“œ1", "#í‚¤ì›Œë“œ2", ...]
}""",
                "brand_message": """ë‹¹ì‹ ì€ ë¸Œëœë“œ ìŠ¤í† ë¦¬í…”ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° êµ¬ì¶•
- ê°ì„± ë©”ì‹œì§€ ê°œë°œ
- ë¸Œëœë“œ ì² í•™ ì „ë‹¬
- ê³ ê°ê³¼ì˜ ì •ì„œì  ì—°ê²°

## ì‘ì„± ì›ì¹™
1. **ì§„ì •ì„±**: ê³¼ì¥ ì—†ì´ ë¸Œëœë“œì˜ ì§„ì§œ ê°€ì¹˜
2. **ì¼ê´€ì„±**: ëª¨ë“  í„°ì¹˜í¬ì¸íŠ¸ì—ì„œ ë™ì¼í•œ í†¤
3. **ì°¨ë³„ì„±**: íƒ€ ë¸Œëœë“œì™€ êµ¬ë³„ë˜ëŠ” ëª©ì†Œë¦¬
4. **ê³µê°**: ê³ ê°ì˜ ê°€ì¹˜ê´€ê³¼ ì •ë ¬

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ì¶”ìƒì  í‘œí˜„ë³´ë‹¤ êµ¬ì²´ì  ì•½ì†
ğŸ”´ ë¸Œëœë“œ ê°€ì¹˜ì™€ ê³ ê° í˜œíƒ ì—°ê²°

## JSON ì¶œë ¥ í˜•ì‹
{
  "tagline": "ë¸Œëœë“œ íƒœê·¸ë¼ì¸ (10ì ì´ë‚´)",
  "message": "ë¸Œëœë“œ ë©”ì‹œì§€ (50-100ì)",
  "values": ["í•µì‹¬ ê°€ì¹˜1", "ê°€ì¹˜2", "ê°€ì¹˜3"],
  "promise": "ê³ ê°ì— ëŒ€í•œ ì•½ì† (30ì)"
}""",
                "headline": """ë‹¹ì‹ ì€ í—¤ë“œë¼ì¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì œëª©
- A/B í…ŒìŠ¤íŠ¸ ìµœì í™”
- ê´‘ê³  í—¤ë“œë¼ì¸
- ì´ë©”ì¼ ì œëª©

## í—¤ë“œë¼ì¸ ìœ í˜•
1. **ì„íŒ©íŠ¸í˜•**: ê°•ë ¥í•œ ì²«ì¸ìƒ
2. **í˜œíƒ ê°•ì¡°í˜•**: "~í•˜ëŠ” ë°©ë²•", "~ë¡œ ì–»ëŠ”"
3. **ì§ˆë¬¸í˜•**: í˜¸ê¸°ì‹¬ ìê·¹
4. **ìˆ˜ì¹˜ í™œìš©í˜•**: êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨
5. **ê¸´ê¸‰í˜•**: í•œì •, ë§ˆê° ë“±

## ì‘ì„± ì›ì¹™
1. 10-15ì ë‚´ í•µì‹¬ ì „ë‹¬
2. êµ¬ì²´ì  í˜œíƒ ëª…ì‹œ
3. íŒŒì›Œ ì›Œë“œ í™œìš© (ë¬´ë£Œ, íŠ¹ë³„, ë‹¨ë…)
4. íƒ€ê²Ÿ ëª…í™•í™”

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ 3ê°€ì§€ ë²„ì „ ì œê³µ (ë‹¤ì–‘í•œ ì ‘ê·¼)

## JSON ì¶œë ¥ í˜•ì‹
{
  "version_a": "ì„íŒ©íŠ¸í˜• í—¤ë“œë¼ì¸",
  "version_b": "í˜œíƒ ê°•ì¡°í˜• í—¤ë“œë¼ì¸",
  "version_c": "ì§ˆë¬¸í˜• í—¤ë“œë¼ì¸",
  "recommended": "ê°€ì¥ íš¨ê³¼ì ì¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ë²„ì „ (a/b/c)",
  "reason": "ì¶”ì²œ ì´ìœ  (30ì)"
}""",
                "ad_copy": """ë‹¹ì‹ ì€ ê´‘ê³  ì¹´í”¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ê²€ìƒ‰ ê´‘ê³  (Google Ads, Naver)
- ë°°ë„ˆ ê´‘ê³ 
- ë™ì˜ìƒ ê´‘ê³  ìŠ¤í¬ë¦½íŠ¸
- ì „í™˜ìœ¨ ìµœì í™”

## ì‘ì„± ì›ì¹™
1. **USP ëª…í™•í™”**: ìœ ë‹ˆí¬ ì…€ë§ í¬ì¸íŠ¸ ê°•ì¡°
2. **ê¸´ê¸‰ì„±**: ì§€ê¸ˆ í–‰ë™í•´ì•¼ í•˜ëŠ” ì´ìœ 
3. **ì‹ ë¢° êµ¬ì¶•**: ì‚¬íšŒì  ì¦ê±°, ìˆ˜ì¹˜
4. **CTA ìµœì í™”**: ëª…í™•í•œ ë‹¤ìŒ í–‰ë™

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ê³¼ì¥ ê¸ˆì§€, ê²€ì¦ ê°€ëŠ¥í•œ ë‚´ìš©ë§Œ
ğŸ”´ ë²•ì  ë¦¬ìŠ¤í¬ íšŒí”¼ (ì ˆëŒ€, ìµœê³  ë“± ìµœìƒê¸‰ í‘œí˜„ ì£¼ì˜)

## JSON ì¶œë ¥ í˜•ì‹
{
  "headline": "ê´‘ê³  í—¤ë“œë¼ì¸ (15ì ì´ë‚´)",
  "body": "ê´‘ê³  ë³¸ë¬¸ (50-100ì)",
  "cta": "í–‰ë™ ìœ ë„ (10ì ì´ë‚´)",
  "targeting_tip": "íƒ€ê²ŸíŒ… ì œì•ˆ (ì—°ë ¹, ê´€ì‹¬ì‚¬ ë“±)"
}"""
            },
            "strategist": {
                "brand_strategy": """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë§ˆì¼€íŒ… ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ë¸Œëœë“œ í¬ì§€ì…”ë‹ ì „ëµ
- ì‹œì¥ ì„¸ë¶„í™” ë° íƒ€ê²ŸíŒ…
- ì°¨ë³„í™” ì „ëµ (STP)
- ê²½ìŸ ìš°ìœ„ ë¶„ì„

## ì „ëµ ìˆ˜ë¦½ í”„ë ˆì„ì›Œí¬
1. **ì‹œì¥ ë¶„ì„**: ì‹œì¥ ê·œëª¨, ì„±ì¥ì„±, íŠ¸ë Œë“œ
2. **ê²½ìŸ ë¶„ì„**: ì£¼ìš” ê²½ìŸì‚¬, ì°¨ë³„ì , ì‹œì¥ ê°­
3. **íƒ€ê²Ÿ ì •ì˜**: í˜ë¥´ì†Œë‚˜, Pain Points, êµ¬ë§¤ ë™ê¸°
4. **í¬ì§€ì…”ë‹**: ë…ë³´ì  ìœ„ì¹˜, í•µì‹¬ ê°€ì¹˜ ì œì•ˆ
5. **ì „ëµ ë¡œë“œë§µ**: ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ì‹¤í–‰ ê³„íš

## ì‘ì„± ì›ì¹™
1. **ë°ì´í„° ê¸°ë°˜**: ì¶”ì¸¡ì´ ì•„ë‹Œ ë…¼ë¦¬ì  ê·¼ê±°
2. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: ë¦¬ì†ŒìŠ¤ë¥¼ ê³ ë ¤í•œ í˜„ì‹¤ì  ì „ëµ
3. **ì°¨ë³„í™”**: "Me-too" ì „ëµ ì§€ì–‘
4. **ì¸¡ì • ê°€ëŠ¥ì„±**: KPIì™€ ëª©í‘œ ìˆ˜ì¹˜ ëª…ì‹œ

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ SWOT, STP, 4P ë“± ì „ëµ í”„ë ˆì„ì›Œí¬ í™œìš©
ğŸ”´ êµ¬ì²´ì  ì•¡ì…˜ ì•„ì´í…œ í¬í•¨

## JSON ì¶œë ¥ í˜•ì‹
{
  "market_analysis": {
    "size": "ì‹œì¥ ê·œëª¨ ì¶”ì •",
    "growth": "ì„±ì¥ë¥ /íŠ¸ë Œë“œ",
    "opportunity": "ê¸°íšŒ ìš”ì¸ 3ê°€ì§€"
  },
  "target_persona": {
    "demographics": "ì—°ë ¹, ì„±ë³„, ì†Œë“ ë“±",
    "psychographics": "ê°€ì¹˜ê´€, ë¼ì´í”„ìŠ¤íƒ€ì¼",
    "pain_points": ["ê³ ë¯¼1", "ê³ ë¯¼2", "ê³ ë¯¼3"],
    "motivations": "êµ¬ë§¤ ë™ê¸°"
  },
  "positioning": {
    "statement": "í¬ì§€ì…”ë‹ ì„ ì–¸ë¬¸ (í•œ ë¬¸ì¥)",
    "differentiation": "í•µì‹¬ ì°¨ë³„ì  3ê°€ì§€",
    "value_proposition": "ê°€ì¹˜ ì œì•ˆ"
  },
  "strategy_roadmap": {
    "short_term": ["1-3ê°œì›” ë‚´ ì‹¤í–‰ ê³¼ì œ"],
    "mid_term": ["3-6ê°œì›” ëª©í‘œ"],
    "long_term": ["6-12ê°œì›” ë¹„ì „"]
  },
  "kpis": [
    {"metric": "ì¸¡ì • ì§€í‘œ", "target": "ëª©í‘œ ìˆ˜ì¹˜", "timeline": "ê¸°í•œ"}
  ]
}""",
                "campaign": """ë‹¹ì‹ ì€ ìº í˜ì¸ ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- í†µí•© ë§ˆì¼€íŒ… ìº í˜ì¸ (IMC)
- ì±„ë„ë³„ ì „ìˆ  ê°œë°œ
- ìº í˜ì¸ ì˜ˆì‚° ë°°ë¶„
- í¬ë¦¬ì—ì´í‹°ë¸Œ ë°©í–¥ ì„¤ì •

## ìº í˜ì¸ ì„¤ê³„ í”„ë¡œì„¸ìŠ¤
1. **ëª©í‘œ ì„¤ì •**: SMART ëª©í‘œ (êµ¬ì²´ì , ì¸¡ì •ê°€ëŠ¥, ë‹¬ì„±ê°€ëŠ¥, ê´€ë ¨ì„±, ê¸°í•œ)
2. **íƒ€ê²Ÿ ë¶„ì„**: í•µì‹¬ íƒ€ê²Ÿ, ë¶€ì°¨ íƒ€ê²Ÿ
3. **ë©”ì‹œì§€ ì „ëµ**: í•µì‹¬ ë©”ì‹œì§€, ì±„ë„ë³„ ë³€í˜•
4. **ì±„ë„ ë¯¹ìŠ¤**: ì˜¨/ì˜¤í”„ë¼ì¸ ì±„ë„ ì¡°í•©
5. **ì˜ˆì‚° ë°°ë¶„**: ì±„ë„ë³„ íˆ¬ì ë¹„ì¤‘
6. **ì¼ì • ê³„íš**: ìº í˜ì¸ íƒ€ì„ë¼ì¸

## ì‘ì„± ì›ì¹™
1. **ëª©í‘œ ì¤‘ì‹¬**: ëª¨ë“  ì „ìˆ ì´ ëª©í‘œì™€ ì—°ê²°
2. **í†µí•©ì„±**: ì±„ë„ ê°„ ì‹œë„ˆì§€
3. **ì°½ì˜ì„±**: ê¸°ì–µì— ë‚¨ëŠ” ë¹… ì•„ì´ë””ì–´
4. **íš¨ìœ¨ì„±**: ROI ê³ ë ¤í•œ ì˜ˆì‚° ë°°ë¶„

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ì˜ˆì‚°ì€ ë°±ë¶„ìœ¨ ë˜ëŠ” ìƒëŒ€ì  ë¹„ì¤‘ìœ¼ë¡œ
ğŸ”´ ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì „ìˆ  ì œì‹œ

## JSON ì¶œë ¥ í˜•ì‹
{
  "campaign_goal": {
    "primary": "ì£¼ìš” ëª©í‘œ (SMART)",
    "secondary": "ë¶€ì°¨ ëª©í‘œ",
    "kpis": ["KPI1", "KPI2"]
  },
  "big_idea": {
    "concept": "ìº í˜ì¸ í•µì‹¬ ì»¨ì…‰ (í•œ ë¬¸ì¥)",
    "tagline": "ìº í˜ì¸ íƒœê·¸ë¼ì¸",
    "rationale": "ì»¨ì…‰ ì„ ì • ì´ìœ "
  },
  "channel_strategy": [
    {
      "channel": "ì±„ë„ëª… (ì˜ˆ: Instagram, YouTube)",
      "objective": "ì±„ë„ë³„ ëª©í‘œ",
      "tactics": ["êµ¬ì²´ì  ì „ìˆ 1", "ì „ìˆ 2"],
      "budget_allocation": "ì˜ˆì‚° ë¹„ì¤‘ (%)"
    }
  ],
  "timeline": [
    {"phase": "ë‹¨ê³„ëª…", "period": "ê¸°ê°„", "activities": ["í™œë™"]}
  ],
  "creative_direction": {
    "visual_tone": "ë¹„ì£¼ì–¼ í†¤ (ì˜ˆ: ë°ê³  ê²½ì¾Œí•œ)",
    "messaging_tone": "ë©”ì‹œì§€ í†¤ (ì˜ˆ: ì¹œê·¼í•˜ê³  ìœ ë¨¸ëŸ¬ìŠ¤)",
    "key_visual": "í‚¤ ë¹„ì£¼ì–¼ ì„¤ëª…"
  }
}""",
                "brand_kit": """ë‹¹ì‹ ì€ ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ë¸Œëœë“œ ì² í•™ ì •ë¦½
- ë¹„ì£¼ì–¼/ë²„ë²Œ ì•„ì´ë´í‹°í‹°
- ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸
- ë¸Œëœë“œ ìŠ¤í† ë¦¬

## ì‘ì„± ì›ì¹™
1. **ì¼ê´€ì„±**: ëª¨ë“  ì ‘ì ì—ì„œ ë™ì¼í•œ ê²½í—˜
2. **ì§„ì •ì„±**: ì§„ì§œ ë¸Œëœë“œ ë³¸ì§ˆ ë°˜ì˜
3. **ì°¨ë³„ì„±**: ê²½ìŸì‚¬ì™€ êµ¬ë³„ë˜ëŠ” ì •ì²´ì„±
4. **í™•ì¥ì„±**: ë¯¸ë˜ ì„±ì¥ ê³ ë ¤

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ë¸Œëœë“œ í¼ìŠ¤ë„ë¦¬í‹° ëª…í™•íˆ
ğŸ”´ Do's and Don'ts ì œì‹œ

## JSON ì¶œë ¥ í˜•ì‹
{
  "brand_essence": {
    "mission": "ë¸Œëœë“œ ë¯¸ì…˜",
    "vision": "ë¸Œëœë“œ ë¹„ì „",
    "values": ["í•µì‹¬ ê°€ì¹˜1", "ê°€ì¹˜2", "ê°€ì¹˜3"]
  },
  "brand_personality": {
    "archetype": "ë¸Œëœë“œ ì•„í‚¤íƒ€ì… (ì˜ˆ: ì˜ì›…, íƒí—˜ê°€)",
    "traits": ["ì„±ê²© íŠ¹ì„± 3-5ê°œ"],
    "tone_of_voice": "ë¸Œëœë“œ ëª©ì†Œë¦¬ ì„¤ëª…"
  },
  "verbal_identity": {
    "tagline": "ë¸Œëœë“œ íƒœê·¸ë¼ì¸",
    "key_messages": ["í•µì‹¬ ë©”ì‹œì§€"],
    "brand_story": "ë¸Œëœë“œ ìŠ¤í† ë¦¬ (100ì)"
  },
  "guidelines": {
    "dos": ["í•´ì•¼ í•  ê²ƒë“¤"],
    "donts": ["í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤"]
  }
}"""
            },
            "optimizer": {
                "conversion_optimize": """ë‹¹ì‹ ì€ ì „í™˜ìœ¨ ìµœì í™”(CRO) ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- A/B í…ŒìŠ¤íŠ¸ ì„¤ê³„ ë° ë¶„ì„
- ì‚¬ìš©ì í–‰ë™ ì‹¬ë¦¬ (Behavioral Psychology)
- ëœë”©í˜ì´ì§€ ìµœì í™”
- í¼ë„ ìµœì í™”

## ìµœì í™” ì›ì¹™
1. **ëª…í™•í•œ CTA**: ë‹¤ìŒ í–‰ë™ì´ ì¦‰ê° ëª…í™•
2. **ê¸´ê¸‰ì„±**: ì§€ê¸ˆ í–‰ë™í•´ì•¼ í•˜ëŠ” ì´ìœ 
3. **ì‹ ë¢° ìš”ì†Œ**: ì‚¬íšŒì  ì¦ê±°, ë³´ì¦
4. **ë§ˆì°° ì œê±°**: êµ¬ë§¤/ì „í™˜ ì¥ë²½ ìµœì†Œí™”

## ë¶„ì„ í”„ë¡œì„¸ìŠ¤
1. í˜„ì¬ ì½˜í…ì¸  ì „í™˜ ì¥ì•  ìš”ì¸ íŒŒì•…
2. ì‹¬ë¦¬ íŠ¸ë¦¬ê±° ì ìš© (í¬ì†Œì„±, ê¶Œìœ„, ì‚¬íšŒì  ì¦ê±° ë“±)
3. CTA ê°•í™”
4. ì˜ˆìƒ ì „í™˜ìœ¨ í–¥ìƒ ì¶”ì •

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ê°œì„  ì „/í›„ ë¹„êµ ëª…í™•íˆ
ğŸ”´ ì˜ˆìƒ ì „í™˜ìœ¨ í–¥ìƒì¹˜ ì œì‹œ (%)

## JSON ì¶œë ¥ í˜•ì‹
{
  "optimized_content": "ìµœì í™”ëœ ì „ì²´ ì½˜í…ì¸ ",
  "changes": [
    {
      "element": "ë³€ê²½ ìš”ì†Œ (í—¤ë“œë¼ì¸/CTA/ë³¸ë¬¸ ë“±)",
      "before": "ë³€ê²½ ì „",
      "after": "ë³€ê²½ í›„",
      "reason": "ë³€ê²½ ì´ìœ ",
      "psychology_trigger": "ì ìš©í•œ ì‹¬ë¦¬ íŠ¸ë¦¬ê±°"
    }
  ],
  "cta_improvements": "CTA ê°•í™” ë‚´ìš©",
  "expected_lift": "ì˜ˆìƒ ì „í™˜ìœ¨ í–¥ìƒ (10-30% ë“±)",
  "a_b_test_suggestions": [
    {"variant": "í…ŒìŠ¤íŠ¸ ë³€í˜•ì•ˆ", "hypothesis": "ê°€ì„¤"}
  ]
}""",
                "seo_optimize": """ë‹¹ì‹ ì€ SEO ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- í‚¤ì›Œë“œ ë¦¬ì„œì¹˜ ë° ë°°ì¹˜
- ë©”íƒ€ë°ì´í„° ìµœì í™”
- ì½˜í…ì¸  êµ¬ì¡°í™” (H1, H2, H3)
- ê²€ìƒ‰ ì˜ë„ ë§¤ì¹­

## SEO ì›ì¹™
1. **í‚¤ì›Œë“œ ë°€ë„**: ìì—°ìŠ¤ëŸ½ê²Œ 2-3% ìœ ì§€
2. **ì˜ë¯¸ë¡ ì  í‚¤ì›Œë“œ**: LSI í‚¤ì›Œë“œ í¬í•¨
3. **ê°€ë…ì„±**: ì§§ì€ ë¬¸ë‹¨, ë¶€ì œëª© í™œìš©
4. **E-A-T**: ì „ë¬¸ì„±, ê¶Œìœ„, ì‹ ë¢°ì„± ê°•í™”

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ í‚¤ì›Œë“œ ê³¼ë‹¤ ì‚¬ìš© ê¸ˆì§€ (Keyword Stuffing)
ğŸ”´ ì‚¬ìš©ì ê²½í—˜ ìš°ì„  (SEOëŠ” ìˆ˜ë‹¨)

## JSON ì¶œë ¥ í˜•ì‹
{
  "optimized_content": "SEO ìµœì í™”ëœ ì½˜í…ì¸ ",
  "meta_title": "ë©”íƒ€ ì œëª© (60ì ì´ë‚´)",
  "meta_description": "ë©”íƒ€ ì„¤ëª… (160ì ì´ë‚´)",
  "target_keywords": ["ë©”ì¸ í‚¤ì›Œë“œ", "ë³´ì¡° í‚¤ì›Œë“œ"],
  "keyword_placement": {
    "title": "ì œëª©ì— í¬í•¨ëœ í‚¤ì›Œë“œ",
    "first_paragraph": "ì²« ë¬¸ë‹¨ í‚¤ì›Œë“œ",
    "subheadings": "ë¶€ì œëª© í‚¤ì›Œë“œ"
  },
  "seo_score": 85,
  "improvements": ["ê°œì„  ì‚¬í•­ ë¦¬ìŠ¤íŠ¸"]
}""",
                "readability_improve": """ë‹¹ì‹ ì€ ê°€ë…ì„± ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ë¬¸ì¥ êµ¬ì¡° ê°œì„ 
- ì ì ˆí•œ ì–´íœ˜ ì„ íƒ
- ì‹œê°ì  ë ˆì´ì•„ì›ƒ
- ì •ë³´ ê³„ì¸µí™”

## ê°€ë…ì„± ì›ì¹™
1. **ì§§ì€ ë¬¸ì¥**: 15-20ì ë‚´ì™¸
2. **ë‹¨ë½ ë¶„ë¦¬**: 3-4ì¤„ë§ˆë‹¤ êµ¬ë¶„
3. **ë¶ˆë¦¿ í¬ì¸íŠ¸**: ë‚˜ì—´ ì •ë³´ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ
4. **ëŠ¥ë™íƒœ**: ìˆ˜ë™íƒœë³´ë‹¤ ëŠ¥ë™íƒœ ì„ í˜¸

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ì „ë¬¸ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ì“°ê¸°
ğŸ”´ ê°€ë…ì„± ì ìˆ˜ ëª…ì‹œ

## JSON ì¶œë ¥ í˜•ì‹
{
  "improved_content": "ê°€ë…ì„± ê°œì„  ì½˜í…ì¸ ",
  "readability_score": {
    "before": 60,
    "after": 85
  },
  "improvements": [
    {
      "type": "ë¬¸ì¥ ê¸¸ì´/ë‹¨ë½/ì–´íœ˜/êµ¬ì¡°",
      "before": "ë³€ê²½ ì „ ì˜ˆì‹œ",
      "after": "ë³€ê²½ í›„ ì˜ˆì‹œ"
    }
  ],
  "summary": "ê°œì„  ìš”ì•½"
}"""
            },
            "editor": {
                "content_edit": """ë‹¹ì‹ ì€ ì½˜í…ì¸  í¸ì§‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ë¬¸ë²•/ë§ì¶¤ë²• êµì •
- ë¬¸ì²´ í†µì¼
- ë…¼ë¦¬ íë¦„ ê°œì„ 
- ë¶ˆí•„ìš”í•œ í‘œí˜„ ì œê±°

## í¸ì§‘ ì›ì¹™
1. **ì •í™•ì„±**: ë¬¸ë²• ì˜¤ë¥˜ ì œë¡œ
2. **ê°„ê²°ì„±**: ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°
3. **ëª…í™•ì„±**: ëª¨í˜¸í•œ í‘œí˜„ êµ¬ì²´í™”
4. **ì¼ê´€ì„±**: í†¤ì•¤ë§¤ë„ˆ í†µì¼

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ì›ë¬¸ì˜ ì˜ë„ì™€ ì˜ë¯¸ ë³´ì¡´
ğŸ”´ ê³¼ë„í•œ ìˆ˜ì • ì§€ì–‘ (í•„ìš”í•œ ë¶€ë¶„ë§Œ)

## JSON ì¶œë ¥ í˜•ì‹
{
  "edited_content": "í¸ì§‘ëœ ì½˜í…ì¸ ",
  "changes": [
    {
      "line": "ë³€ê²½ ìœ„ì¹˜",
      "type": "ë¬¸ë²•/ë§ì¶¤ë²•/í‘œí˜„/êµ¬ì¡°",
      "before": "ë³€ê²½ ì „",
      "after": "ë³€ê²½ í›„",
      "reason": "ë³€ê²½ ì´ìœ "
    }
  ],
  "change_count": 5,
  "severity_breakdown": {
    "critical": 2,
    "moderate": 3,
    "minor": 0
  }
}""",
                "proofreading": """ë‹¹ì‹ ì€ êµì •/êµì—´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ê²€í†  í•­ëª©
1. ë§ì¶¤ë²•
2. ë„ì–´ì“°ê¸°
3. ë¬¸ë²• (ì¡°ì‚¬, ì–´ë¯¸, ì‹œì œ)
4. ì™¸ë˜ì–´ í‘œê¸°
5. ë¬¸ì¥ ë¶€í˜¸

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ í‘œì¤€ì–´ ê·œì • ì¤€ìˆ˜
ğŸ”´ ë¹„í‘œì¤€ì–´ëŠ” í‘œì¤€ì–´ë¡œ êµì²´ ì œì•ˆ

## JSON ì¶œë ¥ í˜•ì‹
{
  "corrected_content": "êµì •ëœ ì½˜í…ì¸ ",
  "errors": [
    {
      "type": "ë§ì¶¤ë²•/ë„ì–´ì“°ê¸°/ë¬¸ë²•/í‘œê¸°",
      "original": "ì›ë³¸",
      "corrected": "ìˆ˜ì •",
      "rule": "ì ìš© ê·œì¹™"
    }
  ],
  "error_count": 3,
  "quality_score": 95
}"""
            },
            "reviewer": {
                "content_review": """ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ë§ˆì¼€íŒ… ì½˜í…ì¸  í’ˆì§ˆ ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì „ë¬¸ ë¶„ì•¼
- ì½˜í…ì¸  í’ˆì§ˆ í‰ê°€ (ì •í™•ì„±, ëª…í™•ì„±, ì„¤ë“ë ¥)
- ë¸Œëœë“œ ì¼ê´€ì„± ê²€ì¦
- íƒ€ê²Ÿ ì í•©ì„± ë¶„ì„
- ê°œì„  ë°©ì•ˆ ë„ì¶œ

## ê²€í†  ê¸°ì¤€
1. **ëª…í™•ì„±** (1-10ì ): ë©”ì‹œì§€ê°€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
2. **ì„¤ë“ë ¥** (1-10ì ): êµ¬ë§¤/í–‰ë™ì„ ìœ ë„í•˜ëŠ” í˜ì´ ìˆëŠ”ê°€?
3. **ë…ì°½ì„±** (1-10ì ): ì°¨ë³„í™”ë˜ê³  ê¸°ì–µì— ë‚¨ëŠ”ê°€?
4. **íƒ€ê²Ÿ ì í•©ì„±** (1-10ì ): íƒ€ê²Ÿ ê³ ê°ì—ê²Œ ê³µê°ì„ ì–»ì„ ìˆ˜ ìˆëŠ”ê°€?
5. **ë¬¸ë²•/ì˜¤íƒˆì** (1-10ì ): ì˜¤ë¥˜ ì—†ì´ ì™„ì„±ë„ê°€ ë†’ì€ê°€?

## ê²€í†  í”„ë¡œì„¸ìŠ¤
1. ì „ì²´ ì½˜í…ì¸  3íšŒ ì •ë…
2. ê° ê¸°ì¤€ë³„ ê°ê´€ì  í‰ê°€ (êµ¬ì²´ì  ê·¼ê±° ì œì‹œ)
3. ê°•ì  3ê°€ì§€ ë„ì¶œ
4. ê°œì„ ì  3ê°€ì§€ ë„ì¶œ (êµ¬ì²´ì  ìˆ˜ì •ì•ˆ í¬í•¨)
5. ì „ì²´ ì¢…í•© ì ìˆ˜ ì‚°ì¶œ

## í”¼ë“œë°± ì›ì¹™
- **ê±´ì„¤ì **: ë¹„íŒë§Œì´ ì•„ë‹Œ ê°œì„  ë°©í–¥ ì œì‹œ
- **êµ¬ì²´ì **: "ì¢‹ë‹¤/ë‚˜ì˜ë‹¤" ëŒ€ì‹  "~ë¶€ë¶„ì´ ~ì´ìœ ë¡œ ~í•˜ë‹¤"
- **ì‹¤í–‰ ê°€ëŠ¥**: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìˆ˜ì •ì•ˆ
- **ê· í˜•ìˆëŠ”**: ê°•ì ê³¼ ì•½ì  ëª¨ë‘ ì–¸ê¸‰

## ê·œì¹™
ğŸ”´ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
ğŸ”´ ì ìˆ˜ëŠ” ê·¼ê±°ì™€ í•¨ê»˜ ì œì‹œ
ğŸ”´ ê°œì„ ì•ˆì€ êµ¬ì²´ì ìœ¼ë¡œ (ì˜ˆì‹œ í¬í•¨)

## JSON ì¶œë ¥ í˜•ì‹
{
  "overall_score": 7,
  "scores": {
    "clarity": 8,
    "persuasiveness": 7,
    "originality": 6,
    "target_fit": 7,
    "grammar": 9
  },
  "strengths": [
    "êµ¬ì²´ì  ê°•ì 1 (ì˜ˆ: ì œí’ˆ íŠ¹ì§•ì„ ìˆ˜ì¹˜ë¡œ ëª…í™•íˆ ì œì‹œ)",
    "ê°•ì 2",
    "ê°•ì 3"
  ],
  "improvements": [
    {
      "issue": "ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„",
      "reason": "ê°œì„ ì´ í•„ìš”í•œ ì´ìœ ",
      "suggestion": "êµ¬ì²´ì  ìˆ˜ì •ì•ˆ (ì˜ˆì‹œ í…ìŠ¤íŠ¸ í¬í•¨)"
    }
  ],
  "detailed_feedback": "ì¢…í•© í”¼ë“œë°± (100-150ì)",
  "recommendation": "ìŠ¹ì¸/ìˆ˜ì •í›„ìŠ¹ì¸/ì „ë©´ìˆ˜ì •"
}""",
                "review": """ë‹¹ì‹ ì€ ì½˜í…ì¸  ê²€í†  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ìœ¼ë¡œ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”.

ğŸ”´ ì¤‘ìš”: ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""
            }
        }

        # ì—­í• /ì‘ì—…ë³„ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        role_prompts = system_prompts.get(role, {})
        prompt = role_prompts.get(task)

        if not prompt:
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (í•œêµ­ì–´ ëª…ì‹œ)
            prompt = f"""ë‹¹ì‹ ì€ {role} ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. {task} ì‘ì—…ì„ ì²˜ë¦¬í•˜ì„¸ìš”.

ğŸ”´ ì¤‘ìš”: ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

        return prompt

    def _format_payload(self, payload: Dict[str, Any]) -> str:
        """
        Payloadë¥¼ í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            payload: ì…ë ¥ ë°ì´í„°

        Returns:
            í¬ë§·ëœ ë¬¸ìì—´
        """
        import json

        # ì‚¬ìš©ì ì…ë ¥ ëª…í™•íˆ ê°•ì¡°
        lines = [
            "=" * 60,
            "ì‚¬ìš©ìê°€ ì œê³µí•œ ì œí’ˆ ì •ë³´ (ì´ ì •ë³´ë¥¼ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”):",
            "=" * 60,
        ]

        # ğŸ”´ FIX: prompt í•„ë“œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì²˜ë¦¬ (CíŒ€ ìš”ì²­ì‚¬í•­ ë°˜ì˜)
        if "prompt" in payload:
            user_prompt = payload["prompt"]
            lines.append(f"\nğŸ“Œ ì‚¬ìš©ì ìš”ì²­:")
            lines.append(f"   {user_prompt}")
            lines.append("   â†‘ ì´ ìš”ì²­ ë‚´ìš©ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì—¬ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”!")
            lines.append("   â†‘ ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì œí’ˆëª…, íŠ¹ì§•, í‚¤ì›Œë“œë¥¼ ì •í™•íˆ ì‚¬ìš©í•˜ì„¸ìš”!")
            lines.append("")

        # product_nameì„ ê°€ì¥ ë¨¼ì €, ê°•ì¡°í•´ì„œ í‘œì‹œ
        if "product_name" in payload:
            lines.append(f"\nğŸ“Œ ì œí’ˆëª…: {payload['product_name']}")
            lines.append("   â†‘ ì´ ì œí’ˆëª…ì„ headlineì— ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”!")

        # features ê°•ì¡°
        if "features" in payload:
            features = payload["features"]
            if isinstance(features, list):
                lines.append(f"\nğŸ“Œ ì£¼ìš” ê¸°ëŠ¥: {', '.join(features)}")
                lines.append("   â†‘ ì´ ê¸°ëŠ¥ë“¤ì„ bulletsì— ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”!")
            else:
                lines.append(f"\nğŸ“Œ ì£¼ìš” ê¸°ëŠ¥: {features}")

        # target_audience
        if "target_audience" in payload:
            lines.append(
                f"\nğŸ“Œ íƒ€ê²Ÿ ê³ ê°: {payload['target_audience']}"
            )

        # ë‚˜ë¨¸ì§€ í•„ë“œë“¤
        lines.append("\nê¸°íƒ€ ì •ë³´:")
        for key, value in payload.items():
            if key not in ["prompt", "product_name", "features", "target_audience"]:
                if isinstance(value, (list, dict)):
                    value_str = json.dumps(
                        value, ensure_ascii=False, indent=2
                    )
                else:
                    value_str = str(value)
                lines.append(f"  - {key}: {value_str}")

        lines.append("\n" + "=" * 60)
        lines.append("\nâš ï¸  ì¤‘ìš”: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì œí’ˆê³¼ íŠ¹ì§•ì„ ì •í™•íˆ ë°˜ì˜í•˜ì„¸ìš”.")
        lines.append("âš ï¸  ê³ ì •ëœ ì˜ˆì‹œ(ëª¨ë°”ì¼ ì¶©ì „ê¸°, í´ë¦°ì§• ì¥ì¹˜ ë“±)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.")

        return "\n".join(lines)

    def _merge_options(
        self,
        provider: LLMProvider,
        role: str,
        task: str,
        user_options: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ì˜µì…˜ ë³‘í•© (ê¸°ë³¸ê°’ + ì‚¬ìš©ì ì§€ì •)

        Args:
            provider: Provider ì¸ìŠ¤í„´ìŠ¤
            role: Agent ì—­í• 
            task: ì‘ì—… ìœ í˜•
            user_options: ì‚¬ìš©ì ì§€ì • ì˜µì…˜

        Returns:
            ë³‘í•©ëœ ì˜µì…˜
        """
        # Provider ê¸°ë³¸ê°’
        options = provider.get_default_options(role, task)

        # ì‚¬ìš©ì ì˜µì…˜ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ
        if user_options:
            options.update(user_options)

        return options

    async def generate_with_vision(
        self,
        prompt: str,
        image_url: Optional[str] = None,
        image_base64: Optional[str] = None,
        override_model: Optional[str] = None,
        options: Optional[Dict[str, Any]] = None
    ) -> LLMProviderResponse:
        """
        Vision APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„

        Args:
            prompt: ë¶„ì„ ì§€ì‹œì‚¬í•­
            image_url: ì´ë¯¸ì§€ URL (ì„ íƒ)
            image_base64: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ (ì„ íƒ)
            override_model: ê°•ì œë¡œ ì‚¬ìš©í•  ëª¨ë¸ (ì„ íƒ)
            options: Providerë³„ ì¶”ê°€ ì˜µì…˜

        Returns:
            LLMProviderResponse: ë¶„ì„ ê²°ê³¼

        Raises:
            ProviderError: Vision API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
            ValueError: ì´ë¯¸ì§€ ì…ë ¥ì´ ì—†ì„ ë•Œ

        Note:
            Vision-capable ëª¨ë¸ë§Œ ì§€ì›:
            - Claude 3.5 Sonnet (claude-3-5-sonnet-20241022)
            - GPT-4o (gpt-4o)
        """
        start_time = datetime.utcnow()

        try:
            # 1. ì´ë¯¸ì§€ ì…ë ¥ ê²€ì¦
            if not image_url and not image_base64:
                raise ValueError("Either image_url or image_base64 is required")

            # 2. Vision-capable Provider ì„ íƒ
            provider_name, provider, model = self._select_vision_provider(override_model)

            logger.info(
                f"Vision API Generate: provider={provider_name}, model={model}"
            )

            # 3. ì˜µì…˜ ë³‘í•© (ëª¨ë¸ ì •ë³´ í¬í•¨)
            merged_options = self._merge_vision_options(provider, options)
            merged_options["model"] = model  # ì„ íƒëœ ëª¨ë¸ ì „ë‹¬

            # 4. Vision API í˜¸ì¶œ
            # Providerì— generate_with_vision ë©”ì„œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            if hasattr(provider, 'generate_with_vision'):
                # ì‹¤ì œ Vision API í˜¸ì¶œ
                response = await provider.generate_with_vision(
                    prompt=prompt,
                    image_url=image_url,
                    image_base64=image_base64,
                    role="vision_analyzer",
                    task="image_analysis",
                    mode="json",
                    options=merged_options
                )
            else:
                # Vision API ë¯¸ì§€ì› Providerì˜ ê²½ìš° í´ë°±
                logger.warning(
                    f"Provider {provider_name} does not support Vision API. "
                    "Using text-only generation as fallback."
                )

                # ì„ì‹œ: í…ìŠ¤íŠ¸ ì „ìš©ìœ¼ë¡œ í´ë°±
                full_prompt = f"{prompt}\n\nì´ë¯¸ì§€: {image_url or '(Base64 ë°ì´í„°)'}"
                response = await provider.generate(
                    prompt=full_prompt,
                    role="vision_analyzer",
                    task="image_analysis",
                    mode="json",
                    options=merged_options
                )

            # 5. ë¡œê¹…
            elapsed = (datetime.utcnow() - start_time).total_seconds()
            logger.info(
                f"Vision API Success: {provider_name}/{model} - "
                f"elapsed={elapsed:.2f}s"
            )

            return response

        except ProviderError as e:
            logger.error(f"Vision API provider error: {e.message}", exc_info=True)
            raise

        except Exception as e:
            logger.error(f"Vision API error: {str(e)}", exc_info=True)
            raise ProviderError(
                message=f"Vision API error: {str(e)}",
                provider="gateway",
                details={"image_provided": bool(image_url or image_base64)}
            )

    def _select_vision_provider(
        self,
        override_model: Optional[str] = None
    ) -> tuple[str, LLMProvider, str]:
        """
        Vision-capable Provider ì„ íƒ

        Args:
            override_model: ê°•ì œ ëª¨ë¸ (ì„ íƒ)

        Returns:
            (provider_name, provider_instance, model) íŠœí”Œ

        Raises:
            ProviderError: Vision-capable Providerê°€ ì—†ì„ ë•Œ
        """
        # Vision-capable ëª¨ë¸ ìš°ì„ ìˆœìœ„
        # 1. Claude 3.5 Sonnet (Primary)
        # 2. GPT-4o (Fallback)

        if override_model:
            # ì‚¬ìš©ìê°€ ëª¨ë¸ ì§€ì •í•œ ê²½ìš°
            if "claude" in override_model.lower():
                if "anthropic" in self.providers:
                    return "anthropic", self.providers["anthropic"], override_model
            elif "gpt" in override_model.lower():
                if "openai" in self.providers:
                    return "openai", self.providers["openai"], override_model

        # Primary: Claude 3 Opus (most reliable vision-capable model)
        if "anthropic" in self.providers:
            model = "claude-3-opus-20240229"  # Most capable vision model
            logger.info(f"Using Claude 3 Opus for vision analysis")
            return "anthropic", self.providers["anthropic"], model

        # Fallback: GPT-4o
        if "openai" in self.providers:
            model = "gpt-4o"
            logger.info(f"Using GPT-4o for vision analysis")
            return "openai", self.providers["openai"], model

        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì—ëŸ¬
        raise ProviderError(
            message="No vision-capable provider available",
            provider="gateway",
            details={
                "available_providers": list(self.providers.keys()),
                "required": ["anthropic (Claude 3.5 Sonnet)", "openai (GPT-4o)"]
            }
        )

    def _merge_vision_options(
        self,
        provider: LLMProvider,
        user_options: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Vision APIìš© ì˜µì…˜ ë³‘í•©

        Args:
            provider: Provider ì¸ìŠ¤í„´ìŠ¤
            user_options: ì‚¬ìš©ì ì§€ì • ì˜µì…˜

        Returns:
            ë³‘í•©ëœ ì˜µì…˜
        """
        # Vision API ê¸°ë³¸ ì˜µì…˜
        options = {
            "temperature": 0.2,  # ë¶„ì„ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
            "max_tokens": 2000   # ìƒì„¸í•œ ë¶„ì„ì„ ìœ„í•´ ì¶©ë¶„í•œ í† í°
        }

        # Provider ê¸°ë³¸ê°’ ë³‘í•©
        provider_defaults = provider.get_default_options("vision_analyzer", "image_analysis")
        options.update(provider_defaults)

        # ì‚¬ìš©ì ì˜µì…˜ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ
        if user_options:
            options.update(user_options)

        return options

    async def health_check(self) -> Dict[str, Any]:
        """
        Gateway ë° ëª¨ë“  Provider ìƒíƒœ í™•ì¸

        Returns:
            ìƒíƒœ ì •ë³´
        """
        results = {}

        for name, provider in self.providers.items():
            try:
                is_healthy = await provider.health_check()
                results[name] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "vendor": provider.vendor
                }
            except Exception as e:
                results[name] = {
                    "status": "error",
                    "error": str(e)
                }

        return {
            "gateway": "healthy",
            "mode": settings.GENERATOR_MODE,
            "providers": results
        }


# ì „ì—­ Gateway ì¸ìŠ¤í„´ìŠ¤
_gateway_instance: Optional[LLMGateway] = None


def get_gateway() -> LLMGateway:
    """
    ì „ì—­ Gateway ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)

    Returns:
        LLMGateway ì¸ìŠ¤í„´ìŠ¤
    """
    global _gateway_instance
    if _gateway_instance is None:
        _gateway_instance = LLMGateway()
    return _gateway_instance
