"""
Context Engineering Integration í…ŒìŠ¤íŠ¸

Agent â†’ LLM Gateway ì—°ë™ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦

ì‘ì„±ì¼: 2025-11-23
ì‘ì„±ì: BíŒ€ (Backend)
"""

import asyncio
import logging
from app.services.agents.copywriter import CopywriterAgent
from app.services.agents.base import AgentRequest

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_context_engineering():
    """
    Context Engineering í•„ë“œê°€ LLM Gatewayë¡œ ì „ë‹¬ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
    """
    print("\n" + "=" * 70)
    print("Context Engineering Integration í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # CopywriterAgent ì´ˆê¸°í™”
    agent = CopywriterAgent()

    # í…ŒìŠ¤íŠ¸ ìš”ì²­
    request = AgentRequest(
        task="product_detail",
        payload={
            "product_name": "í…ŒìŠ¤íŠ¸ìš© ë¬´ì„  ì´ì–´í°",
            "features": ["ë…¸ì´ì¦ˆìº”ìŠ¬ë§", "30ì‹œê°„ ë°°í„°ë¦¬", "ë°©ìˆ˜"],
            "target_audience": "2030 ì§ì¥ì¸"
        },
        options={
            "tone": "professional"
        }
    )

    # _enhance_payload í˜¸ì¶œí•˜ì—¬ í™•ì¸
    enhanced_payload = agent._enhance_payload(request)

    print("\nğŸ“¦ Enhanced Payload:")
    print("-" * 70)
    for key, value in enhanced_payload.items():
        if key.startswith("_"):
            print(f"  {key}: {value}")

    # ê²€ì¦
    assert "_instructions" in enhanced_payload, "âŒ _instructions ì—†ìŒ"
    assert "_output_structure" in enhanced_payload, "âŒ _output_structure ì—†ìŒ"
    assert "_tone_guide" in enhanced_payload, "âŒ _tone_guide ì—†ìŒ"

    print("\nâœ… ëª¨ë“  Context Engineering í•„ë“œê°€ ì •ìƒì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ì‹¤ì œ Agent ì‹¤í–‰ (Mock ëª¨ë“œ)
    print("\nğŸš€ Agent ì‹¤í–‰ í…ŒìŠ¤íŠ¸...")
    try:
        response = await agent.execute(request)

        print(f"\nâœ… Agent ì‹¤í–‰ ì„±ê³µ!")
        print(f"  - Agent: {response.agent}")
        print(f"  - Task: {response.task}")
        print(f"  - Outputs: {len(response.outputs)}ê°œ")
        print(f"  - LLM Provider: {response.meta.get('llm_provider')}")
        print(f"  - LLM Model: {response.meta.get('llm_model')}")

        if response.outputs:
            output = response.outputs[0]
            print(f"\nğŸ“ ìƒì„±ëœ ê²°ê³¼:")
            print(f"  Type: {output.type}")
            print(f"  Name: {output.name}")
            if output.type == "json":
                import json
                print(f"  Value:\n{json.dumps(output.value, indent=2, ensure_ascii=False)}")

    except Exception as e:
        print(f"âŒ Agent ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()

    print("\n" + "=" * 70)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)


if __name__ == "__main__":
    asyncio.run(test_context_engineering())
