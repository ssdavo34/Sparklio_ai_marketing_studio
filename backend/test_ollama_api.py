"""
Ollama LLM Gateway API í…ŒìŠ¤íŠ¸

2025-11-16
"""
import httpx
import asyncio
import json


async def test_ollama_text_mode():
    """Ollama Provider - í…ìŠ¤íŠ¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("Test 1: Ollama Provider - Text Mode")
    print("=" * 60)

    url = "http://localhost:8001/api/v1/llm/generate"
    data = {
        "role": "copywriter",
        "task": "product_detail",
        "payload": {
            "product_name": "ë¬´ì„  ì´ì–´í°",
            "features": ["ë…¸ì´ì¦ˆ ìº”ìŠ¬ë§", "24ì‹œê°„ ë°°í„°ë¦¬"]
        },
        "mode": "text"
    }

    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(url, json=data)
            response.raise_for_status()

            result = response.json()
            print(f"\nâœ… Status: {response.status_code}")
            print(f"\nProvider: {result['provider']}")
            print(f"Model: {result['model']}")
            print(f"\nOutput Type: {result['output']['type']}")
            print(f"Output Value:\n{result['output']['value'][:200]}...")
            print(f"\nUsage: {result['usage']}")

    except Exception as e:
        print(f"âŒ Error: {e}")


async def test_ollama_json_mode():
    """Ollama Provider - JSON ëª¨ë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("Test 2: Ollama Provider - JSON Mode")
    print("=" * 60)

    url = "http://localhost:8001/api/v1/llm/generate"
    data = {
        "role": "copywriter",
        "task": "product_detail",
        "payload": {
            "product_name": "ë¬´ì„  ì´ì–´í°",
            "features": ["ë…¸ì´ì¦ˆ ìº”ìŠ¬ë§", "24ì‹œê°„ ë°°í„°ë¦¬"]
        },
        "mode": "json"
    }

    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(url, json=data)
            response.raise_for_status()

            result = response.json()
            print(f"\nâœ… Status: {response.status_code}")
            print(f"\nProvider: {result['provider']}")
            print(f"Model: {result['model']}")
            print(f"\nOutput Type: {result['output']['type']}")
            print(f"Output Value:")
            print(json.dumps(result['output']['value'], indent=2, ensure_ascii=False))
            print(f"\nUsage: {result['usage']}")

    except Exception as e:
        print(f"âŒ Error: {e}")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\nğŸš€ Ollama LLM Gateway API í…ŒìŠ¤íŠ¸ ì‹œì‘\n")

    # Test 1: Text Mode
    await test_ollama_text_mode()

    # Test 2: JSON Mode
    await test_ollama_json_mode()

    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
