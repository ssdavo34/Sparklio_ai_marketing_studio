#!/usr/bin/env python3
"""
LLM Router í†µí•© í…ŒìŠ¤íŠ¸ - AíŒ€ QA
BíŒ€ ìˆ˜ì •ì‚¬í•­ ê²€ì¦ ë° ì „ì²´ ë¼ìš°íŒ… ë¡œì§ í…ŒìŠ¤íŠ¸
"""

import asyncio
import sys
from pathlib import Path
from typing import Dict, List, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from app.services.llm.router import LLMRouter
from app.services.llm.gateway import LLMGateway
from app.core.config import settings

class LLMRouterTester:
    """LLM Router í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.router = LLMRouter()
        self.gateway = LLMGateway()
        self.test_results = []

    async def test_model_provider_mapping(self):
        """ëª¨ë¸-í”„ë¡œë°”ì´ë” ë§¤í•‘ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ ëª¨ë¸-í”„ë¡œë°”ì´ë” ë§¤í•‘ í…ŒìŠ¤íŠ¸")
        print("-" * 60)

        test_cases = [
            # OpenAI ëª¨ë¸ë“¤
            ("gpt-4o", "openai", "âœ… P0 ì´ìŠˆ í•´ê²° í™•ì¸"),
            ("gpt-4o-mini", "openai", None),
            ("gpt-3.5-turbo", "openai", None),

            # Gemini ëª¨ë¸ë“¤ (BíŒ€ ìˆ˜ì •ì‚¬í•­)
            ("gemini-2.5-flash", "gemini", "âœ… BíŒ€ ìˆ˜ì •ì‚¬í•­"),
            ("gemini-2.0-flash", "gemini", None),
            ("gemini-1.5-pro", "gemini", None),

            # Claude ëª¨ë¸ë“¤
            ("claude-3-5-haiku-20241022", "anthropic", None),
            ("claude-3-sonnet-20240229", "anthropic", None),

            # Ollama ë¡œì»¬ ëª¨ë¸ë“¤
            ("llama3", "ollama", None),
            ("qwen2.5:14b", "ollama", None),
        ]

        passed = 0
        failed = 0

        for model, expected_provider, note in test_cases:
            try:
                actual_model, actual_provider = self.router.route(
                    role="copywriter",
                    task="test",
                    override_model=model
                )

                if actual_provider == expected_provider:
                    status = "âœ… PASS"
                    passed += 1
                else:
                    status = f"âŒ FAIL (got {actual_provider})"
                    failed += 1

                result = f"{model:30} â†’ {actual_provider:10} {status}"
                if note:
                    result += f"  [{note}]"

                print(result)
                self.test_results.append((model, status == "âœ… PASS"))

            except Exception as e:
                status = f"âŒ ERROR: {str(e)[:30]}"
                failed += 1
                print(f"{model:30} â†’ {status}")
                self.test_results.append((model, False))

        print(f"\nê²°ê³¼: {passed}/{passed+failed} í…ŒìŠ¤íŠ¸ í†µê³¼")
        return failed == 0

    async def test_health_check(self):
        """LLM í”„ë¡œë°”ì´ë” í—¬ìŠ¤ì²´í¬"""
        print("\nğŸ“‹ LLM í”„ë¡œë°”ì´ë” í—¬ìŠ¤ì²´í¬")
        print("-" * 60)

        try:
            health_status = await self.gateway.health_check()

            for provider, status in health_status.items():
                icon = "âœ…" if status["status"] == "healthy" else "âŒ"
                print(f"{icon} {provider:15} - {status['status']:10}", end="")

                if status.get("message"):
                    print(f" ({status['message']})")
                else:
                    print()

                # Gemini íŠ¹ë³„ ì²´í¬ (BíŒ€ ìˆ˜ì •ì‚¬í•­)
                if provider == "gemini":
                    if status["status"] == "healthy":
                        print(f"    â†’ BíŒ€ ìˆ˜ì • í›„ ì •ìƒ ì‘ë™ í™•ì¸")
                    else:
                        print(f"    â†’ âš ï¸ BíŒ€ ìˆ˜ì • í›„ì—ë„ ë¬¸ì œ ì§€ì†")
                        print(f"    â†’ API í‚¤ í™•ì¸ í•„ìš”: {settings.GOOGLE_API_KEY[:10]}...")

        except Exception as e:
            print(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
            return False

        return True

    async def test_chat_api_integration(self):
        """Chat API í†µí•© í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ Chat API í†µí•© í…ŒìŠ¤íŠ¸")
        print("-" * 60)

        test_messages = [
            ("gpt-4o", "í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€"),
            ("gemini-2.5-flash", "Gemini í…ŒìŠ¤íŠ¸"),
        ]

        for model, message in test_messages:
            print(f"\ní…ŒìŠ¤íŠ¸: {model}")
            try:
                response = await self.gateway.chat(
                    messages=[{"role": "user", "content": message}],
                    model=model,
                    temperature=0.5
                )

                if response and len(response) > 0:
                    print(f"  âœ… ì‘ë‹µ ì„±ê³µ ({len(response)} ê¸€ì)")
                    print(f"     {response[:100]}...")
                else:
                    print(f"  âŒ ë¹ˆ ì‘ë‹µ")

            except Exception as e:
                error_msg = str(e)
                if "404" in error_msg and "not found" in error_msg:
                    print(f"  âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    if model == "gpt-4o" and "gemini" in error_msg.lower():
                        print(f"  ğŸ’¡ P0 ì´ìŠˆ ì¬ë°œ: gpt-4oê°€ Geminië¡œ ë¼ìš°íŒ…ë¨")
                else:
                    print(f"  âŒ ì—ëŸ¬: {error_msg[:100]}")

    async def test_fallback_mechanism(self):
        """í´ë°± ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ“‹ í´ë°± ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸")
        print("-" * 60)

        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        try:
            model, provider = self.router.route(
                role="copywriter",
                task="test",
                override_model="non-existent-model"
            )
            print(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ â†’ {model} ({provider})")
            print("  âœ… í´ë°± ì •ìƒ ì‘ë™")
        except Exception as e:
            print(f"  âŒ í´ë°± ì‹¤íŒ¨: {e}")

    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ§ª LLM Router í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ - AíŒ€ QA")
        print("=" * 60)

        all_passed = True

        # 1. ëª¨ë¸-í”„ë¡œë°”ì´ë” ë§¤í•‘
        if not await self.test_model_provider_mapping():
            all_passed = False

        # 2. í—¬ìŠ¤ì²´í¬
        if not await self.test_health_check():
            all_passed = False

        # 3. Chat API í†µí•©
        await self.test_chat_api_integration()

        # 4. í´ë°± ë©”ì»¤ë‹ˆì¦˜
        await self.test_fallback_mechanism()

        # ìµœì¢… ê²°ê³¼
        print("\n" + "=" * 60)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)

        if all_passed:
            print("âœ… ëª¨ë“  í•„ìˆ˜ í…ŒìŠ¤íŠ¸ í†µê³¼")
            print("\nğŸ“‹ BíŒ€ ìˆ˜ì •ì‚¬í•­ ê²€ì¦ ê²°ê³¼:")
            print("  âœ… gemini-2.5-flash-preview â†’ gemini-2.5-flash ë³€ê²½ í™•ì¸")
            print("  âœ… Gemini ëª¨ë¸ ë¼ìš°íŒ… ì •ìƒ")
            print("\nğŸ“‹ P0 ì´ìŠˆ ê²€ì¦ ê²°ê³¼:")
            print("  âœ… gpt-4o â†’ OpenAI Provider ë§¤í•‘ ì •ìƒ")
        else:
            print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            print("\nâš ï¸ ì¶”ê°€ ì¡°ì¹˜ í•„ìš”:")
            print("  1. ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ í™•ì¸")
            print("  2. ì—ëŸ¬ ë¡œê·¸ ë¶„ì„")
            print("  3. BíŒ€ê³¼ í˜‘ì˜í•˜ì—¬ ìˆ˜ì •")

        return all_passed

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = LLMRouterTester()
    success = await tester.run_all_tests()

    print("\n" + "=" * 60)
    print("ğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("=" * 60)

    sys.exit(0 if success else 1)

if __name__ == "__main__":
    asyncio.run(main())