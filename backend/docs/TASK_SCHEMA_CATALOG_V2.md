# Task & Schema Catalog v2

**ì‘ì„±ì¼**: 2025-11-23
**ì‘ì„±ì**: BíŒ€ (Backend) + AíŒ€ (QA)
**ë²„ì „**: 2.0
**ëª©ì **: ëª¨ë“  Agentì˜ Task ì •ì˜ ë° Input/Output ìŠ¤í‚¤ë§ˆ í‘œì¤€í™”

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [CopywriterAgent Tasks](#copywriteragent-tasks)
3. [StrategistAgent Tasks](#strategistagent-tasks)
4. [ReviewerAgent Tasks](#revieweragent-tasks)
5. [DesignerAgent Tasks](#designeragent-tasks)
6. [OptimizerAgent Tasks](#optimizeragent-tasks)
7. [Validation Pipeline](#validation-pipeline)
8. [Golden Set ê²½ë¡œ ê·œì¹™](#golden-set-ê²½ë¡œ-ê·œì¹™)

---

## ê°œìš”

### ìŠ¤í‚¤ë§ˆ í‘œì¤€í™” ëª©ì 

1. **íƒ€ì… ì•ˆì „ì„±**: TypeScript ì¸í„°í˜ì´ìŠ¤ë¡œ í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ íƒ€ì… ì¼ì¹˜
2. **ìë™ ê²€ì¦**: Pydantic ëª¨ë¸ë¡œ ëŸ°íƒ€ì„ ê²€ì¦
3. **ë¬¸ì„œí™”**: ëª¨ë“  Agent Taskì˜ Input/Output ëª…ì„¸ ì¤‘ì•™ ê´€ë¦¬
4. **Golden Set**: ê° Taskë³„ ê¸°ëŒ€ ì¶œë ¥ ìƒ˜í”Œ ì •ì˜

### í‘œê¸° ê·œì¹™

- **Input Schema**: Agent ì‹¤í–‰ ì‹œ í•„ìš”í•œ ì…ë ¥ ë°ì´í„°
- **Output Schema**: Agentê°€ ë°˜í™˜í•˜ëŠ” ì¶œë ¥ ë°ì´í„°
- **TypeScript Interface**: í”„ë¡ íŠ¸ì—”ë“œìš© íƒ€ì… ì •ì˜
- **Pydantic Model**: ë°±ì—”ë“œìš© ê²€ì¦ ëª¨ë¸
- **Validation Rules**: 4ë‹¨ê³„ ê²€ì¦ íŒŒì´í”„ë¼ì¸ ê·œì¹™

---

## CopywriterAgent Tasks

### Task 1: `product_detail`

#### ì„¤ëª…
ì œí’ˆì˜ ìƒì„¸ ì„¤ëª… í…ìŠ¤íŠ¸ ìƒì„± (headline, subheadline, body, bullets, cta)

#### Input Schema

**TypeScript Interface**:
```typescript
interface ProductDetailInput {
  product_name: string;           // ì œí’ˆëª…
  features: string[];              // ì£¼ìš” íŠ¹ì§• (ìµœëŒ€ 5ê°œ)
  target_audience: string;         // íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤
  category?: string;               // ì¹´í…Œê³ ë¦¬ (optional)
  brand_voice?: string;            // ë¸Œëœë“œ í†¤ (optional)
}
```

**Pydantic Model**:
```python
from pydantic import BaseModel, Field

class ProductDetailInput(BaseModel):
    product_name: str = Field(..., min_length=1, max_length=100)
    features: list[str] = Field(..., min_items=1, max_items=5)
    target_audience: str = Field(..., min_length=1, max_length=100)
    category: str | None = None
    brand_voice: str | None = None
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface ProductDetailOutput {
  headline: string;                // 5-20ì
  subheadline: string;             // 10-30ì
  body: string;                    // 20-80ì
  bullets: string[];               // 3ê°œ, ê° 20ì ì´ë‚´
  cta: string;                     // 4-15ì
}
```

**Pydantic Model**:
```python
from pydantic import BaseModel, Field, validator

class ProductDetailOutput(BaseModel):
    headline: str = Field(..., min_length=5, max_length=20)
    subheadline: str = Field(..., min_length=10, max_length=30)
    body: str = Field(..., min_length=20, max_length=80)
    bullets: list[str] = Field(..., min_items=3, max_items=3)
    cta: str = Field(..., min_length=4, max_length=15)

    @validator("bullets")
    def validate_bullets(cls, v):
        for bullet in v:
            if len(bullet) > 20:
                raise ValueError(f"Bullet exceeds 20 chars: {bullet}")
        return v

    @validator("headline", "subheadline", "body", "cta")
    def check_korean(cls, v):
        korean_chars = sum(1 for c in v if '\uac00' <= c <= '\ud7a3')
        total_chars = len(v.replace(" ", ""))
        if total_chars > 0 and korean_chars / total_chars < 0.5:
            raise ValueError(f"Korean ratio < 50%: {v}")
        return v
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ëª¨ë“  í•„ë“œ íƒ€ì…/ê¸¸ì´ ì¼ì¹˜ |
| **2. Length** | ê° í•„ë“œ ê¸¸ì´ ì œì•½ | headline â‰¤20, subheadline 10-30, body 20-80, bullets â‰¤20, cta 4-15 |
| **3. Language** | í•œêµ­ì–´ ë¹„ìœ¨ ê²€ì¦ | ê° í•„ë“œ í•œêµ­ì–´ ë¹„ìœ¨ â‰¥50% |
| **4. Quality** | ê¸°ë³¸ê°’ í´ë°± ê°ì§€ | subheadline != "ì œí’ˆ ì„¤ëª…" |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/copywriter_product_detail_golden_set.json
```

#### ì˜ˆì‹œ

**Input**:
```json
{
  "product_name": "ìš¸íŠ¸ë¼ ë¬´ì„  ì´ì–´í° Pro",
  "features": ["ANC ë…¸ì´ì¦ˆìº”ìŠ¬ë§", "30ì‹œê°„ ë°°í„°ë¦¬", "IPX7 ë°©ìˆ˜"],
  "target_audience": "2030 ì§ì¥ì¸",
  "category": "ì „ìì œí’ˆ"
}
```

**Output**:
```json
{
  "headline": "ì™„ë²½í•œ ì†ŒìŒ ì°¨ë‹¨ì˜ ì‹œì‘",
  "subheadline": "í”„ë¦¬ë¯¸ì—„ ANC ê¸°ìˆ ë¡œ ì§‘ì¤‘ë ¥ ê·¹ëŒ€í™”",
  "body": "ìš¸íŠ¸ë¼ ë¬´ì„  ì´ì–´í° ProëŠ” 30ì‹œê°„ ë°°í„°ë¦¬ì™€ IPX7 ë°©ìˆ˜ë¡œ ì–¸ì œ ì–´ë””ì„œë‚˜ ìµœê³ ì˜ ì‚¬ìš´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
  "bullets": ["ANC ë…¸ì´ì¦ˆìº”ìŠ¬ë§", "30ì‹œê°„ ë°°í„°ë¦¬", "IPX7 ë°©ìˆ˜"],
  "cta": "ì§€ê¸ˆ ë°”ë¡œ ì²´í—˜í•˜ê¸°"
}
```

---

### Task 2: `sns`

#### ì„¤ëª…
SNS í”Œë«í¼ìš© ì§§ì€ ì½˜í…ì¸  ìƒì„± (post, hashtags, cta)

#### Input Schema

**TypeScript Interface**:
```typescript
interface SNSInput {
  topic: string;                   // ì£¼ì œ
  platform?: 'instagram' | 'facebook' | 'twitter' | 'linkedin'; // í”Œë«í¼
  tone?: 'casual' | 'professional' | 'friendly'; // í†¤
  target_audience?: string;        // íƒ€ê²Ÿ
}
```

**Pydantic Model**:
```python
from pydantic import BaseModel, Field
from typing import Literal

class SNSInput(BaseModel):
    topic: str = Field(..., min_length=1, max_length=200)
    platform: Literal['instagram', 'facebook', 'twitter', 'linkedin'] | None = None
    tone: Literal['casual', 'professional', 'friendly'] | None = None
    target_audience: str | None = None
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface SNSOutput {
  post: string;                    // 80-120ì
  hashtags: string[];              // 5-10ê°œ
  cta?: string;                    // ì„ íƒì  CTA
}
```

**Pydantic Model**:
```python
class SNSOutput(BaseModel):
    post: str = Field(..., min_length=80, max_length=120)
    hashtags: list[str] = Field(..., min_items=5, max_items=10)
    cta: str | None = Field(None, max_length=20)

    @validator("hashtags")
    def validate_hashtags(cls, v):
        for tag in v:
            if not tag.startswith("#"):
                raise ValueError(f"Hashtag must start with #: {tag}")
            if len(tag) > 20:
                raise ValueError(f"Hashtag too long: {tag}")
        return v
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ëª¨ë“  í•„ë“œ íƒ€ì… ì¼ì¹˜ |
| **2. Length** | post 80-120ì, hashtags 5-10ê°œ | ê¸¸ì´ ë²”ìœ„ ì¤€ìˆ˜ |
| **3. Language** | í•œêµ­ì–´ ë¹„ìœ¨ â‰¥50% (postë§Œ) | hashtagsëŠ” ì˜ë¬¸ í—ˆìš© |
| **4. Quality** | hashtagsê°€ #ìœ¼ë¡œ ì‹œì‘ | ëª¨ë“  hashtags # í¬í•¨ |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/copywriter_sns_golden_set.json
```

---

### Task 3: `brand_message`

#### ì„¤ëª…
ë¸Œëœë“œì˜ í•µì‹¬ ë©”ì‹œì§€ ë° ê°€ì¹˜ í‘œí˜„ (tagline, message, values)

#### Input Schema

**TypeScript Interface**:
```typescript
interface BrandMessageInput {
  brand_name: string;
  industry: string;
  target_market: string;
  core_values?: string[];
}
```

**Pydantic Model**:
```python
class BrandMessageInput(BaseModel):
    brand_name: str = Field(..., min_length=1, max_length=50)
    industry: str = Field(..., min_length=1, max_length=100)
    target_market: str = Field(..., min_length=1, max_length=100)
    core_values: list[str] | None = None
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface BrandMessageOutput {
  tagline: string;                 // 10ì ì´ë‚´
  message: string;                 // 50-100ì
  values: string[];                // 3ê°œ í•µì‹¬ ê°€ì¹˜
  promise?: string;                // ë¸Œëœë“œ ì•½ì† (ì„ íƒ)
}
```

**Pydantic Model**:
```python
class BrandMessageOutput(BaseModel):
    tagline: str = Field(..., min_length=3, max_length=10)
    message: str = Field(..., min_length=50, max_length=100)
    values: list[str] = Field(..., min_items=3, max_items=3)
    promise: str | None = Field(None, max_length=50)

    @validator("values")
    def validate_values(cls, v):
        for value in v:
            if len(value) > 15:
                raise ValueError(f"Value too long: {value}")
        return v
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ëª¨ë“  í•„ë“œ íƒ€ì…/ê¸¸ì´ ì¼ì¹˜ |
| **2. Length** | tagline â‰¤10, message 50-100, values 3ê°œ ê° â‰¤15 | ê¸¸ì´ ì¤€ìˆ˜ |
| **3. Language** | í•œêµ­ì–´ ë¹„ìœ¨ â‰¥90% | ë¸Œëœë“œ ë©”ì‹œì§€ëŠ” ìˆœí•œêµ­ì–´ |
| **4. Quality** | ì¤‘ë³µ ê°€ì¹˜ ì—†ìŒ | valuesì— ì¤‘ë³µ ì—†ìŒ |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/copywriter_brand_message_golden_set.json
```

---

## StrategistAgent Tasks

### Task 1: `brand_kit`

#### ì„¤ëª…
ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° ì „ì²´ ì •ì˜ (positioning, persona, messages, tone)

#### Input Schema

**TypeScript Interface**:
```typescript
interface BrandKitInput {
  brand_name: string;
  industry: string;
  target_market: string;
  competitors?: string[];
  unique_value?: string;
}
```

**Pydantic Model**:
```python
class BrandKitInput(BaseModel):
    brand_name: str = Field(..., min_length=1, max_length=50)
    industry: str = Field(..., min_length=1, max_length=100)
    target_market: str = Field(..., min_length=1, max_length=100)
    competitors: list[str] | None = None
    unique_value: str | None = None
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface BrandKitOutput {
  brand_positioning: string;       // ë¸Œëœë“œ í¬ì§€ì…”ë‹ (100-200ì)
  target_persona: {
    demographics: string;           // ì¸êµ¬í†µê³„
    psychographics: string;         // ì‹¬ë¦¬í†µê³„
    pain_points: string[];          // í˜ì¸í¬ì¸íŠ¸ 3ê°œ
    goals: string[];                // ëª©í‘œ 3ê°œ
  };
  key_messages: string[];          // í•µì‹¬ ë©”ì‹œì§€ 3-5ê°œ
  tone_guidelines: {
    do: string[];                   // ê¶Œì¥ í†¤ 3ê°œ
    dont: string[];                 // ê¸ˆì§€ í†¤ 3ê°œ
  };
  differentiation: string;         // ì°¨ë³„ì  (50-100ì)
}
```

**Pydantic Model**:
```python
class TargetPersona(BaseModel):
    demographics: str = Field(..., max_length=200)
    psychographics: str = Field(..., max_length=200)
    pain_points: list[str] = Field(..., min_items=3, max_items=3)
    goals: list[str] = Field(..., min_items=3, max_items=3)

class ToneGuidelines(BaseModel):
    do: list[str] = Field(..., min_items=3, max_items=3)
    dont: list[str] = Field(..., min_items=3, max_items=3)

class BrandKitOutput(BaseModel):
    brand_positioning: str = Field(..., min_length=100, max_length=200)
    target_persona: TargetPersona
    key_messages: list[str] = Field(..., min_items=3, max_items=5)
    tone_guidelines: ToneGuidelines
    differentiation: str = Field(..., min_length=50, max_length=100)
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ì¤‘ì²© êµ¬ì¡° í¬í•¨ ëª¨ë“  í•„ë“œ ê²€ì¦ |
| **2. Length** | ê° í•„ë“œ ê¸¸ì´ ì œì•½ | positioning 100-200, differentiation 50-100 |
| **3. Language** | í•œêµ­ì–´ ë¹„ìœ¨ â‰¥90% | ì „ëµ ë¬¸ì„œëŠ” ìˆœí•œêµ­ì–´ |
| **4. Quality** | persona, tone ì¼ê´€ì„± | pain_pointsì™€ goalsê°€ ë…¼ë¦¬ì  ì—°ê²° |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/strategist_brand_kit_golden_set.json
```

---

## ReviewerAgent Tasks

### Task 1: `content_review`

#### ì„¤ëª…
ì½˜í…ì¸  í’ˆì§ˆ ê²€í†  ë° ê°œì„  ì œì•ˆ (scores, strengths, weaknesses, improvements)

#### Input Schema

**TypeScript Interface**:
```typescript
interface ContentReviewInput {
  content: {
    headline?: string;
    subheadline?: string;
    body: string;                  // í•„ìˆ˜
    bullets?: string[];
    cta?: string;
  };
  context?: {
    product_name?: string;
    target_audience?: string;
    tone?: string;
  };
}
```

**Pydantic Model**:
```python
class ContentToReview(BaseModel):
    headline: str | None = None
    subheadline: str | None = None
    body: str = Field(..., min_length=1)  # í•„ìˆ˜
    bullets: list[str] | None = None
    cta: str | None = None

class ReviewContext(BaseModel):
    product_name: str | None = None
    target_audience: str | None = None
    tone: str | None = None

class ContentReviewInput(BaseModel):
    content: ContentToReview
    context: ReviewContext | None = None
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface ContentReviewOutput {
  overall_score: number;           // 1-10
  dimension_scores: {
    clarity: number;               // 1-10
    persuasiveness: number;        // 1-10
    tone_match: number;            // 1-10
    grammar: number;               // 1-10
  };
  strengths: string[];             // 3ê°œ ê°•ì 
  weaknesses: string[];            // 3ê°œ ì•½ì 
  improvements: string[];          // 3-5ê°œ êµ¬ì²´ì  ê°œì„ ì•ˆ
  recommendation: 'approve' | 'revise_minor' | 'revise_major' | 'reject';
}
```

**Pydantic Model**:
```python
from pydantic import validator
from typing import Literal

class DimensionScores(BaseModel):
    clarity: int = Field(..., ge=1, le=10)
    persuasiveness: int = Field(..., ge=1, le=10)
    tone_match: int = Field(..., ge=1, le=10)
    grammar: int = Field(..., ge=1, le=10)

class ContentReviewOutput(BaseModel):
    overall_score: int = Field(..., ge=1, le=10)
    dimension_scores: DimensionScores
    strengths: list[str] = Field(..., min_items=3, max_items=3)
    weaknesses: list[str] = Field(..., min_items=3, max_items=3)
    improvements: list[str] = Field(..., min_items=3, max_items=5)
    recommendation: Literal['approve', 'revise_minor', 'revise_major', 'reject']

    @validator("overall_score")
    def validate_overall_score(cls, v, values):
        # overall_scoreëŠ” dimension_scoresì˜ í‰ê· ê³¼ ìœ ì‚¬í•´ì•¼ í•¨
        if "dimension_scores" in values:
            dim_scores = values["dimension_scores"]
            avg = (dim_scores.clarity + dim_scores.persuasiveness +
                   dim_scores.tone_match + dim_scores.grammar) / 4
            if abs(v - avg) > 2:
                raise ValueError(f"overall_score ({v}) too far from dimension average ({avg:.1f})")
        return v
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ëª¨ë“  ì ìˆ˜ 1-10 ë²”ìœ„ |
| **2. Length** | strengths/weaknesses ê° 3ê°œ, improvements 3-5ê°œ | ê°œìˆ˜ ì¤€ìˆ˜ |
| **3. Language** | í•œêµ­ì–´ ë¹„ìœ¨ â‰¥95% | ë¦¬ë·°ëŠ” ìˆœí•œêµ­ì–´ |
| **4. Quality** | overall_scoreì™€ dimension_scores ì¼ê´€ì„± | í‰ê·  ì°¨ì´ â‰¤2 |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/reviewer_content_review_golden_set.json
```

---

## DesignerAgent Tasks

### Task 1: `product_image`

#### ì„¤ëª…
ì œí’ˆ ì´ë¯¸ì§€ ìƒì„± (ComfyUI ë˜ëŠ” NanoBanana ì‚¬ìš©)

#### Input Schema

**TypeScript Interface**:
```typescript
interface ProductImageInput {
  product_name: string;
  style?: 'professional' | 'lifestyle' | 'minimalist' | 'vibrant';
  background?: 'white' | 'gradient' | 'scene' | 'transparent';
  width?: number;                  // ê¸°ë³¸ 600
  height?: number;                 // ê¸°ë³¸ 400
}
```

**Pydantic Model**:
```python
from typing import Literal

class ProductImageInput(BaseModel):
    product_name: str = Field(..., min_length=1, max_length=100)
    style: Literal['professional', 'lifestyle', 'minimalist', 'vibrant'] | None = None
    background: Literal['white', 'gradient', 'scene', 'transparent'] | None = None
    width: int = Field(600, ge=100, le=2000)
    height: int = Field(400, ge=100, le=2000)
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface ProductImageOutput {
  type: 'base64' | 'url';
  data: string;                    // base64 string or URL
  format: 'png' | 'jpg' | 'webp';
  dimensions: {
    width: number;
    height: number;
  };
  english_prompt: string;          // ìƒì„±ì— ì‚¬ìš©ëœ ì˜ë¬¸ í”„ë¡¬í”„íŠ¸
  negative_prompt?: string;
  provider: 'comfyui' | 'nanobanana' | 'mock';
}
```

**Pydantic Model**:
```python
class ImageDimensions(BaseModel):
    width: int = Field(..., ge=100)
    height: int = Field(..., ge=100)

class ProductImageOutput(BaseModel):
    type: Literal['base64', 'url']
    data: str = Field(..., min_length=1)
    format: Literal['png', 'jpg', 'webp']
    dimensions: ImageDimensions
    english_prompt: str = Field(..., min_length=10)
    negative_prompt: str | None = None
    provider: Literal['comfyui', 'nanobanana', 'mock']
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ëª¨ë“  í•„ë“œ íƒ€ì… ì¼ì¹˜ |
| **2. Length** | english_prompt â‰¥10ì | í”„ë¡¬í”„íŠ¸ ìµœì†Œ ê¸¸ì´ |
| **3. Image** | base64/URL í˜•ì‹ ê²€ì¦ | ì´ë¯¸ì§€ ë°ì´í„° ìœ íš¨ì„± |
| **4. Quality** | dimensions ì‹¤ì œ ì´ë¯¸ì§€ì™€ ì¼ì¹˜ | ë©”íƒ€ë°ì´í„° ì •í™•ì„± |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/designer_product_image_golden_set.json
```

---

## OptimizerAgent Tasks

### Task 1: `conversion_optimize`

#### ì„¤ëª…
ì½˜í…ì¸ ë¥¼ ì „í™˜ìœ¨ ìµœì í™” ê´€ì ì—ì„œ ê°œì„ 

#### Input Schema

**TypeScript Interface**:
```typescript
interface ConversionOptimizeInput {
  content: {
    headline: string;
    body: string;
    cta?: string;
  };
  review_feedback?: {
    weaknesses: string[];
    improvements: string[];
  };
}
```

**Pydantic Model**:
```python
class ContentToOptimize(BaseModel):
    headline: str = Field(..., min_length=1)
    body: str = Field(..., min_length=1)
    cta: str | None = None

class ReviewFeedback(BaseModel):
    weaknesses: list[str]
    improvements: list[str]

class ConversionOptimizeInput(BaseModel):
    content: ContentToOptimize
    review_feedback: ReviewFeedback | None = None
```

#### Output Schema

**TypeScript Interface**:
```typescript
interface ConversionOptimizeOutput {
  optimized_content: {
    headline: string;
    body: string;
    cta: string;
  };
  improvements: string[];          // ì ìš©í•œ ê°œì„  ì‚¬í•­ 3-5ê°œ
  before_after: {
    headline: { before: string; after: string; reason: string; };
    body: { before: string; after: string; reason: string; };
    cta?: { before: string; after: string; reason: string; };
  };
  expected_impact: string;         // ì˜ˆìƒ íš¨ê³¼ (50-100ì)
}
```

**Pydantic Model**:
```python
class OptimizedContent(BaseModel):
    headline: str = Field(..., min_length=5, max_length=20)
    body: str = Field(..., min_length=20, max_length=80)
    cta: str = Field(..., min_length=4, max_length=15)

class BeforeAfter(BaseModel):
    before: str
    after: str
    reason: str = Field(..., min_length=10, max_length=100)

class BeforeAfterComparison(BaseModel):
    headline: BeforeAfter
    body: BeforeAfter
    cta: BeforeAfter | None = None

class ConversionOptimizeOutput(BaseModel):
    optimized_content: OptimizedContent
    improvements: list[str] = Field(..., min_items=3, max_items=5)
    before_after: BeforeAfterComparison
    expected_impact: str = Field(..., min_length=50, max_length=100)
```

#### Validation Rules

| Stage | ê·œì¹™ | í†µê³¼ ì¡°ê±´ |
|-------|------|-----------|
| **1. Schema** | Pydantic ëª¨ë¸ ê²€ì¦ | ëª¨ë“  í•„ë“œ íƒ€ì…/ê¸¸ì´ ì¼ì¹˜ |
| **2. Length** | optimized_content ê¸¸ì´ ì œì•½ | headline 5-20, body 20-80, cta 4-15 |
| **3. Language** | í•œêµ­ì–´ ë¹„ìœ¨ â‰¥90% | reasonê³¼ expected_impact í•œêµ­ì–´ |
| **4. Quality** | before vs after ë¹„êµ | afterê°€ beforeì™€ ë‹¤ë¦„, reason ë…¼ë¦¬ì  |

#### Golden Set ê²½ë¡œ
```
tests/golden_sets/optimizer_conversion_optimize_golden_set.json
```

---

## Validation Pipeline

### 4ë‹¨ê³„ ê²€ì¦ í”„ë¡œì„¸ìŠ¤

ëª¨ë“  Agent ì¶œë ¥ì€ ë‹¤ìŒ 4ë‹¨ê³„ ê²€ì¦ì„ ê±°ì¹©ë‹ˆë‹¤:

#### Stage 1: Schema Validation (Pydantic)
- Pydantic ëª¨ë¸ë¡œ íƒ€ì… ë° í•„ë“œ ì¡´ì¬ ê²€ì¦
- ê¸¸ì´ ì œì•½ (min_length, max_length) ê²€ì¦
- Enum ê°’ ê²€ì¦ (Literal íƒ€ì…)
- ì¤‘ì²© êµ¬ì¡° ê²€ì¦

**êµ¬í˜„**:
```python
def validate_schema(output: dict, task: str) -> StageResult:
    schema_class = get_schema_for_task(task)
    try:
        schema_class(**output)
        return StageResult(stage="schema", passed=True, issues=[])
    except ValidationError as e:
        return StageResult(stage="schema", passed=False, issues=e.errors())
```

#### Stage 2: Length Validation
- ê° í•„ë“œì˜ ì‹¤ì œ ê¸¸ì´ê°€ ê¸°ëŒ€ ë²”ìœ„ ë‚´ì¸ì§€ ê²€ì¦
- ë°°ì—´ í•„ë“œì˜ í•­ëª© ê°œìˆ˜ ê²€ì¦
- ì¤‘ì²© í•„ë“œì˜ ê¸¸ì´ ê²€ì¦

**êµ¬í˜„**:
```python
def validate_length(output: dict, task: str) -> StageResult:
    rules = get_length_rules(task)
    issues = []

    for field, rule in rules.items():
        value = output.get(field)
        if "max_length" in rule and len(str(value)) > rule["max_length"]:
            issues.append(f"{field} exceeds {rule['max_length']} chars")

    return StageResult(stage="length", passed=len(issues) == 0, issues=issues)
```

#### Stage 3: Language Validation (í•œêµ­ì–´ ì²´í¬)
- í•œê¸€ ë¹„ìœ¨ ê³„ì‚° (í•œê¸€ ë¬¸ì ìˆ˜ / ì „ì²´ ë¬¸ì ìˆ˜)
- ì˜ì–´ ì¶œë ¥ ë°©ì§€ (í•œê¸€ ë¹„ìœ¨ < 50% ì‹œ ì‹¤íŒ¨)
- ì˜ˆì™¸: hashtags, english_prompt ë“±ì€ ì˜ì–´ í—ˆìš©

**êµ¬í˜„**:
```python
import re

def validate_language(output: dict) -> StageResult:
    issues = []

    for field, value in output.items():
        if field in ["hashtags", "english_prompt", "negative_prompt"]:
            continue  # ì˜ì–´ í—ˆìš© í•„ë“œ

        if isinstance(value, str):
            korean_ratio = calculate_korean_ratio(value)
            if korean_ratio < 0.5:
                issues.append(f"{field}: í•œê¸€ ë¹„ìœ¨ {korean_ratio:.0%} (< 50%)")

    return StageResult(stage="language", passed=len(issues) == 0, issues=issues)

def calculate_korean_ratio(text: str) -> float:
    korean_chars = len(re.findall(r'[ê°€-í£]', text))
    total_chars = len(re.sub(r'\s', '', text))
    return korean_chars / total_chars if total_chars > 0 else 0.0
```

#### Stage 4: Quality Validation
- ê¸°ë³¸ê°’ í´ë°± ê°ì§€ (ì˜ˆ: subheadline = "ì œí’ˆ ì„¤ëª…")
- ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì¦ (ì˜ˆ: overall_score vs dimension_scores)
- ì¤‘ë³µ ì œê±° (ì˜ˆ: valuesì— ì¤‘ë³µ ì—†ìŒ)
- í†¤ì•¤ë§¤ë„ˆ ì¼ì¹˜ (tone íŒŒë¼ë¯¸í„°ì™€ ì¶œë ¥ ì¼ì¹˜)

**êµ¬í˜„**:
```python
def validate_quality(output: dict, task: str, input_data: dict) -> StageResult:
    issues = []

    # ê¸°ë³¸ê°’ í´ë°± ê°ì§€
    if task == "product_detail":
        if output.get("subheadline") == "ì œí’ˆ ì„¤ëª…":
            issues.append("subheadline is default fallback value")

    # ë…¼ë¦¬ì  ì¼ê´€ì„± (ReviewerAgent)
    if task == "content_review":
        overall = output.get("overall_score", 0)
        dim_scores = output.get("dimension_scores", {})
        avg = sum(dim_scores.values()) / len(dim_scores) if dim_scores else 0
        if abs(overall - avg) > 2:
            issues.append(f"overall_score ({overall}) inconsistent with dimension avg ({avg:.1f})")

    # ì¤‘ë³µ ì œê±°
    if "values" in output:
        values = output["values"]
        if len(values) != len(set(values)):
            issues.append("Duplicate values detected")

    return StageResult(stage="quality", passed=len(issues) == 0, issues=issues)
```

---

## Golden Set ê²½ë¡œ ê·œì¹™

### ë„¤ì´ë° ê·œì¹™
```
tests/golden_sets/{agent}_{task}_golden_set.json
```

### ì˜ˆì‹œ
- `copywriter_product_detail_golden_set.json`
- `copywriter_sns_golden_set.json`
- `copywriter_brand_message_golden_set.json`
- `strategist_brand_kit_golden_set.json`
- `reviewer_content_review_golden_set.json`
- `designer_product_image_golden_set.json`
- `optimizer_conversion_optimize_golden_set.json`

### Golden Set êµ¬ì¡°
```json
{
  "meta": {
    "agent": "copywriter",
    "task": "product_detail",
    "version": "1.0",
    "created_at": "2025-11-23",
    "created_by": "BíŒ€ (Backend)",
    "description": "CopywriterAgent product_detail ê³¨ë“  ì„¸íŠ¸"
  },
  "golden_cases": [
    {
      "id": "golden_001",
      "scenario": "ë¬´ì„  ì´ì–´í° - í…Œí¬ ì œí’ˆ",
      "input": { ... },
      "expected_output": { ... },
      "quality_metrics": {
        "min_score": 7.0,
        "tone": "professional"
      }
    }
  ],
  "validation_criteria": {
    "similarity_threshold": 0.7,
    "quality_score_threshold": 7.0
  }
}
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [AíŒ€ í’ˆì§ˆ ê²€ì¦ ë³´ê³ ì„œ](A_TEAM_QUALITY_VALIDATION_REPORT_2025-11-23.md)
- [Agent Specifications](AGENT_SPECIFICATIONS.md)
- [Prompt Engineering Guidelines](PROMPT_ENGINEERING_GUIDELINES.md)
- [Golden Set README](../tests/golden_sets/README.md)

---

**ì‘ì„±ì**: BíŒ€ (Backend) + AíŒ€ (QA)
**ê²€í† ì**: AíŒ€ (QA), CíŒ€ (Frontend)
**ìŠ¹ì¸ ë‚ ì§œ**: 2025-11-23 (ìŠ¹ì¸ ëŒ€ê¸°ì¤‘)

**Status**: ğŸŸ¢ **READY FOR IMPLEMENTATION**
