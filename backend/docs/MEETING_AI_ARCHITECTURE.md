# Meeting AI Architecture

**ì‘ì„±ì¼**: 2025-11-24
**ì‘ì„±ì**: BíŒ€ (Backend)
**ë²„ì „**: v2.0 (Transcript Layer í‘œì¤€í™”)

---

## ğŸ“‹ ëª©ì°¨

1. [ì „ì²´ ê°œìš”](#ì „ì²´-ê°œìš”)
2. [í•µì‹¬ ì„¤ê³„ ì›ì¹™](#í•µì‹¬-ì„¤ê³„-ì›ì¹™)
3. [Transcript Layer í‘œì¤€í™”](#transcript-layer-í‘œì¤€í™”)
4. [Whisper STT ì „ëµ](#whisper-stt-ì „ëµ)
5. [ì…ë ¥ ì†ŒìŠ¤ë³„ í”Œë¡œìš°](#ì…ë ¥-ì†ŒìŠ¤ë³„-í”Œë¡œìš°)
6. [í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ](#í•˜ì´ë¸Œë¦¬ë“œ-ì „ëµ)
7. [API êµ¬ì¡°](#api-êµ¬ì¡°)
8. [ìš´ì˜ ê°€ì´ë“œ](#ìš´ì˜-ê°€ì´ë“œ)

---

## ì „ì²´ ê°œìš”

### Meeting AIì˜ ëª©í‘œ

**ì…ë ¥**: ë‹¤ì–‘í•œ í˜•íƒœì˜ íšŒì˜ ë…¹ìŒ/ì˜ìƒ
**ì¶œë ¥**: í†µì¼ëœ íšŒì˜ ë¶„ì„ ê²°ê³¼ (ìš”ì•½, ì•ˆê±´, ê²°ì •ì‚¬í•­, ì•¡ì…˜ì•„ì´í…œ, ìº í˜ì¸ ì•„ì´ë””ì–´)

### ì§€ì› ì…ë ¥ ì†ŒìŠ¤

| ì†ŒìŠ¤ íƒ€ì… | ì„¤ëª… | ì˜ˆì‹œ |
|---------|------|------|
| **íŒŒì¼ ì—…ë¡œë“œ** | ì§ì ‘ ì—…ë¡œë“œí•œ ìŒì„±/ì˜ìƒ íŒŒì¼ | mp4, mp3, m4a, wav |
| **YouTube URL** | YouTube ë™ì˜ìƒ URL | `https://youtube.com/watch?v=...` |
| **ê¸°íƒ€ URL** | ë™ì˜ìƒ/ì˜¤ë””ì˜¤ URL | Vimeo, ì§ì ‘ í˜¸ìŠ¤íŒ… ë“± |
| **(ë¯¸ë˜) ì‹¤ì‹œê°„ ë…¹ìŒ** | WebRTC ì‹¤ì‹œê°„ ë…¹ìŒ | ë¸Œë¼ìš°ì € ë…¹ìŒ |
| **(ë¯¸ë˜) Zoom/Teams** | íšŒì˜ í”Œë«í¼ API ì—°ë™ | Zoom API, Teams API |

### ì²˜ë¦¬ í”Œë¡œìš° (High-Level)

```
[ì‚¬ìš©ì ì…ë ¥]
  â†“
[Audio/Caption Extraction Layer]
  - Caption Fetcher (YouTube, Zoom, ...)
  - Audio Extractor (ffmpeg)
  â†“
[Transcript Layer] â­ï¸ í•µì‹¬ í‘œì¤€í™” ë ˆì´ì–´
  - Caption Transcript (source_type='caption')
  - Whisper Transcript (source_type='whisper')
  - Merged Transcript (source_type='merged')
  â€» ì´ ì¤‘ í•˜ë‚˜ê°€ is_primary = true
  â†“
[Meeting Agent]
  - MeetingAgent: ìš”ì•½/ì•ˆê±´/ê²°ì •/ì•¡ì…˜/ìº í˜ì¸ ì•„ì´ë””ì–´
  â†“
[Meeting â†’ Brief Agent]
  - Brand Kit + Meeting Summary â†’ Campaign Brief
  â†“
[Frontend]
  - Transcript íƒ­
  - Summary íƒ­
  - Brief íƒ­
```

---

## í•µì‹¬ ì„¤ê³„ ì›ì¹™

### 1. **ì…ë ¥ ë…ë¦½ì„± (Input Agnostic)**

**ì›ì¹™**: ì…ë ¥ ì†ŒìŠ¤(íŒŒì¼/URL/YouTube)ì™€ ê´€ê³„ì—†ì´, ëª¨ë“  ì…ë ¥ì€ **í‘œì¤€í™”ëœ Transcript**ë¡œ ë³€í™˜ë¨

**ì´ì **:
- ìƒˆë¡œìš´ ì…ë ¥ ì†ŒìŠ¤ ì¶”ê°€ ì‹œ Transcript Layerë§Œ ì—°ê²°í•˜ë©´ ë¨
- MeetingAgentëŠ” ì…ë ¥ ì†ŒìŠ¤ë¥¼ ëª°ë¼ë„ ë¨
- ì†ŒìŠ¤ë³„ íŠ¹ìˆ˜ ì²˜ë¦¬ ë¡œì§ì´ ê²©ë¦¬ë¨

### 2. **ë‹¤ì¤‘ Transcript ì§€ì› (Multiple Transcripts)**

**ì›ì¹™**: í•˜ë‚˜ì˜ Meetingì€ **ì—¬ëŸ¬ Transcript**ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒ

**ì´ì **:
- Captionê³¼ Whisperë¥¼ ë‘˜ ë‹¤ ì €ì¥í•˜ì—¬ í’ˆì§ˆ ë¹„êµ ê°€ëŠ¥
- ë‚˜ì¤‘ì— ë” ì¢‹ì€ Transcriptê°€ ìƒì„±ë˜ë©´ primary êµì²´ ê°€ëŠ¥
- ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ í¸ì§‘í•œ Transcriptë„ ì¶”ê°€ ê°€ëŠ¥

### 3. **Primary Transcript Pattern**

**ì›ì¹™**: `is_primary=true`ì¸ Transcriptê°€ **MeetingAgentê°€ ì‚¬ìš©í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸**

**ì´ì **:
- MeetingAgentëŠ” í•­ìƒ "primary transcript"ë§Œ ì¡°íšŒí•˜ë©´ ë¨
- Primaryë¥¼ ë™ì ìœ¼ë¡œ êµì²´í•˜ì—¬ í’ˆì§ˆ ê°œì„  ê°€ëŠ¥
- A/B í…ŒìŠ¤íŠ¸ ë° í’ˆì§ˆ ì‹¤í—˜ ìš©ì´

### 4. **í’ˆì§ˆ ê¸°ë°˜ ì„ íƒ (Quality-Based Selection)**

**ì›ì¹™**: `quality_score`ë¥¼ ìë™ ê³„ì‚°í•˜ì—¬ **ê°€ì¥ ì¢‹ì€ Transcriptë¥¼ primaryë¡œ ì„ íƒ**

**í’ˆì§ˆ ê³„ì‚° ê¸°ì¤€**:
- í…ìŠ¤íŠ¸ ê¸¸ì´ vs ì˜ìƒ ê¸¸ì´ ë¹„ìœ¨
- ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨
- ì–¸ì–´ ê°ì§€ ì¼ì¹˜ë„
- Whisper confidence ì ìˆ˜

---

## Transcript Layer í‘œì¤€í™”

### DB ìŠ¤í‚¤ë§ˆ: `meeting_transcripts`

```sql
CREATE TABLE meeting_transcripts (
    id UUID PRIMARY KEY,
    meeting_id UUID REFERENCES meetings(id) ON DELETE CASCADE,

    -- ì†ŒìŠ¤ ì •ë³´
    source_type VARCHAR NOT NULL,  -- 'caption' | 'whisper' | 'merged'
    provider VARCHAR NOT NULL,      -- 'upload' | 'youtube' | 'zoom' | 'gmeet' | 'teams' | 'manual'

    -- Primary ì§€ì •
    is_primary BOOLEAN NOT NULL DEFAULT FALSE,
    quality_score FLOAT,            -- 0.0 ~ 1.0

    -- íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°
    transcript_text TEXT NOT NULL,
    language VARCHAR(10),
    segments JSONB,                 -- [{start, end, text, speaker}]

    -- ë©”íƒ€ë°ì´í„°
    whisper_metadata JSONB,

    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

CREATE INDEX ix_meeting_transcripts_is_primary
    ON meeting_transcripts (meeting_id, is_primary);
```

### Transcript Source Type

| source_type | ì„¤ëª… | ìƒì„± ë°©ë²• |
|------------|------|----------|
| **caption** | ìë§‰ ê¸°ë°˜ Transcript | YouTube API, Zoom API, VTT íŒŒì¼ íŒŒì‹± |
| **whisper** | Whisper STT ê¸°ë°˜ | faster-whisper ì„œë²„, OpenAI Whisper API |
| **merged** | Caption + Whisper ë³‘í•© | LLM ê¸°ë°˜ ë³‘í•© ë˜ëŠ” Align ì•Œê³ ë¦¬ì¦˜ |

### Transcript Provider

| provider | ì„¤ëª… | source_type ì¡°í•© |
|---------|------|-----------------|
| **upload** | ì§ì ‘ ì—…ë¡œë“œ | whisper (íŒŒì¼ ì—…ë¡œë“œ â†’ STT) |
| **youtube** | YouTube | caption (ìë§‰ ìš°ì„ ), whisper (ìë§‰ ì—†ì„ ë•Œ) |
| **zoom** | Zoom | caption (Zoom ìë§‰), whisper (ë³´ì¡°) |
| **gmeet** | Google Meet | caption (ìë™ ìë§‰), whisper (ë³´ì¡°) |
| **teams** | Microsoft Teams | caption (Teams ìë§‰), whisper (ë³´ì¡°) |
| **manual** | ìˆ˜ë™ ì…ë ¥ | caption (ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥) |

### Primary Transcript ì„ íƒ ë¡œì§

```python
def select_primary_transcript(meeting_id: UUID) -> MeetingTranscript:
    """
    Meetingì˜ ì—¬ëŸ¬ transcript ì¤‘ primaryë¥¼ ì„ íƒ

    ìš°ì„ ìˆœìœ„:
    1. ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•œ primary (is_primary=true)
    2. quality_scoreê°€ ê°€ì¥ ë†’ì€ transcript
    3. source_type ìš°ì„ ìˆœìœ„ (merged > whisper > caption)
    4. ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ transcript
    """
    transcripts = db.query(MeetingTranscript).filter(
        MeetingTranscript.meeting_id == meeting_id
    ).order_by(
        MeetingTranscript.is_primary.desc(),      # ìˆ˜ë™ ì§€ì • ìš°ì„ 
        MeetingTranscript.quality_score.desc(),   # í’ˆì§ˆ ë†’ì€ ê²ƒ ìš°ì„ 
        MeetingTranscript.created_at.desc()       # ìµœì‹  ê²ƒ ìš°ì„ 
    ).all()

    if not transcripts:
        return None

    # ì²« ë²ˆì§¸ê°€ primary
    primary = transcripts[0]

    # primary í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
    for t in transcripts:
        t.is_primary = (t.id == primary.id)

    db.commit()
    return primary
```

---

## Whisper STT ì „ëµ

### ìš´ì˜ ê¸°ì¤€ (3-Tier Strategy)

| ìˆœìœ„ | ë°±ì—”ë“œ | í™˜ê²½ | ì—­í•  |
|-----|-------|------|------|
| **P0** | **faster-whisper** | RTX Desktop GPU | **ë©”ì¸ STT**, ëª¨ë“  íŠ¸ë˜í”½ ì²˜ë¦¬ |
| **P1** | **whisper.cpp** | Mac mini CPU (ì„ íƒ) | Desktop ì¥ì•  ì‹œ ë°±ì—… |
| **P2** | **OpenAI Whisper** | Cloud API | ìµœí›„ fallback + PoC/í…ŒìŠ¤íŠ¸ |

### Whisper ëª¨ë“œë³„ ë™ì‘

#### 1. `hybrid_cost` (ê¸°ë³¸ê°’) - ë¹„ìš© ì ˆê° ìš°ì„ 

```python
# .env
WHISPER_MODE=hybrid_cost
```

**ë™ì‘ ë¡œì§**:
```
1. íšŒì˜ ê¸¸ì´ ê³„ì‚° (ffprobe)

2. IF duration <= WHISPER_OPENAI_MAX_MINUTES (ê¸°ë³¸ 20ë¶„):
   - OpenAI Whisper ì‹œë„ (ì§§ì€ ë¯¸íŒ…ì€ ë¹ ë¥´ê³  ì €ë ´)
   - ì‹¤íŒ¨ â†’ faster-whisper fallback

3. ELSE (ê¸´ ë¯¸íŒ…):
   - faster-whisper ìš°ì„  (GPUë¡œ ë¹„ìš© ì ˆê°)
   - ì‹¤íŒ¨ â†’ OpenAI Whisper fallback
```

**ì ìš© ì¼€ì´ìŠ¤**: ì¼ë°˜ íšŒì˜, ì¼ì¼ ìŠ¤íƒ ë“œì—…, ì§§ì€ ë¯¸íŒ…

#### 2. `hybrid_quality` - í’ˆì§ˆ ìš°ì„ 

```python
# .env
WHISPER_MODE=hybrid_quality
```

**ë™ì‘ ë¡œì§**:
```
1. ê¸¸ì´ ìƒê´€ì—†ì´ faster-whisper(large-v3) ìš°ì„ 
2. ì‹¤íŒ¨ â†’ OpenAI Whisper fallback
```

**ì ìš© ì¼€ì´ìŠ¤**: í´ë¼ì´ì–¸íŠ¸ ë¯¸íŒ…, ì„¸ë¯¸ë‚˜, ì¤‘ìš” íšŒì˜

#### 3. `local` - ë¡œì»¬ ì „ìš©

```python
# .env
WHISPER_MODE=local
```

**ë™ì‘ ë¡œì§**:
```
1. faster-whisper ìš°ì„ 
2. ì‹¤íŒ¨ â†’ whisper.cpp fallback
3. ëª¨ë‘ ì‹¤íŒ¨ â†’ ì—ëŸ¬ (OpenAI ì‚¬ìš© ì•ˆ í•¨)
```

**ì ìš© ì¼€ì´ìŠ¤**: ì˜¤í”„ë¼ì¸ í™˜ê²½, ë³´ì•ˆ ìš”êµ¬ì‚¬í•­

#### 4. `openai` - OpenAI ì „ìš©

```python
# .env
WHISPER_MODE=openai
```

**ë™ì‘ ë¡œì§**:
```
1. OpenAI Whisperë§Œ ì‚¬ìš©
2. ì‹¤íŒ¨ â†’ ì—ëŸ¬
```

**ì ìš© ì¼€ì´ìŠ¤**: ì´ˆê¸° PoC, í…ŒìŠ¤íŠ¸ í™˜ê²½

### í™˜ê²½ë³„ ì„¤ì •

#### RTX Desktop (faster-whisper ì„œë²„)

```yaml
# docker-compose.yml
version: "3.8"
services:
  faster-whisper:
    image: faster-whisper-server:latest
    ports:
      - "9000:9000"
    environment:
      - WHISPER_MODEL=large-v3
      - WHISPER_DEVICE=cuda
      - WHISPER_COMPUTE_TYPE=float16
    volumes:
      - D:/models/whisper:/models
    restart: unless-stopped
```

**Endpoint**: `http://100.123.51.6:9000/transcribe`

**API ìŠ¤í™**:
```http
POST /transcribe
Content-Type: multipart/form-data

file: <audio_file>
language: ko (optional)
model: large-v3 (optional)

Response:
{
  "text": "ì „ì²´ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸...",
  "segments": [
    {"start": 0.0, "end": 5.2, "text": "ì•ˆë…•í•˜ì„¸ìš”..."}
  ],
  "language": "ko",
  "duration": 120.5
}
```

#### Mac mini Backend (.env)

```bash
# Whisper ì „ëµ
WHISPER_MODE=hybrid_cost

# faster-whisper ì„œë²„ (RTX Desktop Tailscale IP)
WHISPER_LOCAL_BACKEND=faster_whisper
WHISPER_FAST_ENDPOINT=http://100.123.51.6:9000/transcribe

# whisper.cpp (ì„ íƒ, Mac mini ë¡œì»¬)
WHISPER_CPP_ENDPOINT=http://127.0.0.1:8765/transcribe

# OpenAI (fallback)
WHISPER_OPENAI_MODEL=whisper-1
WHISPER_OPENAI_MAX_MINUTES=20  # 20ë¶„ ì´í•˜ë§Œ OpenAI ì‚¬ìš© í—ˆìš©

# ëª¨ë¸ í”„ë¡œí•„
WHISPER_PROFILE_FAST=small
WHISPER_PROFILE_BALANCED=medium
WHISPER_PROFILE_ACCURATE=large-v3

WHISPER_TIMEOUT_SECONDS=600
WHISPER_MAX_RETRIES=2
```

---

## ì…ë ¥ ì†ŒìŠ¤ë³„ í”Œë¡œìš°

### 1. íŒŒì¼ ì—…ë¡œë“œ (Upload)

```
[ì‚¬ìš©ì] íŒŒì¼ ì—…ë¡œë“œ (mp4/mp3/...)
   â†“
[Backend] Meeting ìƒì„± + MinIO presigned URL ë°˜í™˜
   â†“
[ì‚¬ìš©ì] presigned URLë¡œ íŒŒì¼ ì—…ë¡œë“œ
   â†“
[Background Job] Whisper STT ì‹¤í–‰
   1) MinIOì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
   2) TranscriberService.transcribe()
      - hybrid_cost ëª¨ë“œ ì ìš©
      - faster-whisper ìš°ì„  â†’ OpenAI fallback
   3) meeting_transcripts ì €ì¥
      - source_type='whisper'
      - provider='upload'
      - is_primary=true
      - quality_score ìë™ ê³„ì‚°
   â†“
[MeetingAgent] primary transcriptë¡œ ìš”ì•½ ìƒì„±
```

### 2. YouTube URL

```
[ì‚¬ìš©ì] YouTube URL ì…ë ¥
   â†“
[Backend] Meeting ìƒì„±
   â†“
[Background Job] YouTube ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
   1) ë©”íƒ€ë°ì´í„° ì¡°íšŒ (ì œëª©, ê¸¸ì´ ë“±)

   2) ìë§‰ ì‹œë„ (Caption Fetcher)
      - YouTube APIë¡œ ìë§‰ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
      - ì„ í˜¸ ì–¸ì–´ (ko â†’ en â†’ auto) ìˆœìœ¼ë¡œ ì„ íƒ
      - ìë§‰ ìˆìœ¼ë©´:
        * transcript_text + segments ì¶”ì¶œ
        * meeting_transcripts ì €ì¥
          - source_type='caption'
          - provider='youtube'
          - quality_score ê³„ì‚°
        * í’ˆì§ˆ ì¢‹ìœ¼ë©´ is_primary=true

   3) Whisper STT (ì„ íƒì , ì˜µì…˜ì— ë”°ë¼)
      - also_run_whisper=trueì¼ ë•Œ:
        * ffmpegë¡œ audio ì¶”ì¶œ
        * TranscriberService.transcribe()
        * meeting_transcripts ì €ì¥
          - source_type='whisper'
          - provider='youtube'
          - quality_score ê³„ì‚°
        * captionë³´ë‹¤ í’ˆì§ˆ ì¢‹ìœ¼ë©´ primary êµì²´

   4) Primary ì„ íƒ
      - select_primary_transcript(meeting_id)
      - caption vs whisper ì¤‘ quality_score ë†’ì€ ê²ƒ ì„ íƒ
   â†“
[MeetingAgent] primary transcriptë¡œ ìš”ì•½ ìƒì„±
```

### 3. ê¸°íƒ€ URL

```
[ì‚¬ìš©ì] ë™ì˜ìƒ/ì˜¤ë””ì˜¤ URL ì…ë ¥
   â†“
[Backend] Meeting ìƒì„±
   â†“
[Background Job] URL ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
   1) yt-dlpë¡œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ

   2) ìë§‰ ì‹œë„
      - yt-dlpë¡œ ìë§‰ ë‹¤ìš´ë¡œë“œ ì‹œë„
      - VTT/SRT íŒŒì¼ íŒŒì‹±
      - ìˆìœ¼ë©´ caption transcript ì €ì¥

   3) Audio ë‹¤ìš´ë¡œë“œ + Whisper STT
      - yt-dlpë¡œ audio ì¶”ì¶œ
      - TranscriberService.transcribe()
      - whisper transcript ì €ì¥

   4) Primary ì„ íƒ
   â†“
[MeetingAgent] primary transcriptë¡œ ìš”ì•½ ìƒì„±
```

---

## í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ

### Caption vs Whisper í’ˆì§ˆ ë¹„êµ

#### í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (`quality_score`)

```python
def calculate_quality_score(
    transcript: MeetingTranscript,
    meeting_duration: float
) -> float:
    """
    Transcript í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
    """
    score = 0.0

    # 1. ê¸¸ì´ ë¹„ìœ¨ (0 ~ 0.3)
    #    - ì˜ìƒ ê¸¸ì´ ëŒ€ë¹„ transcript ê¸¸ì´ê°€ ì ì ˆí•œì§€
    #    - ê¸°ì¤€: 1ë¶„ë‹¹ 150~200 ê¸€ì (í•œê¸€ ê¸°ì¤€)
    expected_length = meeting_duration * 60 * 175  # 175ì/ë¶„
    actual_length = len(transcript.transcript_text)
    length_ratio = min(actual_length / expected_length, 1.0)
    score += length_ratio * 0.3

    # 2. ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ (0 ~ 0.2)
    #    - ë„ˆë¬´ ë§ì€ ê³µë°±ì´ë‚˜ ì¡ìŒ ë¬¸ìëŠ” í’ˆì§ˆ ì €í•˜
    text = transcript.transcript_text
    clean_ratio = len(text.strip()) / max(len(text), 1)
    special_char_ratio = len([c for c in text if not c.isalnum() and not c.isspace()]) / max(len(text), 1)
    score += (clean_ratio * 0.1) + ((1 - special_char_ratio) * 0.1)

    # 3. ì–¸ì–´ ì¼ì¹˜ë„ (0 ~ 0.2)
    #    - ê°ì§€ëœ ì–¸ì–´ê°€ ì˜ˆìƒ ì–¸ì–´ì™€ ì¼ì¹˜í•˜ëŠ”ì§€
    if transcript.language:
        # í•œê¸€ ë¹„ìœ¨ ê³„ì‚° (í•œêµ­ì–´ íšŒì˜ì¸ ê²½ìš°)
        korean_chars = len([c for c in text if 'ê°€' <= c <= 'í£'])
        korean_ratio = korean_chars / max(len(text), 1)
        score += min(korean_ratio, 0.2)

    # 4. Segments í’ˆì§ˆ (0 ~ 0.3)
    #    - íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—°ì†ì ì´ê³  ëˆ„ë½ì´ ì—†ëŠ”ì§€
    if transcript.segments:
        segments = transcript.segments
        # ì‹œê°„ ì»¤ë²„ë¦¬ì§€ (ì˜ìƒ ì „ì²´ë¥¼ ì»¤ë²„í•˜ëŠ”ì§€)
        last_segment_time = segments[-1].get('end', 0) if segments else 0
        coverage_ratio = min(last_segment_time / meeting_duration, 1.0)
        score += coverage_ratio * 0.3

    return min(score, 1.0)
```

#### Caption vs Whisper ì„ íƒ ë¡œì§

```python
async def process_youtube_url(
    meeting_id: UUID,
    youtube_url: str,
    options: Dict[str, Any]
) -> MeetingTranscript:
    """
    YouTube URL ì²˜ë¦¬ â†’ primary transcript ì„ íƒ
    """
    meeting = get_meeting(meeting_id)

    # 1. Caption ì‹œë„
    caption_transcript = None
    try:
        caption_data = await fetch_youtube_caption(youtube_url)
        if caption_data:
            caption_transcript = MeetingTranscript(
                meeting_id=meeting_id,
                source_type=TranscriptSourceType.CAPTION,
                provider=TranscriptProvider.YOUTUBE,
                transcript_text=caption_data['text'],
                segments=caption_data['segments'],
                language=caption_data['language'],
                quality_score=calculate_quality_score(caption_data, meeting.duration)
            )
            db.add(caption_transcript)
            db.commit()
    except Exception as e:
        logger.warning(f"Caption fetch failed: {e}")

    # 2. Whisper STT (ì˜µì…˜ ë˜ëŠ” caption ì‹¤íŒ¨ ì‹œ)
    whisper_transcript = None
    should_run_whisper = (
        options.get('also_run_whisper', False) or  # ëª…ì‹œì  ì˜µì…˜
        caption_transcript is None or               # Caption ì—†ìŒ
        caption_transcript.quality_score < 0.5      # Caption í’ˆì§ˆ ë‚®ìŒ
    )

    if should_run_whisper:
        try:
            audio_path = await download_youtube_audio(youtube_url)
            whisper_data = await transcriber.transcribe_async(audio_path)

            whisper_transcript = MeetingTranscript(
                meeting_id=meeting_id,
                source_type=TranscriptSourceType.WHISPER,
                provider=TranscriptProvider.YOUTUBE,
                transcript_text=whisper_data['transcript_text'],
                segments=whisper_data['segments'],
                language=whisper_data['language'],
                whisper_metadata=whisper_data['whisper_metadata'],
                quality_score=calculate_quality_score(whisper_data, meeting.duration)
            )
            db.add(whisper_transcript)
            db.commit()
        except Exception as e:
            logger.error(f"Whisper STT failed: {e}")

    # 3. Primary ì„ íƒ
    return select_primary_transcript(meeting_id)
```

### Merged Transcript (ê³ ê¸‰ ì „ëµ)

Captionê³¼ Whisperë¥¼ LLMìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ transcript ìƒì„±:

```python
async def create_merged_transcript(
    meeting_id: UUID,
    caption_transcript: MeetingTranscript,
    whisper_transcript: MeetingTranscript
) -> MeetingTranscript:
    """
    Caption + Whisperë¥¼ LLMìœ¼ë¡œ ë³‘í•©
    """
    # LLMìœ¼ë¡œ ë‘ transcriptë¥¼ í†µí•©
    merge_request = AgentRequest(
        task="merge_transcripts",
        payload={
            "caption_text": caption_transcript.transcript_text,
            "whisper_text": whisper_transcript.transcript_text,
            "caption_segments": caption_transcript.segments,
            "whisper_segments": whisper_transcript.segments,
            "_instructions": (
                "ë‘ ê°œì˜ transcriptë¥¼ ë¹„êµí•˜ì—¬ ê°€ì¥ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ "
                "ìµœì¢… transcriptë¥¼ ìƒì„±í•˜ì„¸ìš”. "
                "Captionì€ êµ¬ì¡°ê°€ ì¢‹ì§€ë§Œ ëˆ„ë½ì´ ìˆì„ ìˆ˜ ìˆê³ , "
                "WhisperëŠ” ì™„ì „í•˜ì§€ë§Œ í‘œí˜„ì´ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        }
    )

    agent = get_meeting_ai_agent()
    response = await agent.execute(merge_request)

    merged_data = response.outputs[0].value

    # Merged transcript ì €ì¥
    merged_transcript = MeetingTranscript(
        meeting_id=meeting_id,
        source_type=TranscriptSourceType.MERGED,
        provider=caption_transcript.provider,
        transcript_text=merged_data['text'],
        segments=merged_data['segments'],
        language=caption_transcript.language,
        quality_score=1.0,  # MergedëŠ” ìµœê³  í’ˆì§ˆë¡œ ê°„ì£¼
        is_primary=True     # ë°”ë¡œ primaryë¡œ ì§€ì •
    )

    # ê¸°ì¡´ transcriptë“¤ì˜ primary í”Œë˜ê·¸ í•´ì œ
    caption_transcript.is_primary = False
    whisper_transcript.is_primary = False

    db.add(merged_transcript)
    db.commit()

    return merged_transcript
```

---

## API êµ¬ì¡°

### Meeting Import API

```http
POST /api/v1/meetings/import-from-url
Content-Type: application/json

{
  "url": "https://www.youtube.com/watch?v=xxxx",
  "source_type": "youtube",
  "title": "íšŒì˜ ì œëª© (optional)",
  "brand_id": "uuid (optional)",
  "project_id": "uuid (optional)",
  "options": {
    "use_caption_first": true,
    "also_run_whisper": true,
    "whisper_mode": "hybrid_quality",
    "preferred_language": "ko"
  }
}

Response:
{
  "meeting_id": "uuid",
  "status": "processing",
  "estimated_time_seconds": 120
}
```

### Transcript ì¡°íšŒ API

```http
GET /api/v1/meetings/{meeting_id}/transcripts

Response:
{
  "transcripts": [
    {
      "id": "uuid",
      "source_type": "caption",
      "provider": "youtube",
      "is_primary": false,
      "quality_score": 0.7,
      "language": "ko",
      "created_at": "2025-11-24T10:00:00Z"
    },
    {
      "id": "uuid",
      "source_type": "whisper",
      "provider": "youtube",
      "is_primary": true,
      "quality_score": 0.85,
      "language": "ko",
      "created_at": "2025-11-24T10:05:00Z"
    }
  ],
  "primary_transcript_id": "uuid"
}
```

### Primary Transcript ë³€ê²½ API

```http
PATCH /api/v1/meetings/{meeting_id}/transcripts/{transcript_id}/set-primary

Response:
{
  "message": "Primary transcript updated",
  "transcript_id": "uuid",
  "meeting_id": "uuid"
}
```

---

## ìš´ì˜ ê°€ì´ë“œ

### ìš°ì„ ìˆœìœ„ë³„ êµ¬í˜„ ë¡œë“œë§µ

#### âœ… Phase 1: ê¸°ë³¸ êµ¬ì¡° (ì™„ë£Œ)
- [x] DB Schema (meetings, meeting_transcripts)
- [x] Alembic Migration
- [x] OpenAI Whisper í†µí•©
- [x] MeetingAgent (meeting_summary task)
- [x] API Endpoints

#### ğŸ”„ Phase 2: Transcript Layer í‘œì¤€í™” (ì§„í–‰ ì¤‘)
- [x] source_type, provider, is_primary ì¶”ê°€
- [x] quality_score ê³„ì‚° ë¡œì§
- [ ] select_primary_transcript() êµ¬í˜„
- [ ] Transcript ê´€ë¦¬ API

#### â³ Phase 3: Whisper ë“€ì–¼ ëª¨ë“œ
- [ ] faster-whisper ì„œë²„ ì„¤ì • (RTX Desktop)
- [ ] TranscriberService í™•ì¥ (hybrid_cost, hybrid_quality)
- [ ] whisper.cpp ë°±ì—… (optional)

#### â³ Phase 4: YouTube Caption
- [ ] YouTube Caption Fetcher
- [ ] Caption vs Whisper í’ˆì§ˆ ë¹„êµ
- [ ] also_run_whisper ì˜µì…˜

#### â³ Phase 5: í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ
- [ ] Merged Transcript ìƒì„± (LLM ê¸°ë°˜)
- [ ] A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

### ëª¨ë‹ˆí„°ë§ ì§€í‘œ

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ |
|-----|------|------|
| **Transcript ìƒì„± ì„±ê³µë¥ ** | ì „ì²´ ìš”ì²­ ëŒ€ë¹„ ì„±ê³µ ë¹„ìœ¨ | â‰¥ 95% |
| **Primary Transcript í’ˆì§ˆ** | primary transcriptì˜ í‰ê·  quality_score | â‰¥ 0.75 |
| **Whisper ì‘ë‹µ ì‹œê°„** | faster-whisper ì„œë²„ í‰ê·  ì‘ë‹µ ì‹œê°„ | â‰¤ 60ì´ˆ (10ë¶„ íšŒì˜ ê¸°ì¤€) |
| **Caption í™œìš©ë¥ ** | YouTube ì…ë ¥ ì¤‘ caption ì‚¬ìš© ë¹„ìœ¨ | â‰¥ 60% |
| **Fallback ë°œìƒë¥ ** | OpenAI Whisper fallback ë¹„ìœ¨ | â‰¤ 10% |

---

## ë¶€ë¡

### A. Whisper ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | ë©”ëª¨ë¦¬ (GPU) | ì†ë„ (RTX 3090 ê¸°ì¤€) | ì •í™•ë„ |
|-----|---------|------------|-------------------|--------|
| **tiny** | 39M | ~1GB | 10x ì‹¤ì‹œê°„ | â˜…â˜…â˜†â˜†â˜† |
| **small** | 244M | ~2GB | 5x ì‹¤ì‹œê°„ | â˜…â˜…â˜…â˜†â˜† |
| **medium** | 769M | ~5GB | 2x ì‹¤ì‹œê°„ | â˜…â˜…â˜…â˜…â˜† |
| **large-v3** | 1550M | ~10GB | 1x ì‹¤ì‹œê°„ | â˜…â˜…â˜…â˜…â˜… |

**ì¶”ì²œ**:
- **ê¸°ë³¸ê°’**: medium (ì†ë„+í’ˆì§ˆ ê· í˜•)
- **ì¤‘ìš” íšŒì˜**: large-v3 (ìµœê³  í’ˆì§ˆ)
- **ë¹ ë¥¸ ì²˜ë¦¬**: small (ìŠ¤íƒ ë“œì—…, ì§§ì€ ë¯¸íŒ…)

### B. í™˜ê²½ë³„ ê¶Œì¥ ì„¤ì •

#### ê°œë°œ í™˜ê²½ (ë…¸íŠ¸ë¶)
```bash
WHISPER_MODE=openai
WHISPER_OPENAI_MODEL=whisper-1
```

#### ìŠ¤í…Œì´ì§• í™˜ê²½ (Mac mini + RTX Desktop)
```bash
WHISPER_MODE=hybrid_cost
WHISPER_LOCAL_BACKEND=faster_whisper
WHISPER_FAST_ENDPOINT=http://100.123.51.6:9000/transcribe
WHISPER_OPENAI_MAX_MINUTES=20
```

#### í”„ë¡œë•ì…˜ í™˜ê²½
```bash
WHISPER_MODE=hybrid_cost
WHISPER_LOCAL_BACKEND=faster_whisper
WHISPER_FAST_ENDPOINT=http://100.123.51.6:9000/transcribe
WHISPER_CPP_ENDPOINT=http://127.0.0.1:8765/transcribe  # ë°±ì—…
WHISPER_OPENAI_MAX_MINUTES=15  # ë” ì—„ê²©í•˜ê²Œ
WHISPER_MAX_RETRIES=3
```

---

## ë¬¸ì˜ ë° ê¸°ì—¬

- **ë¬¸ì„œ ê´€ë¦¬**: BíŒ€ (Backend)
- **ì—…ë°ì´íŠ¸ ì´ë ¥**: `git log docs/MEETING_AI_ARCHITECTURE.md`
- **ì´ìŠˆ ì œë³´**: GitHub Issues
