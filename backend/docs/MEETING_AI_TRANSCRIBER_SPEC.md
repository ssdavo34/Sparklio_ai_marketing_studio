# Meeting AI Transcriber & Whisper Hybrid Spec

**ì‘ì„±ì¼**: 2025-11-24
**ë²„ì „**: v2.0 (í†µí•© ë²„ì „)
**ëŒ€ìƒ íŒ€**: AíŒ€(QA), BíŒ€(Backend), CíŒ€(Frontend)

---

## ğŸ“‹ ëª©ì°¨

1. [ëª©í‘œ & ìŠ¤ì½”í”„](#1-ëª©í‘œ--ìŠ¤ì½”í”„)
2. [ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”](#2-ì „ì²´-ì•„í‚¤í…ì²˜-ê°œìš”)
3. [í™˜ê²½ ë³€ìˆ˜ & ëª¨ë“œ ì •ì˜](#3-í™˜ê²½-ë³€ìˆ˜--ëª¨ë“œ-ì •ì˜)
4. [DB ìŠ¤í‚¤ë§ˆ](#4-db-ìŠ¤í‚¤ë§ˆ)
5. [TranscriberService ì„¤ê³„](#5-transcriberservice-ì„¤ê³„)
6. [API ìŠ¤í™](#6-api-ìŠ¤í™)
7. [RTX Desktop faster-whisper ì„œë²„ ìŠ¤í™](#7-rtx-desktop-faster-whisper-ì„œë²„-ìŠ¤í™)
8. [QA í…ŒìŠ¤íŠ¸ í”Œëœ](#8-qa-í…ŒìŠ¤íŠ¸-í”Œëœ)
9. [í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ê°€ì´ë“œ](#9-í”„ë¡ íŠ¸ì—”ë“œ-ì—°ë™-ê°€ì´ë“œ)
10. [íŒ€ë³„ ì—­í•  ë° ì²´í¬ë¦¬ìŠ¤íŠ¸](#10-íŒ€ë³„-ì—­í• -ë°-ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## 1. ëª©í‘œ & ìŠ¤ì½”í”„

### 1.1 ëª©í‘œ

Meeting AIì—ì„œ ì‚¬ìš©í•˜ëŠ” **ìŒì„± â†’ í…ìŠ¤íŠ¸(STT) ì¸í”„ë¼ë¥¼ í‘œì¤€í™”**í•˜ê³ , ë‹¤ì–‘í•œ ì†ŒìŠ¤ë¥¼ **í•˜ë‚˜ì˜ í†µì¼ëœ Transcript Layer**ë¡œ ë§Œë“œëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.

**ì…ë ¥**:
- íšŒì˜ ë…¹ìŒ íŒŒì¼ (mp3, wav, m4a, mp4â€¦)
- YouTube/URL ë“±ì—ì„œ ê°€ì ¸ì˜¨ ì˜¤ë””ì˜¤
- ì¶”í›„ Zoom/Google Meet/Teams APIë¡œ ê°€ì ¸ì˜¨ íšŒì˜

**ì²˜ë¦¬**:
- ê¸°ë³¸ STT ì—”ì§„: **RTX Desktopì˜ faster-whisper(GPU)**
- **whisper.cpp(Mac mini)** & **OpenAI Whisper**ëŠ” ë°±ì—…/ë³´ì¡° ì—­í• 
- íšŒì˜ ê¸¸ì´Â·ì¤‘ìš”ë„Â·ë¹„ìš©ì„ ê³ ë ¤í•œ **í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ** ì ìš©

**ì¶œë ¥**:
- DB `meeting_transcripts`ì— í†µì¼ëœ ìŠ¤í‚¤ë§ˆë¡œ ì €ì¥
- MeetingAgent / Meetingâ†’Brief AgentëŠ” ì´ ë ˆì´ì–´ë§Œ ë°”ë¼ë³´ê³  ë™ì‘

### 1.2 í•µì‹¬ ì„¤ê³„ ì›ì¹™

1. **ì…ë ¥ ë…ë¦½ì„±**: ì…ë ¥ ì†ŒìŠ¤(íŒŒì¼/URL/YouTube)ì™€ ê´€ê³„ì—†ì´, ëª¨ë“  ì…ë ¥ì€ í‘œì¤€í™”ëœ Transcriptë¡œ ë³€í™˜
2. **ë‹¤ì¤‘ Transcript ì§€ì›**: í•˜ë‚˜ì˜ Meetingì€ ì—¬ëŸ¬ Transcriptë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒ (caption, whisper, merged ë“±)
3. **Primary Transcript Pattern**: `is_primary=true`ì¸ Transcriptê°€ MeetingAgentê°€ ì‚¬ìš©í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
4. **ì¶”ì ì„±**: `backend`, `model`, `latency_ms` ë“±ìœ¼ë¡œ ì–´ë–¤ ì—”ì§„ì´ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ ì¶”ì  ê°€ëŠ¥

---

## 2. ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”

### 2.1 High-Level Flow

```
[ì‚¬ìš©ì ë¸Œë¼ìš°ì € - CíŒ€]
  â””â”€ íšŒì˜ ìƒì„± / íŒŒì¼ ì—…ë¡œë“œ / URL ë“±ë¡
        â†“
[Backend - BíŒ€]
  â””â”€ Meeting ë ˆì½”ë“œ + Audio Source ì €ì¥ (DB/MinIO)
        â†“
[TranscriberService - BíŒ€]
  â””â”€ duration ê³„ì‚° (ffprobe)
  â””â”€ WHISPER_MODE / ê¸¸ì´ / ì¤‘ìš”ë„ì— ë”°ë¼ ì—”ì§„ ì„ íƒ
       - ìš°ì„ : RTX Desktop faster-whisper HTTP ì„œë²„
       - ì‹¤íŒ¨ or ì •ì±…ì— ë”°ë¼ OpenAI / whisper.cpp ë°±ì—…
        â†“
[meeting_transcripts í…Œì´ë¸” - BíŒ€]
  â””â”€ transcript row ìƒì„± (source_type=whisper, backend=faster_whisper ë“±)
  â””â”€ is_primary = true ì§€ì •
        â†“
[MeetingAgent - BíŒ€]
  â””â”€ primary transcript ê¸°ë°˜ìœ¼ë¡œ summary / decisions / actions ìƒì„±
        â†“
[Meetingâ†’Brief Agent - BíŒ€]
  â””â”€ meeting_summary + Brand Kit â†’ Campaign Brief ìƒì„±
        â†“
[í”„ë¡ íŠ¸ UI - CíŒ€]
  â””â”€ Transcript / Summary / Brief íƒ­ì— ê²°ê³¼ í‘œì‹œ
```

### 2.2 Whisper ì „ëµ ìš”ì•½ (3-Tier Strategy)

| ìˆœìœ„ | ë°±ì—”ë“œ | í™˜ê²½ | ì—­í•  |
|-----|-------|------|------|
| **P0** | **faster-whisper** | RTX Desktop GPU | **ë©”ì¸ STT**, ëª¨ë“  íŠ¸ë˜í”½ ì²˜ë¦¬ |
| **P1** | **whisper.cpp** | Mac mini CPU (ì„ íƒ) | Desktop ì¥ì•  ì‹œ ë°±ì—… |
| **P2** | **OpenAI Whisper** | Cloud API | ìµœí›„ fallback + PoC/í…ŒìŠ¤íŠ¸ |

---

## 3. í™˜ê²½ ë³€ìˆ˜ & ëª¨ë“œ ì •ì˜

### 3.1 .env ì„¤ì • (BíŒ€ ê¸°ì¤€)

```bash
# Whisper ì „ëµ ëª¨ë“œ
WHISPER_MODE=hybrid_cost             # openai | local | hybrid_cost | hybrid_quality

# ë¡œì»¬ ë°±ì—”ë“œ ê¸°ë³¸ê°’: RTX Desktop faster-whisper
WHISPER_LOCAL_BACKEND=faster_whisper # whisper_cpp | faster_whisper | none

# RTX Desktop faster-whisper ì„œë²„
WHISPER_FAST_ENDPOINT=http://100.123.51.6:9000/transcribe

# (ì˜µì…˜) Mac mini whisper.cpp ì„œë²„
WHISPER_CPP_ENDPOINT=http://127.0.0.1:8765/transcribe

# OpenAI Whisper
WHISPER_OPENAI_MODEL=whisper-1
WHISPER_OPENAI_MAX_MINUTES=20   # ì´ ì´í•˜ì˜ ì§§ì€ íšŒì˜ì—ì„œë§Œ OpenAI ì‚¬ìš©

# ê¸¸ì´ë³„ ëª¨ë¸ í”„ë¡œí•„ (ë¡œì»¬ ì—”ì§„ ë‚´ë¶€ì—ì„œ ì‚¬ìš©)
WHISPER_PROFILE_FAST=small          # â‰¤15ë¶„
WHISPER_PROFILE_BALANCED=medium     # 15~60ë¶„
WHISPER_PROFILE_ACCURATE=large-v3   # â‰¥60ë¶„

WHISPER_TIMEOUT_SECONDS=600         # 10ë¶„
WHISPER_MAX_RETRIES=2
```

### 3.2 ëª¨ë“œë³„ ë™ì‘ (AíŒ€ QA ê²€ì¦ ëŒ€ìƒ)

#### Mode 1: `openai` - OpenAI ì „ìš©

```
ëª¨ë“  íšŒì˜ â†’ OpenAI Whisper ì‚¬ìš©
ì‹¤íŒ¨ â†’ ì—ëŸ¬
```

**ì ìš© ì¼€ì´ìŠ¤**: ì´ˆê¸° PoC, í…ŒìŠ¤íŠ¸ í™˜ê²½

#### Mode 2: `local` - ë¡œì»¬ ì „ìš©

```
ëª¨ë“  íšŒì˜ â†’ ë¡œì»¬(ê¸°ë³¸: faster-whisper) ì‚¬ìš©
ì‹¤íŒ¨ â†’ (ì˜µì…˜) OpenAI fallback ë˜ëŠ” ì—ëŸ¬
```

**ì ìš© ì¼€ì´ìŠ¤**: ì˜¤í”„ë¼ì¸ í™˜ê²½, ë³´ì•ˆ ìš”êµ¬ì‚¬í•­

#### Mode 3: `hybrid_cost` (ê¸°ë³¸ê°’, ê¶Œì¥) - ë¹„ìš© ì ˆê° ìš°ì„ 

```
1. duration ê³„ì‚° (ffprobe)

2. IF duration <= WHISPER_OPENAI_MAX_MINUTES (ê¸°ë³¸ 20ë¶„):
   - ì§§ì€ íšŒì˜ â†’ OpenAIë¡œ ë¹ ë¥¸ ì²˜ë¦¬ ì‹œë„
   - ì‹¤íŒ¨ ì‹œ â†’ faster-whisper fallback

3. ELSE (ê¸´ íšŒì˜):
   - faster-whisper ìš°ì„  (GPUë¡œ ë¹„ìš© ì ˆê°)
   - ì‹¤íŒ¨ ì‹œ â†’ OpenAI fallback
```

**ì ìš© ì¼€ì´ìŠ¤**: ì¼ë°˜ íšŒì˜, ì¼ì¼ ìŠ¤íƒ ë“œì—…, ì§§ì€ ë¯¸íŒ…

#### Mode 4: `hybrid_quality` - í’ˆì§ˆ ìš°ì„ 

```
1. ê¸¸ì´ ìƒê´€ì—†ì´ faster-whisper(large-v3) ìš°ì„ 
2. ì‹¤íŒ¨ â†’ OpenAI Whisper fallback
```

**ì ìš© ì¼€ì´ìŠ¤**: í´ë¼ì´ì–¸íŠ¸ ë¯¸íŒ…, ì„¸ë¯¸ë‚˜, ì¤‘ìš” íšŒì˜

---

## 4. DB ìŠ¤í‚¤ë§ˆ

### 4.1 ê°œë…

í•œ íšŒì˜ì— ëŒ€í•´ **ì—¬ëŸ¬ Transcript ë²„ì „ ì¡´ì¬ ê°€ëŠ¥**:
- **caption**: YouTube/Zoom ë“± í”Œë«í¼ ìë§‰
- **whisper**: STT ì—”ì§„ ì¶œë ¥ (faster-whisper, whisper.cpp, OpenAI)
- **merged**: caption + whisper í†µí•©ë³¸ (ì˜µì…˜)
- **manual**: ì‚¬ëŒì´ ìˆ˜ì •í•œ ìµœì¢…ë³¸

í•­ìƒ `is_primary = true`ì¸ 1ê±´ì´ MeetingAIì˜ ê¸°ì¤€ transcript

### 4.2 PostgreSQL Schema

```sql
-- Enum Types
CREATE TYPE transcript_source_type AS ENUM (
  'caption',
  'whisper',
  'merged',
  'manual'
);

CREATE TYPE transcript_provider AS ENUM (
  'upload',
  'youtube',
  'zoom',
  'gmeet',
  'teams',
  'manual'
);

CREATE TYPE transcript_backend AS ENUM (
  'openai',
  'whisper_cpp',
  'faster_whisper',
  'manual',
  'unknown'
);

-- Table
CREATE TABLE meeting_transcripts (
  id               UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  meeting_id       UUID NOT NULL REFERENCES meetings (id) ON DELETE CASCADE,

  -- ì†ŒìŠ¤ ì •ë³´
  source_type      transcript_source_type NOT NULL,  -- caption | whisper | merged | manual
  provider         transcript_provider NOT NULL,     -- upload | youtube | zoom | gmeet | teams | manual
  backend          transcript_backend NOT NULL,      -- openai | whisper_cpp | faster_whisper | manual | unknown
  model            VARCHAR(100),                      -- whisper-1, large-v3, medium ë“±

  -- Primary ì§€ì •
  is_primary       BOOLEAN NOT NULL DEFAULT FALSE,

  -- í’ˆì§ˆ ë° ë©”íŠ¸ë¦­
  quality_score    FLOAT,                             -- 0.0 ~ 1.0 (ìë™ ê³„ì‚°)
  confidence       FLOAT,                             -- 0.0 ~ 1.0 (Whisper confidence)
  latency_ms       INTEGER,                           -- STT ì²˜ë¦¬ ì‹œê°„ (ms)

  -- íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë°ì´í„°
  language         VARCHAR(10),                       -- ko, en ë“±
  transcript_text  TEXT NOT NULL,
  segments         JSONB,                             -- [{"start": 0.0, "end": 3.2, "text": "..."}]

  -- ë©”íƒ€ë°ì´í„°
  whisper_metadata JSONB,

  created_at       TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at       TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Indexes
CREATE INDEX idx_meeting_transcripts_meeting_id
  ON meeting_transcripts (meeting_id);

CREATE INDEX idx_meeting_transcripts_primary
  ON meeting_transcripts (meeting_id, is_primary);
```

### 4.3 ì»¬ëŸ¼ ì„¤ëª… (A/B/CíŒ€ ê³µí†µ ì´í•´ìš©)

| í•„ë“œ | íƒ€ì… | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|------|
| **meeting_id** | UUID | ì–´ë–¤ íšŒì˜ì˜ transcriptì¸ì§€ | `a1b2c3...` |
| **source_type** | enum | caption / whisper / merged / manual | `whisper` |
| **provider** | enum | upload / youtube / zoom / gmeet / teams / manual | `upload` |
| **backend** | enum | openai / whisper_cpp / faster_whisper / manual / unknown | `faster_whisper` |
| **model** | varchar | ì‹¤ì œ ëª¨ë¸ ëª… | `large-v3` |
| **is_primary** | boolean | MeetingAgentê°€ ì‚¬ìš©í•˜ëŠ” ëŒ€í‘œ transcript | `true` |
| **quality_score** | float | 0.0~1.0, ìë™ ê³„ì‚° í’ˆì§ˆ ì ìˆ˜ | `0.85` |
| **confidence** | float | 0.0~1.0, Whisper confidence | `0.92` |
| **latency_ms** | integer | STT ì²˜ë¦¬ ì‹œê°„ (ms) | `52340` |
| **transcript_text** | text | ì „ì²´ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ í…ìŠ¤íŠ¸ | `"ì•ˆë…•í•˜ì„¸ìš”..."` |
| **segments** | jsonb | íƒ€ì„ìŠ¤íƒ¬í”„ ì„¸ê·¸ë¨¼íŠ¸ | `[{"start": 0.0, "end": 3.2, "text": "..."}]` |

---

## 5. TranscriberService ì„¤ê³„

### 5.1 ê³µí†µ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ (TranscriptionResult)

```python
# app/schemas/transcriber.py
from pydantic import BaseModel
from typing import List, Optional

class TranscriptSegment(BaseModel):
    start: float
    end: float
    text: str

class TranscriptionResult(BaseModel):
    text: str
    segments: List[TranscriptSegment]
    language: str
    duration_seconds: float
    backend: str      # "faster_whisper" | "openai" | "whisper_cpp"
    model: str        # "large-v3" | "whisper-1" ...
    latency_ms: int
    confidence: Optional[float] = None
```

### 5.2 í´ë¼ì´ì–¸íŠ¸ êµ¬ì¡°

```python
# Base Interface
class BaseWhisperClient(ABC):
    @abstractmethod
    async def transcribe(self, audio_path: str, **kwargs) -> TranscriptionResult:
        ...

# Implementations
class OpenAIWhisperClient(BaseWhisperClient):
    """OpenAI Audio API í˜¸ì¶œ"""
    ...

class WhisperCppClient(BaseWhisperClient):
    """Mac mini whisper.cpp HTTP ì„œë²„ í˜¸ì¶œ"""
    ...

class FasterWhisperClient(BaseWhisperClient):
    """RTX Desktop faster-whisper HTTP ì„œë²„ í˜¸ì¶œ"""
    ...
```

### 5.3 TranscriberService í•µì‹¬ ë¡œì§

```python
# app/services/transcriber.py
class TranscriberService:
    def __init__(self, settings: Optional[Settings] = None):
        self.settings = settings or Settings()
        self.mode = self.settings.WHISPER_MODE
        self.openai_client = OpenAIWhisperClient(self.settings)

        if self.settings.WHISPER_LOCAL_BACKEND == WhisperLocalBackend.whisper_cpp:
            self.local_client = WhisperCppClient(self.settings)
        elif self.settings.WHISPER_LOCAL_BACKEND == WhisperLocalBackend.faster_whisper:
            self.local_client = FasterWhisperClient(self.settings)
        else:
            self.local_client = None

    async def transcribe(
        self,
        audio_path: str,
        duration_seconds: float,
        force_mode: Optional[str] = None
    ) -> TranscriptionResult:
        """
        ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            duration_seconds: ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
            force_mode: ëª¨ë“œ ê°•ì œ (openai | local | hybrid_cost | hybrid_quality)

        Returns:
            TranscriptionResult
        """
        mode = force_mode or self.mode

        if mode == WhisperMode.openai:
            return await self._openai_only(audio_path)

        if mode == WhisperMode.local:
            return await self._local_only(audio_path)

        if mode == WhisperMode.hybrid_cost:
            return await self._hybrid_cost(audio_path, duration_seconds)

        if mode == WhisperMode.hybrid_quality:
            return await self._hybrid_quality(audio_path, duration_seconds)

        # Default fallback
        return await self._openai_only(audio_path)

    async def _hybrid_cost(
        self,
        audio_path: str,
        duration_seconds: float
    ) -> TranscriptionResult:
        """
        hybrid_cost ëª¨ë“œ:
        - ì§§ì€ íšŒì˜ (â‰¤ WHISPER_OPENAI_MAX_MINUTES): OpenAI ìš°ì„  â†’ local fallback
        - ê¸´ íšŒì˜: local ìš°ì„  â†’ OpenAI fallback
        """
        max_minutes = self.settings.WHISPER_OPENAI_MAX_MINUTES or 20

        if duration_seconds <= max_minutes * 60:
            # ì§§ì€ íšŒì˜: OpenAI ìš°ì„ 
            try:
                return await self.openai_client.transcribe(audio_path)
            except Exception as e:
                logger.warning(f"OpenAI failed, fallback to local: {e}")
                if self.local_client:
                    return await self.local_client.transcribe(audio_path)
                raise
        else:
            # ê¸´ íšŒì˜: local ìš°ì„ 
            if self.local_client:
                try:
                    return await self.local_client.transcribe(audio_path)
                except Exception as e:
                    logger.warning(f"Local failed, fallback to OpenAI: {e}")
                    return await self.openai_client.transcribe(audio_path)
            else:
                return await self.openai_client.transcribe(audio_path)

    async def _hybrid_quality(
        self,
        audio_path: str,
        duration_seconds: float
    ) -> TranscriptionResult:
        """
        hybrid_quality ëª¨ë“œ:
        - ë¬´ì¡°ê±´ local(large-v3) ìš°ì„  â†’ OpenAI fallback
        """
        if self.local_client:
            try:
                return await self.local_client.transcribe(
                    audio_path,
                    model="large-v3"  # í’ˆì§ˆ ìš°ì„ 
                )
            except Exception as e:
                logger.warning(f"Local failed, fallback to OpenAI: {e}")
                return await self.openai_client.transcribe(audio_path)
        else:
            return await self.openai_client.transcribe(audio_path)

    # ... (ê¸°íƒ€ ë©”ì„œë“œ ìƒëµ)
```

---

## 6. API ìŠ¤í™

### 6.1 POST /api/v1/meetings/{meeting_id}/transcribe

**ëª©ì **: íŠ¹ì • Meetingì— ì—°ê²°ëœ ì˜¤ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ STT ì‹¤í–‰ ë° transcript ìƒì„±

#### Request

```http
POST /api/v1/meetings/123/transcribe
Content-Type: application/json

{
  "force_mode": null,           // "openai" | "local" | "hybrid_cost" | "hybrid_quality" (ì—†ìœ¼ë©´ .env)
  "reprocess": false,           // trueë©´ ê¸°ì¡´ primary transcript ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±
  "importance": "normal",       // "normal" | "high" (high -> hybrid_quality ê°•ì œ ë“± ì •ì±… ê°€ëŠ¥)
  "run_meeting_agent": true     // trueë©´ STT ì™„ë£Œ í›„ MeetingAgent ì‹¤í–‰
}
```

#### Response (ì„±ê³µ)

```json
{
  "meeting_id": "uuid-123",
  "transcript_id": "uuid-987",
  "source_type": "whisper",
  "backend": "faster_whisper",
  "model": "large-v3",
  "language": "ko",
  "duration_seconds": 3600.5,
  "latency_ms": 52340,
  "is_primary": true,
  "status": "completed",
  "meeting_agent_triggered": true
}
```

#### Response (ì—ëŸ¬)

```json
{
  "error": {
    "code": "transcription_failed",
    "message": "All STT engines failed",
    "details": {
      "faster_whisper_error": "Connection timeout",
      "openai_error": "API rate limit exceeded"
    }
  }
}
```

### 6.2 ì£¼ìš” ë™ì‘ í”Œë¡œìš° (BíŒ€ êµ¬í˜„)

1. Meeting ì¡´ì¬ í™•ì¸ (404 ì²˜ë¦¬)
2. `get_meeting_audio_source(meeting)`ë¡œ ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ duration_seconds í™•ë³´
3. TranscriberService ìƒì„±
   - `force_mode` ë˜ëŠ” `importance=high`ì— ë”°ë¼ mode ì„ì‹œ override
4. `transcribe(audio_path, duration_seconds)` í˜¸ì¶œ
5. `reprocess=true`ë©´, ê¸°ì¡´ primary transcriptì˜ `is_primary=false`ë¡œ ê°±ì‹ 
6. ìƒˆë¡œìš´ `meeting_transcripts` row ìƒì„± (`source_type='whisper'`, `is_primary=true`)
7. `run_meeting_agent=true`ë©´ BackgroundTasksë¡œ MeetingAgent ì‹¤í–‰
8. Response ë°˜í™˜

---

## 7. RTX Desktop faster-whisper ì„œë²„ ìŠ¤í™

### 7.1 ì—”ë“œí¬ì¸íŠ¸

- **Base URL**: `http://100.123.51.6:9000`
- **ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸**: `POST /transcribe`

### 7.2 Request (multipart/form-data)

```http
POST /transcribe HTTP/1.1
Host: 100.123.51.6:9000
Content-Type: multipart/form-data; boundary=----Boundary

------Boundary
Content-Disposition: form-data; name="audio_file"; filename="meeting.wav"
Content-Type: audio/wav

<ë°”ì´ë„ˆë¦¬ ë°ì´í„°>
------Boundary
Content-Disposition: form-data; name="model"

large-v3
------Boundary
Content-Disposition: form-data; name="language"

auto
------Boundary
Content-Disposition: form-data; name="task"

transcribe
------Boundary
Content-Disposition: form-data; name="temperature"

0.0
------Boundary--
```

**í•„ë“œ**:
- `audio_file` (í•„ìˆ˜): ì˜¤ë””ì˜¤ ë°”ì´ë„ˆë¦¬
- `model` (ì„ íƒ): small | medium | large-v3 ë“±
- `language` (ì„ íƒ): auto ë˜ëŠ” ko, en ë“±
- `task` (ì„ íƒ): transcribe / translate
- `temperature` (ì„ íƒ): 0.0 ~ 1.0

### 7.3 Response (ì„±ê³µ)

```json
{
  "backend": "faster_whisper",
  "model": "large-v3",
  "language": "ko",
  "duration": 3600.52,
  "latency_ms": 52340,
  "text": "ì „ì²´ transcript ë‚´ìš©...",
  "segments": [
    {
      "id": 0,
      "start": 0.00,
      "end": 3.20,
      "text": "ì²« ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤."
    },
    {
      "id": 1,
      "start": 3.20,
      "end": 7.80,
      "text": "ë‘ ë²ˆì§¸ ë¬¸ì¥ì…ë‹ˆë‹¤."
    }
  ],
  "confidence": 0.92
}
```

### 7.4 Response (ì—ëŸ¬)

```json
{
  "error": {
    "type": "internal_error",      // internal_error | invalid_audio | model_not_found | timeout
    "message": "Failed to run faster-whisper: CUDA out of memory.",
    "details": null
  }
}
```

---

## 8. QA í…ŒìŠ¤íŠ¸ í”Œëœ

### 8.1 ëª¨ë“œë³„ ë™ì‘ (AíŒ€ ê²€ì¦ ëŒ€ìƒ)

| í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ | WHISPER_MODE | íšŒì˜ ê¸¸ì´ | ì˜ˆìƒ ë™ì‘ | ê²€ì¦ í•­ëª© |
|------------|--------------|----------|---------|---------|
| TC-1 | openai | 10ë¶„ | OpenAIë§Œ í˜¸ì¶œ | backend='openai' |
| TC-2 | local | 60ë¶„ | faster-whisperë§Œ í˜¸ì¶œ | backend='faster_whisper' |
| TC-3 | hybrid_cost | 10ë¶„ | OpenAI ìš°ì„  â†’ ì‹¤íŒ¨ ì‹œ faster-whisper | fallback ë¡œì§ |
| TC-4 | hybrid_cost | 90ë¶„ | faster-whisper ìš°ì„  â†’ ì‹¤íŒ¨ ì‹œ OpenAI | fallback ë¡œì§ |
| TC-5 | hybrid_quality | 10ë¶„ | faster-whisper(large-v3) ìš°ì„  | model='large-v3' |

### 8.2 ë°±ì—”ë“œ ì¢…ë¥˜ë³„

- ë™ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ì— ëŒ€í•´ faster-whisper / whisper.cpp / OpenAI ê²°ê³¼ ë¹„êµ
- `backend`, `model`, `latency_ms`ê°€ ê¸°ëŒ€ê°’ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦

### 8.3 meeting_transcripts ì¼ê´€ì„±

- **reprocess=false**: ê¸°ì¡´ primary ìœ ì§€, ìƒˆ transcriptëŠ” `is_primary=false`
- **reprocess=true**: ê¸°ì¡´ primary â†’ `false`, ìƒˆ transcript â†’ `true`
- MeetingAgentê°€ í•­ìƒ `is_primary=true` transcriptë§Œ ì‚¬ìš©í•˜ëŠ”ì§€

### 8.4 ì¥ì• /ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤

- faster-whisper ì„œë²„ ë‹¤ìš´ / Timeout â†’ OpenAI fallback í™•ì¸
- ì˜ëª»ëœ ì˜¤ë””ì˜¤ íŒŒì¼ â†’ ì ì ˆí•œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
- í”„ë¡ íŠ¸ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ë©”ì‹œì§€ í‘œì‹œ

---

## 9. í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ê°€ì´ë“œ

### 9.1 ê¸°ë³¸ UX í”Œë¡œìš° (CíŒ€)

1. Meeting ìƒì„¸ í˜ì´ì§€ì—ì„œ "Transcribe" ë²„íŠ¼ í´ë¦­
2. `POST /api/v1/meetings/{id}/transcribe` í˜¸ì¶œ
   - ê¸°ë³¸: `{ "importance": "normal", "run_meeting_agent": true }`
   - ì¤‘ìš”í•œ íšŒì˜: `{ "importance": "high" }` â†’ hybrid_quality ì „ëµ
3. ì‘ë‹µì´ ì„±ê³µì´ë©´:
   - "Transcript ì¤€ë¹„ ì™„ë£Œ" ìƒíƒœë¡œ í‘œì‹œ
   - Transcript/ Summary/ Brief íƒ­ ë°ì´í„° ì¬ì¡°íšŒ
4. ì‹¤íŒ¨ ì‹œ:
   - ë°±ì—”ë“œì—ì„œ ë‚´ë ¤ì¤€ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
   - í•„ìš” ì‹œ ì¬ì‹œë„ ë²„íŠ¼ ì œê³µ

### 9.2 í‘œì‹œí•˜ë©´ ì¢‹ì€ ì •ë³´

Transcript ìƒì„± í›„:
- **STT ì—”ì§„**: `backend` (faster_whisper, openai ë“±)
- **ëª¨ë¸**: `model` (large-v3, whisper-1 ë“±)
- **ì²˜ë¦¬ ì‹œê°„**: `latency_ms` (ì˜ˆ: 52ì´ˆ)
- **ì˜¤ë””ì˜¤ ê¸¸ì´**: `duration_seconds` (ì˜ˆ: 60ë¶„)

ì´ ì •ë³´ëŠ” AíŒ€ QAì—ë„ ìœ ìš©í•œ Debug ì •ë³´ì´ë¯€ë¡œ, ê°œë°œì ëª¨ë“œë‚˜ ê°„ë‹¨í•œ ë¼ë²¨ë¡œ ë…¸ì¶œ ê¶Œì¥.

---

## 10. íŒ€ë³„ ì—­í•  ë° ì²´í¬ë¦¬ìŠ¤íŠ¸

### 10.1 AíŒ€ (QA)

- [ ] ëª¨ë“œë³„ ë™ì‘ ê²€ì¦ (openai, local, hybrid_cost, hybrid_quality)
- [ ] Fallback ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ (faster-whisper ë‹¤ìš´ â†’ OpenAI)
- [ ] Golden Set ì‘ì„± (5ê°œ íšŒì˜ ìƒ˜í”Œ, ë‹¤ì–‘í•œ ê¸¸ì´/ì¤‘ìš”ë„)
- [ ] meeting_transcripts primary ì¼ê´€ì„± ê²€ì¦
- [ ] ì—ëŸ¬ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ (ì˜ëª»ëœ íŒŒì¼, ì„œë²„ ì¥ì•  ë“±)

### 10.2 BíŒ€ (Backend)

- [ ] DB Schema ì™„ì„± (source_type, provider, backend, model ë“±)
- [ ] Alembic Migration ì‘ì„±
- [ ] TranscriberService êµ¬í˜„ (4-mode strategy)
- [ ] FasterWhisperClient êµ¬í˜„ (RTX Desktop ì„œë²„ ì—°ë™)
- [ ] WhisperCppClient êµ¬í˜„ (optional, Mac mini)
- [ ] OpenAIWhisperClient êµ¬í˜„
- [ ] `/meetings/{id}/transcribe` API ì™„ì„±
- [ ] reprocess ë¡œì§ êµ¬í˜„
- [ ] run_meeting_agent BackgroundTask ì—°ë™

### 10.3 CíŒ€ (Frontend)

- [ ] Meeting ìƒì„¸ í˜ì´ì§€ì— "Transcribe" ë²„íŠ¼ ì¶”ê°€
- [ ] `/meetings/{id}/transcribe` API ì—°ë™
- [ ] ì§„í–‰ ìƒíƒœ í‘œì‹œ (Transcribing... â†’ Completed)
- [ ] backend, model, latency_ms ì •ë³´ í‘œì‹œ (ê°œë°œì ëª¨ë“œ)
- [ ] ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ ë° ì¬ì‹œë„ ë²„íŠ¼
- [ ] Transcript/Summary/Brief íƒ­ êµ¬í˜„
- [ ] importance ì˜µì…˜ UI (normal / high í† ê¸€)

---

## ë¶€ë¡

### A. Whisper ëª¨ë¸ ë¹„êµ

| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | ë©”ëª¨ë¦¬ (GPU) | ì†ë„ (RTX 3090 ê¸°ì¤€) | ì •í™•ë„ |
|-----|---------|------------|-------------------|--------|
| **tiny** | 39M | ~1GB | 10x ì‹¤ì‹œê°„ | â˜…â˜…â˜†â˜†â˜† |
| **small** | 244M | ~2GB | 5x ì‹¤ì‹œê°„ | â˜…â˜…â˜…â˜†â˜† |
| **medium** | 769M | ~5GB | 2x ì‹¤ì‹œê°„ | â˜…â˜…â˜…â˜…â˜† |
| **large-v3** | 1550M | ~10GB | 1x ì‹¤ì‹œê°„ | â˜…â˜…â˜…â˜…â˜… |

**ì¶”ì²œ**:
- **ê¸°ë³¸ê°’**: medium (ì†ë„+í’ˆì§ˆ ê· í˜•)
- **ì¤‘ìš” íšŒì˜**: large-v3 (ìµœê³  í’ˆì§ˆ)
- **ë¹ ë¥¸ ì²˜ë¦¬**: small (ìŠ¤íƒ ë“œì—…, ì§§ì€ ë¯¸íŒ…)

### B. í™˜ê²½ë³„ ê¶Œì¥ ì„¤ì •

#### ê°œë°œ í™˜ê²½ (ë…¸íŠ¸ë¶)
```bash
WHISPER_MODE=openai
WHISPER_OPENAI_MODEL=whisper-1
```

#### ìŠ¤í…Œì´ì§• í™˜ê²½ (Mac mini + RTX Desktop)
```bash
WHISPER_MODE=hybrid_cost
WHISPER_LOCAL_BACKEND=faster_whisper
WHISPER_FAST_ENDPOINT=http://100.123.51.6:9000/transcribe
WHISPER_OPENAI_MAX_MINUTES=20
```

#### í”„ë¡œë•ì…˜ í™˜ê²½
```bash
WHISPER_MODE=hybrid_cost
WHISPER_LOCAL_BACKEND=faster_whisper
WHISPER_FAST_ENDPOINT=http://100.123.51.6:9000/transcribe
WHISPER_CPP_ENDPOINT=http://127.0.0.1:8765/transcribe  # ë°±ì—…
WHISPER_OPENAI_MAX_MINUTES=15  # ë” ì—„ê²©í•˜ê²Œ
WHISPER_MAX_RETRIES=3
```

---

## ë¬¸ì˜ ë° ê¸°ì—¬

- **ë¬¸ì„œ ê´€ë¦¬**: BíŒ€ (Backend)
- **ì—…ë°ì´íŠ¸ ì´ë ¥**: `git log docs/MEETING_AI_TRANSCRIBER_SPEC.md`
- **ì´ìŠˆ ì œë³´**: GitHub Issues
